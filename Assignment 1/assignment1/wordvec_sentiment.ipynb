{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Word Vectors and Sentiment Analysis\n",
    "CS 224D Assignment 1  \n",
    "Spring 2015\n",
    "\n",
    "*Complete and hand in this completed worksheet (including its outputs and any supporting code outside of the worksheet) with your assignment submission. For more details see the [assignments page](http://cs224d.stanford.edu/assignment1) on the course website.*\n",
    "\n",
    "In this assignment, we will walk you through the process of implementing \n",
    "\n",
    "- A softmax function\n",
    "- A simple neural network\n",
    "- Back propagation\n",
    "- Word2vec models\n",
    "\n",
    "and training your own word vectors with stochastic gradient descent (SGD) for a sentiment analysis task. Please make sure to finish the corresponding problems in the problem set PDF when instructed by the worksheet.\n",
    "\n",
    "The purpose of this assignment is to familiarize you with basic knowledge about neural networks and machine learning, including optimization and cross-validation, and help you gain proficiency in writing efficient, vectorized code.\n",
    "\n",
    "** Please don't add or remove any code cells, as it might break our automatic grading system and affect your grade. **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Honor Code:** I hereby agree to abide the Stanford Honor Code and that of the Computer Science Department, promise that the submitted assignment is my own work, and understand that my code is subject to plagiarism test.\n",
    "\n",
    "**Signature**: *Shubhanshu Mishra*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Run some setup code for this notebook. Don't modify anything in this cell.\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "from cs224d.data_utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# This is a bit of magic to make matplotlib figures appear inline in the notebook\n",
    "# rather than in a new window.\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# Some more magic so that the notebook will reload external python modules;\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Softmax\n",
    "*Please answer the first first complementary problem before starting this part.*\n",
    "\n",
    "Given an input matrix of *N* rows and *d* columns, compute the softmax prediction for each row. That is, when the input is\n",
    "\n",
    "    [[1,2],\n",
    "    [3,4]]\n",
    "    \n",
    "the output of your functions should be\n",
    "\n",
    "    [[0.2689, 0.7311],\n",
    "    [0.2689, 0.7311]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    \"\"\" Softmax function \"\"\"\n",
    "    ###################################################################\n",
    "    # Compute the softmax function for the input here.                #\n",
    "    # It is crucial that this function is optimized for speed because #\n",
    "    # it will be used frequently in later code.                       #\n",
    "    # You might find numpy functions np.exp, np.sum, np.reshape,      #\n",
    "    # np.max, and numpy broadcasting useful for this task. (numpy     #\n",
    "    # broadcasting documentation:                                     #\n",
    "    # http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)  #\n",
    "    # You should also make sure that your code works for one          #\n",
    "    # dimensional inputs (treat the vector as a row), you might find  #\n",
    "    # it helpful for your later problems.                             #\n",
    "    ###################################################################\n",
    "    \n",
    "    ### YOUR CODE HERE\n",
    "    x = x.T\n",
    "    x -= np.max(x,axis=0) # normalize x by max in each row\n",
    "    x = np.exp(x)\n",
    "    x = x/np.sum(x,axis=0)  # softmax probability\n",
    "    return x.T\n",
    "    ### END YOUR CODE\n",
    "    \n",
    "    #return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== For autograder ===\n",
      "[[ 0.26894142  0.73105858]\n",
      " [ 0.26894142  0.73105858]]\n",
      "Wall time: 2 ms\n",
      "[[ 0.09003057  0.24472847  0.66524096]\n",
      " [ 0.09003057  0.24472847  0.66524096]]\n",
      "Wall time: 3 ms\n",
      "[ 0.09003057  0.24472847  0.66524096]\n",
      "Wall time: 1 ms\n",
      "[[ 0.26894142  0.73105858]\n",
      " [ 0.26894142  0.73105858]]\n",
      "Wall time: 1e+03 Âµs\n",
      "[[ 0.73105858  0.26894142]]\n",
      "Wall time: 2 ms\n"
     ]
    }
   ],
   "source": [
    "# Verify your softmax implementation\n",
    "\n",
    "print \"=== For autograder ===\"\n",
    "%time print softmax(np.array([[1,2],[3,4]]))\n",
    "%time print softmax(np.array([[1,2,3],[3,4,5]]))\n",
    "%time print softmax(np.array([1,2,3]))\n",
    "%time print softmax(np.array([[1001,1002],[3,4]]))\n",
    "%time print softmax(np.array([[-1001,-1002]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Neural network basics\n",
    "\n",
    "*Please answer the second complementary question before starting this part.*\n",
    "\n",
    "In this part, you're going to implement\n",
    "\n",
    "* A sigmoid activation function and its gradient\n",
    "* A forward propagation for a simple neural network with cross-entropy cost\n",
    "* A backward propagation algorithm to compute gradients for the parameters\n",
    "* Gradient / derivative check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    \"\"\" Sigmoid function \"\"\"\n",
    "    ###################################################################\n",
    "    # Compute the sigmoid function for the input here.                #\n",
    "    ###################################################################\n",
    "    \n",
    "    ### YOUR CODE HERE\n",
    "    return 1./(1+np.exp(-x))\n",
    "    ### END YOUR CODE\n",
    "    \n",
    "    #return x\n",
    "\n",
    "def sigmoid_grad(f):\n",
    "    \"\"\" Sigmoid gradient function \"\"\"\n",
    "    ###################################################################\n",
    "    # Compute the gradient for the sigmoid function here. Note that   #\n",
    "    # for this implementation, the input f should be the sigmoid      #\n",
    "    # function value of your original input x.                        #\n",
    "    ###################################################################\n",
    "    \n",
    "    ### YOUR CODE HERE\n",
    "    return f*(1-f)\n",
    "    ### END YOUR CODE\n",
    "    \n",
    "    #return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n",
      "Wall time: 0 ns\n",
      "=== For autograder ===\n",
      "[[ 0.73105858  0.88079708]\n",
      " [ 0.26894142  0.11920292]]\n",
      "[[ 0.19661193  0.10499359]\n",
      " [ 0.19661193  0.10499359]]\n"
     ]
    }
   ],
   "source": [
    "# Check your sigmoid implementation\n",
    "x = np.array([[1, 2], [-1, -2]])\n",
    "%time f = sigmoid(x)\n",
    "%time g = sigmoid_grad(f)\n",
    "print \"=== For autograder ===\"\n",
    "print f\n",
    "print g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, use the functions you just implemented, fill in the following functions to implement a neural network with one sigmoid hidden layer. You might find the handout and your answers to the second complementary problem helpful for this part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# First implement a gradient checker by filling in the following functions\n",
    "def gradcheck_naive(f, x):\n",
    "    \"\"\" \n",
    "    Gradient check for a function f \n",
    "    - f should be a function that takes a single argument and outputs the cost and its gradients\n",
    "    - x is the point (numpy array) to check the gradient at\n",
    "    \"\"\" \n",
    "\n",
    "    rndstate = random.getstate()\n",
    "    random.setstate(rndstate)  \n",
    "    fx, grad = f(x) # Evaluate function value at original point\n",
    "    h = 1e-4\n",
    "\n",
    "    # Iterate over all indexes in x\n",
    "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    while not it.finished:\n",
    "        ix = it.multi_index\n",
    "    \n",
    "        ### YOUR CODE HERE: try modifying x[ix] with h defined above to compute numerical gradients\n",
    "        ### make sure you call random.setstate(rndstate) before calling f(x) each time, this will make it \n",
    "        ### possible to test cost functions with built in randomness later\n",
    "    \n",
    "        #return # replace this line with your code\n",
    "        #x_temp = x[ix]\n",
    "        x[ix] -= h\n",
    "        random.setstate(rndstate)\n",
    "        f0 = f(x)[0]\n",
    "        x[ix] += 2 * h\n",
    "        random.setstate(rndstate)\n",
    "        f1 = f(x)[0]\n",
    "        #x[ix] = x_temp\n",
    "        x[ix] -= h\n",
    "        numgrad = (f1 - f0) / (2 * h)\n",
    "        \n",
    "        #print x[ix], numgrad, fx_h1, fx_h2\n",
    "        ### END YOUR CODE\n",
    "        #print grad.shape\n",
    "\n",
    "        # Compare gradients\n",
    "        reldiff = abs(numgrad - grad[ix]) / max(1, abs(numgrad), abs(grad[ix]))\n",
    "        if reldiff > 1e-5:\n",
    "            print \"Gradient check failed.\"\n",
    "            print \"First gradient error found at index %s\" % str(ix)\n",
    "            print \"Your gradient: %f \\t Numerical gradient: %f\" % (grad[ix], numgrad)\n",
    "            return\n",
    "    \n",
    "        it.iternext() # Step to next dimension\n",
    "\n",
    "    print \"Gradient check passed!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== For autograder ===\n",
      "Gradient check passed!\n",
      "Gradient check passed!\n",
      "Gradient check passed!\n",
      "1 loops, best of 3: 382 Âµs per loop\n",
      "Gradient check passed!\n",
      "Gradient check passed!\n",
      "Gradient check passed!\n",
      "1 loops, best of 3: 654 Âµs per loop\n",
      "Gradient check passed!\n",
      "Gradient check passed!\n",
      "Gradient check passed!\n",
      "1 loops, best of 3: 3.04 ms per loop\n"
     ]
    }
   ],
   "source": [
    "# Sanity check for the gradient checker\n",
    "quad = lambda x: (np.sum(x ** 2), x * 2)\n",
    "\n",
    "print \"=== For autograder ===\"\n",
    "%timeit -n 1 gradcheck_naive(quad, np.array(123.456))      # scalar test\n",
    "%timeit -n 1 gradcheck_naive(quad, np.random.randn(3,))    # 1-D test\n",
    "%timeit -n 1 gradcheck_naive(quad, np.random.randn(4,5))   # 2-D test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set up fake data and parameters for the neural network\n",
    "N = 20\n",
    "dimensions = [10, 5, 10]\n",
    "data = np.random.randn(N, dimensions[0])   # each row will be a datum\n",
    "labels = np.zeros((N, dimensions[2]))\n",
    "for i in xrange(N):\n",
    "    labels[i,random.randint(0,dimensions[2]-1)] = 1\n",
    "\n",
    "params = np.random.randn((dimensions[0] + 1) * dimensions[1] + (dimensions[1] + 1) * dimensions[2], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def forward_backward_prop(data, labels, params):\n",
    "    \"\"\" Forward and backward propagation for a two-layer sigmoidal network \"\"\"\n",
    "    ###################################################################\n",
    "    # Compute the forward propagation and for the cross entropy cost, #\n",
    "    # and backward propagation for the gradients for all parameters.  #\n",
    "    ###################################################################\n",
    "    \n",
    "    ### Unpack network parameters (do not modify)\n",
    "    t = 0\n",
    "    W1 = np.reshape(params[t:t+dimensions[0]*dimensions[1]], (dimensions[0], dimensions[1]))\n",
    "    t += dimensions[0]*dimensions[1]\n",
    "    b1 = np.reshape(params[t:t+dimensions[1]], (1, dimensions[1]))\n",
    "    t += dimensions[1]\n",
    "    W2 = np.reshape(params[t:t+dimensions[1]*dimensions[2]], (dimensions[1], dimensions[2]))\n",
    "    t += dimensions[1]*dimensions[2]\n",
    "    b2 = np.reshape(params[t:t+dimensions[2]], (1, dimensions[2]))\n",
    "    \n",
    "    ### YOUR CODE HERE: forward propagation\n",
    "    # cost = ...\n",
    "    #print \"Shapes: x=> %s, W1 => %s, b1 => %s, W2 => %s, b2 => %s, y => %s\" \\\n",
    "    #    %(data.shape, W1.shape, b1.shape, W2.shape, b2.shape, labels.shape)\n",
    "    N = data.shape[0]\n",
    "    X = data\n",
    "    Y = labels\n",
    "    Z1 = X.dot(W1)\n",
    "    H = sigmoid(Z1+b1)\n",
    "    Z2 = H.dot(W2)\n",
    "    Y_hat = softmax(Z2+b2)\n",
    "    # cost = ...\n",
    "    cost = np.sum(-Y*np.log(Y_hat))/N\n",
    "\n",
    "    ### END YOUR CODE\n",
    "\n",
    "    ### YOUR CODE HERE: backward propagation\n",
    "    #print \"z1 => %s, h => %s, z2 => %s, y_hat => %s\" % (Z1.shape, H.shape, Z2.shape, Y_hat.shape)\n",
    "    \n",
    "    dZ2 = Y_hat - Y \n",
    "    dW2 = H.T.dot(dZ2)\n",
    "    db2 = np.sum(dZ2, axis=0) # Also can be written as db2 = dZ2.T.dot(np.ones(dZ2.shape[0]))\n",
    "    dH = dZ2.dot(W2.T)\n",
    "    dZ1 = dH*sigmoid_grad(H)\n",
    "    dW1 = X.T.dot(dZ1)\n",
    "    db1 = np.sum(dZ1, axis=0) # Also can be written as db1 = dZ1.T.dot(np.ones(dZ1.shape[0]))\n",
    "    #print \"dZ2 => %s, dW2 => %s, db2 => %s, dZ1 => %s, dW1 => %s, db1 => %s\"\\\n",
    "    #    % (dZ2.shape, dW2.shape, db2.shape, dZ1.shape, dW1.shape, db1.shape)\n",
    "    \n",
    "    #gradW1 = ...\n",
    "    #gradb1 = ...\n",
    "    #gradW2 = ...\n",
    "    #gradb2 = ...\n",
    "    \n",
    "    gradW2 = dW2/N\n",
    "    gradW1 = dW1/N\n",
    "    gradb1 = db1/N\n",
    "    gradb2 = db2/N\n",
    "    \n",
    "    ### END YOUR CODE\n",
    "    \n",
    "    ### Stack gradients (do not modify)\n",
    "    grad = np.concatenate((gradW1.flatten(), gradb1.flatten(), gradW2.flatten(), gradb2.flatten()))\n",
    "    \n",
    "    return cost, grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== For autograder ===\n",
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "# Perform gradcheck on your neural network\n",
    "print \"=== For autograder ===\"\n",
    "#print forward_backward_prop(data, labels, params)\n",
    "gradcheck_naive(lambda params: forward_backward_prop(data, labels, params), np.array(params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Word2vec\n",
    "\n",
    "*Please answer the third complementary problem before starting this part.*\n",
    "\n",
    "In this part you will implement the `word2vec` models and train your own word vectors with stochastic gradient descent (SGD)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Implement your skip-gram and CBOW models here\n",
    "\n",
    "# Interface to the dataset for negative sampling\n",
    "dataset = type('dummy', (), {})()\n",
    "def dummySampleTokenIdx():\n",
    "    return random.randint(0, 4)\n",
    "def getRandomContext(C):\n",
    "    tokens = [\"a\", \"b\", \"c\", \"d\", \"e\"]\n",
    "    return tokens[random.randint(0,4)], [tokens[random.randint(0,4)] for i in xrange(2*C)]\n",
    "dataset.sampleTokenIdx = dummySampleTokenIdx\n",
    "dataset.getRandomContext = getRandomContext\n",
    "\n",
    "def softmaxCostAndGradient(predicted, target, outputVectors):\n",
    "    \"\"\" Softmax cost function for word2vec models \"\"\"\n",
    "    ###################################################################\n",
    "    # Implement the cost and gradients for one predicted word vector  #\n",
    "    # and one target word vector as a building block for word2vec     #\n",
    "    # models, assuming the softmax prediction function and cross      #\n",
    "    # entropy loss.                                                   #\n",
    "    # Inputs:                                                         #\n",
    "    #   - predicted: numpy ndarray, predicted word vector (\\hat{r} in #\n",
    "    #           the written component)                                #\n",
    "    #   - target: integer, the index of the target word               #\n",
    "    #   - outputVectors: \"output\" vectors for all tokens              #\n",
    "    # Outputs:                                                        #\n",
    "    #   - cost: cross entropy cost for the softmax word prediction    #\n",
    "    #   - gradPred: the gradient with respect to the predicted word   #\n",
    "    #           vector                                                #\n",
    "    #   - grad: the gradient with respect to all the other word       # \n",
    "    #           vectors                                               #\n",
    "    # We will not provide starter code for this function, but feel    #\n",
    "    # free to reference the code you previously wrote for this        #\n",
    "    # assignment!                                                     #\n",
    "    ###################################################################\n",
    "    \n",
    "    ### YOUR CODE HERE\n",
    "    # predicted: d-dimensional 1-d array\n",
    "    # outputVectors: V * d\n",
    "    # gradPred: d-dimensional 1-d array\n",
    "    # grad : V * d\n",
    "    y = softmax(outputVectors.dot(predicted))\n",
    "    cost = -np.log(y[target])\n",
    "    y[target] -= 1\n",
    "    gradPred = outputVectors.T.dot(y)\n",
    "    grad = np.outer(y, predicted)\n",
    "    #print \"gradPred.shape, grad.shape\", gradPred.shape, grad.shape\n",
    "    ### END YOUR CODE\n",
    "    \n",
    "    return cost, gradPred, grad\n",
    "\n",
    "def negSamplingCostAndGradient(predicted, target, outputVectors, K=10):\n",
    "    \"\"\" Negative sampling cost function for word2vec models \"\"\"\n",
    "    ###################################################################\n",
    "    # Implement the cost and gradients for one predicted word vector  #\n",
    "    # and one target word vector as a building block for word2vec     #\n",
    "    # models, using the negative sampling technique. K is the sample  #\n",
    "    # size. You might want to use dataset.sampleTokenIdx() to sample  #\n",
    "    # a random word index.                                            #\n",
    "    # Input/Output Specifications: same as softmaxCostAndGradient     #\n",
    "    # We will not provide starter code for this function, but feel    #\n",
    "    # free to reference the code you previously wrote for this        #\n",
    "    # assignment!                                                     #\n",
    "    ###################################################################\n",
    "    \n",
    "    ### YOUR CODE HERE\n",
    "\n",
    "    # predicted: d-dimensional 1-d array\n",
    "    # outputVectors: V * d\n",
    "    # gradPred: d-dimensional 1-d array\n",
    "    # grad : V * d\n",
    "    y = sigmoid(outputVectors[target,:].dot(predicted))\n",
    "    cost = -np.log(y)\n",
    "    gradPred = (y-1)*outputVectors[target,:]\n",
    "    grad = np.zeros_like(outputVectors)\n",
    "    grad[target,:] += (y-1)*predicted\n",
    "    for _ in xrange(K):\n",
    "        i = dataset.sampleTokenIdx()\n",
    "        y = sigmoid(-outputVectors[i,:].dot(predicted))\n",
    "        cost += -np.log(y)\n",
    "        gradPred += (1-y)*outputVectors[i,:]\n",
    "        grad[i,:] += (1-y)*predicted\n",
    "        \n",
    "    \n",
    "    ### END YOUR CODE\n",
    "    \n",
    "    return cost, gradPred, grad\n",
    "\n",
    "def skipgram(currentWord, C, contextWords, tokens, inputVectors, outputVectors, word2vecCostAndGradient = softmaxCostAndGradient):\n",
    "    \"\"\" Skip-gram model in word2vec \"\"\"\n",
    "    ###################################################################\n",
    "    # Implement the skip-gram model in this function.                 #         \n",
    "    # Inputs:                                                         #\n",
    "    #   - currrentWord: a string of the current center word           #\n",
    "    #   - C: integer, context size                                    #\n",
    "    #   - contextWords: list of no more than 2*C strings, the context #\n",
    "    #             words                                               #\n",
    "    #   - tokens: a dictionary that maps words to their indices in    #\n",
    "    #             the word vector list                                #\n",
    "    #   - inputVectors: \"input\" word vectors for all tokens           #\n",
    "    #   - outputVectors: \"output\" word vectors for all tokens         #\n",
    "    #   - word2vecCostAndGradient: the cost and gradient function for #\n",
    "    #             a prediction vector given the target word vectors,  #\n",
    "    #             could be one of the two cost functions you          #\n",
    "    #             implemented above                                   #\n",
    "    # Outputs:                                                        #\n",
    "    #   - cost: the cost function value for the skip-gram model       #\n",
    "    #   - grad: the gradient with respect to the word vectors         #\n",
    "    # We will not provide starter code for this function, but feel    #\n",
    "    # free to reference the code you previously wrote for this        #\n",
    "    # assignment!                                                     #\n",
    "    ###################################################################\n",
    "    \n",
    "    ### YOUR CODE HERE\n",
    "    cost = 0\n",
    "    gradIn = np.zeros_like(inputVectors)\n",
    "    gradOut = np.zeros_like(outputVectors)\n",
    "    \n",
    "    idx = tokens[currentWord]\n",
    "    predicted = inputVectors[idx, :]\n",
    "    for word in contextWords:\n",
    "        target = tokens[word]\n",
    "        c, gPred, grad = word2vecCostAndGradient(predicted, target, outputVectors)\n",
    "        cost += c\n",
    "        gradIn[idx, :] += gPred\n",
    "        gradOut += grad\n",
    "    #print cost, gradIn, gradOut\n",
    "    ### END YOUR CODE\n",
    "    \n",
    "    return cost, gradIn, gradOut\n",
    "\n",
    "def cbow(currentWord, C, contextWords, tokens, inputVectors, outputVectors, word2vecCostAndGradient = softmaxCostAndGradient):\n",
    "    \"\"\" CBOW model in word2vec \"\"\"\n",
    "    ###################################################################\n",
    "    # Implement the continuous bag-of-words model in this function.   #         \n",
    "    # Input/Output specifications: same as the skip-gram model        #\n",
    "    # We will not provide starter code for this function, but feel    #\n",
    "    # free to reference the code you previously wrote for this        #\n",
    "    # assignment!                                                     #\n",
    "    ###################################################################\n",
    "    \n",
    "    ### YOUR CODE HERE\n",
    "    gradIn = np.zeros_like(inputVectors)\n",
    "    \n",
    "    target = tokens[currentWord]\n",
    "    sumContext = np.sum(inputVectors[[tokens[cw] for cw in contextWords],:], axis=0)\n",
    "    cost, gradPred, gradOut = word2vecCostAndGradient(sumContext, target, outputVectors)\n",
    "    for cw in contextWords:\n",
    "        gradIn[tokens[cw],:] += gradPred\n",
    "    ### END YOUR CODE\n",
    "    \n",
    "    return cost, gradIn, gradOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== For autograder ===\n",
      "[[ 0.6         0.8       ]\n",
      " [ 0.4472136   0.89442719]]\n",
      "[ 0.6  0.8]\n"
     ]
    }
   ],
   "source": [
    "# Implement a function that normalizes each row of a matrix to have unit length\n",
    "def normalizeRows(x):\n",
    "    \"\"\" Row normalization function \"\"\"\n",
    "    \n",
    "    ### YOUR CODE HERE\n",
    "    x = x.T\n",
    "    sum_row = np.sum(x**2,axis=0)\n",
    "    x = x/(sum_row**0.5)\n",
    "    x = x.T\n",
    "    ### END YOUR CODE\n",
    "    \n",
    "    return x\n",
    "\n",
    "# Test this function\n",
    "print \"=== For autograder ===\"\n",
    "print normalizeRows(np.array([[3.0,4.0],[1, 2]]))  # the result should be [[0.6, 0.8], [0.4472, 0.8944]]\n",
    "print normalizeRows(np.array([3.0,4.0]))  # the result should be [[0.6, 0.8], [0.4472, 0.8944]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Gradient check for skip-gram ====\n",
      "Gradient check passed!\n",
      "Wall time: 3.04 s\n",
      "Gradient check passed!\n",
      "Wall time: 14.7 s\n",
      "\n",
      "==== Gradient check for CBOW      ====\n",
      "Gradient check passed!\n",
      "Wall time: 1.75 s\n",
      "Gradient check passed!\n",
      "Wall time: 3.73 s\n",
      "\n",
      "=== For autograder ===\n",
      "(11.166109001533981, array([[ 0.        ,  0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        ],\n",
      "       [-1.26947339, -1.36873189,  2.45158957],\n",
      "       [ 0.        ,  0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        ]]), array([[-0.41045956,  0.18834851,  1.43272264],\n",
      "       [ 0.38202831, -0.17530219, -1.33348241],\n",
      "       [ 0.07009355, -0.03216399, -0.24466386],\n",
      "       [ 0.09472154, -0.04346509, -0.33062865],\n",
      "       [-0.13638384,  0.06258276,  0.47605228]]))\n",
      "(14.095272649623695, array([[ 0.        ,  0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        ],\n",
      "       [-3.40325278, -2.74731195, -0.95360761],\n",
      "       [ 0.        ,  0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        ]]), array([[-0.49853822,  0.22876535,  1.74016407],\n",
      "       [-0.22716495,  0.10423969,  0.79292674],\n",
      "       [-0.22764219,  0.10445868,  0.79459256],\n",
      "       [-0.94807832,  0.43504684,  3.30929863],\n",
      "       [-0.32248118,  0.14797767,  1.1256312 ]]))\n",
      "(0.79899580109066481, array([[ 0.23330542, -0.51643128, -0.8281311 ],\n",
      "       [ 0.11665271, -0.25821564, -0.41406555],\n",
      "       [ 0.11665271, -0.25821564, -0.41406555],\n",
      "       [ 0.        ,  0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        ]]), array([[ 0.80954933,  0.21962514, -0.54095764],\n",
      "       [-0.03556575, -0.00964874,  0.02376577],\n",
      "       [-0.13016109, -0.0353118 ,  0.08697634],\n",
      "       [-0.1650812 , -0.04478539,  0.11031068],\n",
      "       [-0.47874129, -0.1298792 ,  0.31990485]]))\n",
      "(12.312796216098871, array([[-5.99665734, -4.85531835,  2.30742523],\n",
      "       [-2.99832867, -2.42765918,  1.15371261],\n",
      "       [-2.99832867, -2.42765918,  1.15371261],\n",
      "       [ 0.        ,  0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        ]]), array([[-3.53424992, -0.95881757,  2.36165904],\n",
      "       [-0.68912523, -0.18695491,  0.46048776],\n",
      "       [ 0.        ,  0.        ,  0.        ],\n",
      "       [-2.58955401, -0.7025281 ,  1.73039366],\n",
      "       [-2.36749007, -0.64228369,  1.58200593]]))\n"
     ]
    }
   ],
   "source": [
    "# Gradient check!\n",
    "\n",
    "def word2vec_sgd_wrapper(word2vecModel, tokens, wordVectors, dataset, C, word2vecCostAndGradient = softmaxCostAndGradient):\n",
    "    batchsize = 50\n",
    "    cost = 0.0\n",
    "    grad = np.zeros(wordVectors.shape)\n",
    "    N = wordVectors.shape[0]\n",
    "    inputVectors = wordVectors[:N/2,:]\n",
    "    outputVectors = wordVectors[N/2:,:]\n",
    "    for i in xrange(batchsize):\n",
    "        C1 = random.randint(1,C)\n",
    "        centerword, context = dataset.getRandomContext(C1)\n",
    "        \n",
    "        if word2vecModel == skipgram:\n",
    "            denom = 1\n",
    "        else:\n",
    "            denom = 1\n",
    "        \n",
    "        c, gin, gout = word2vecModel(centerword, C1, context, tokens, inputVectors, outputVectors, word2vecCostAndGradient)        \n",
    "        cost += c / batchsize / denom\n",
    "        grad[:N/2, :] += gin / batchsize / denom\n",
    "        grad[N/2:, :] += gout / batchsize / denom\n",
    "        \n",
    "    return cost, grad\n",
    "\n",
    "random.seed(31415)\n",
    "np.random.seed(9265)\n",
    "dummy_vectors = normalizeRows(np.random.randn(10,3))\n",
    "dummy_tokens = dict([(\"a\",0), (\"b\",1), (\"c\",2),(\"d\",3),(\"e\",4)])\n",
    "print \"==== Gradient check for skip-gram ====\"\n",
    "%time gradcheck_naive(lambda vec: word2vec_sgd_wrapper(skipgram, dummy_tokens, vec, dataset, 5), dummy_vectors)\n",
    "%time gradcheck_naive(lambda vec: word2vec_sgd_wrapper(skipgram, dummy_tokens, vec, dataset, 5, negSamplingCostAndGradient), dummy_vectors)\n",
    "print \"\\n==== Gradient check for CBOW      ====\"\n",
    "%time gradcheck_naive(lambda vec: word2vec_sgd_wrapper(cbow, dummy_tokens, vec, dataset, 5), dummy_vectors)\n",
    "%time gradcheck_naive(lambda vec: word2vec_sgd_wrapper(cbow, dummy_tokens, vec, dataset, 5, negSamplingCostAndGradient), dummy_vectors)\n",
    "\n",
    "print \"\\n=== For autograder ===\"\n",
    "print skipgram(\"c\", 3, [\"a\", \"b\", \"e\", \"d\", \"b\", \"c\"], dummy_tokens, dummy_vectors[:5,:], dummy_vectors[5:,:])\n",
    "print skipgram(\"c\", 1, [\"a\", \"b\"], dummy_tokens, dummy_vectors[:5,:], dummy_vectors[5:,:], negSamplingCostAndGradient)\n",
    "print cbow(\"a\", 2, [\"a\", \"b\", \"c\", \"a\"], dummy_tokens, dummy_vectors[:5,:], dummy_vectors[5:,:])\n",
    "print cbow(\"a\", 2, [\"a\", \"b\", \"a\", \"c\"], dummy_tokens, dummy_vectors[:5,:], dummy_vectors[5:,:], negSamplingCostAndGradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now, implement SGD\n",
    "\n",
    "# Save parameters every a few SGD iterations as fail-safe\n",
    "SAVE_PARAMS_EVERY = 1000\n",
    "\n",
    "import glob\n",
    "import os.path as op\n",
    "import cPickle as pickle\n",
    "\n",
    "def load_saved_params():\n",
    "    \"\"\" A helper function that loads previously saved parameters and resets iteration start \"\"\"\n",
    "    st = 0\n",
    "    for f in glob.glob(\"saved_params_*.npy\"):\n",
    "        iter = int(op.splitext(op.basename(f))[0].split(\"_\")[2])\n",
    "        if (iter > st):\n",
    "            st = iter\n",
    "            \n",
    "    if st > 0:\n",
    "        with open(\"saved_params_%d.npy\" % st, \"r\") as f:\n",
    "            params = pickle.load(f)\n",
    "            state = pickle.load(f)\n",
    "        return st, params, state\n",
    "    else:\n",
    "        return st, None, None\n",
    "    \n",
    "def save_params(iter, params):\n",
    "    with open(\"saved_params_%d.npy\" % iter, \"w\") as f:\n",
    "        pickle.dump(params, f)\n",
    "        pickle.dump(random.getstate(), f)\n",
    "\n",
    "def sgd(f, x0, step, iterations, postprocessing = None, useSaved = False, PRINT_EVERY=10):\n",
    "    \"\"\" Stochastic Gradient Descent \"\"\"\n",
    "    ###################################################################\n",
    "    # Implement the stochastic gradient descent method in this        #\n",
    "    # function.                                                       #\n",
    "    # Inputs:                                                         #\n",
    "    #   - f: the function to optimize, it should take a single        #\n",
    "    #        argument and yield two outputs, a cost and the gradient  #\n",
    "    #        with respect to the arguments                            #\n",
    "    #   - x0: the initial point to start SGD from                     #\n",
    "    #   - step: the step size for SGD                                 #\n",
    "    #   - iterations: total iterations to run SGD for                 #\n",
    "    #   - postprocessing: postprocessing function for the parameters  #\n",
    "    #        if necessary. In the case of word2vec we will need to    #\n",
    "    #        normalize the word vectors to have unit length.          #\n",
    "    #   - PRINT_EVERY: specifies every how many iterations to output  #\n",
    "    # Output:                                                         #\n",
    "    #   - x: the parameter value after SGD finishes                   #\n",
    "    ###################################################################\n",
    "    \n",
    "    # Anneal learning rate every several iterations\n",
    "    ANNEAL_EVERY = 20000\n",
    "    \n",
    "    if useSaved:\n",
    "        start_iter, oldx, state = load_saved_params()\n",
    "        if start_iter > 0:\n",
    "            x0 = oldx;\n",
    "            step *= 0.5 ** (start_iter / ANNEAL_EVERY)\n",
    "            \n",
    "        if state:\n",
    "            random.setstate(state)\n",
    "    else:\n",
    "        start_iter = 0\n",
    "    \n",
    "    x = x0\n",
    "    \n",
    "    if not postprocessing:\n",
    "        postprocessing = lambda x: x\n",
    "    \n",
    "    expcost = None\n",
    "    \n",
    "    for iter in xrange(start_iter + 1, iterations + 1):\n",
    "        ### YOUR CODE HERE\n",
    "        ### Don't forget to apply the postprocessing after every iteration!\n",
    "        ### You might want to print the progress every few iterations.\n",
    "        cost, grad = f(x)\n",
    "        x -= step*grad\n",
    "        x = postprocessing(x)\n",
    "        if iter % PRINT_EVERY == 0:\n",
    "            print \"After %sth iteration, cost function is %s\" % (iter, cost)\n",
    "        ### END YOUR CODE\n",
    "        \n",
    "        if iter % SAVE_PARAMS_EVERY == 0 and useSaved:\n",
    "            save_params(iter, x)\n",
    "            \n",
    "        if iter % ANNEAL_EVERY == 0:\n",
    "            step *= 0.5\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Show time! Now we are going to load some real data and train word vectors with everything you just implemented!**\n",
    "\n",
    "We are going to use the Stanford Sentiment Treebank (SST) dataset to train word vectors, and later apply them to a simple sentiment analysis task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load some data and initialize word vectors\n",
    "\n",
    "# Reset the random seed to make sure that everyone gets the same results\n",
    "random.seed(314)\n",
    "dataset = StanfordSentiment()\n",
    "tokens = dataset.tokens()\n",
    "nWords = len(tokens)\n",
    "\n",
    "# We are going to train 10-dimensional vectors for this assignment\n",
    "dimVectors = 10\n",
    "\n",
    "# Context size\n",
    "C = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 18010th iteration, cost function is 10.6431753746\n",
      "After 18020th iteration, cost function is 9.48896057127\n",
      "After 18030th iteration, cost function is 11.7614863835\n",
      "After 18040th iteration, cost function is 11.2348366126\n",
      "After 18050th iteration, cost function is 10.2873108814\n",
      "After 18060th iteration, cost function is 9.23682105167\n",
      "After 18070th iteration, cost function is 10.9761933599\n",
      "After 18080th iteration, cost function is 10.9713709486\n",
      "After 18090th iteration, cost function is 10.9831636582\n",
      "After 18100th iteration, cost function is 11.0263744611\n",
      "After 18110th iteration, cost function is 7.76731330207\n",
      "After 18120th iteration, cost function is 9.78522945109\n",
      "After 18130th iteration, cost function is 10.7192051237\n",
      "After 18140th iteration, cost function is 9.908739917\n",
      "After 18150th iteration, cost function is 9.88254884001\n",
      "After 18160th iteration, cost function is 10.098293025\n",
      "After 18170th iteration, cost function is 9.89296196663\n",
      "After 18180th iteration, cost function is 9.60409375779\n",
      "After 18190th iteration, cost function is 11.3507585722\n",
      "After 18200th iteration, cost function is 9.39697529253\n",
      "After 18210th iteration, cost function is 9.64229861039\n",
      "After 18220th iteration, cost function is 9.86813391139\n",
      "After 18230th iteration, cost function is 10.420057573\n",
      "After 18240th iteration, cost function is 9.67715287389\n",
      "After 18250th iteration, cost function is 11.7739837987\n",
      "After 18260th iteration, cost function is 9.47668994835\n",
      "After 18270th iteration, cost function is 9.70890969555\n",
      "After 18280th iteration, cost function is 9.98366933634\n",
      "After 18290th iteration, cost function is 12.2901057886\n",
      "After 18300th iteration, cost function is 10.0779616073\n",
      "After 18310th iteration, cost function is 11.3643439196\n",
      "After 18320th iteration, cost function is 11.9820480548\n",
      "After 18330th iteration, cost function is 9.88419002657\n",
      "After 18340th iteration, cost function is 10.5315055812\n",
      "After 18350th iteration, cost function is 10.6418758183\n",
      "After 18360th iteration, cost function is 10.1985485347\n",
      "After 18370th iteration, cost function is 8.4116893808\n",
      "After 18380th iteration, cost function is 11.1869632633\n",
      "After 18390th iteration, cost function is 11.4174964986\n",
      "After 18400th iteration, cost function is 10.4606672171\n",
      "After 18410th iteration, cost function is 8.78140932718\n",
      "After 18420th iteration, cost function is 10.3423626773\n",
      "After 18430th iteration, cost function is 9.5654414441\n",
      "After 18440th iteration, cost function is 10.0736418712\n",
      "After 18450th iteration, cost function is 10.8318305579\n",
      "After 18460th iteration, cost function is 10.0809820153\n",
      "After 18470th iteration, cost function is 11.0692896497\n",
      "After 18480th iteration, cost function is 10.2726337615\n",
      "After 18490th iteration, cost function is 10.1331841159\n",
      "After 18500th iteration, cost function is 10.9465275379\n",
      "After 18510th iteration, cost function is 10.1868041749\n",
      "After 18520th iteration, cost function is 9.31909125903\n",
      "After 18530th iteration, cost function is 9.58366457582\n",
      "After 18540th iteration, cost function is 11.7053400429\n",
      "After 18550th iteration, cost function is 9.69681803118\n",
      "After 18560th iteration, cost function is 11.0717022357\n",
      "After 18570th iteration, cost function is 9.64221481402\n",
      "After 18580th iteration, cost function is 10.2123442346\n",
      "After 18590th iteration, cost function is 10.2150068614\n",
      "After 18600th iteration, cost function is 9.89609323396\n",
      "After 18610th iteration, cost function is 10.5012198742\n",
      "After 18620th iteration, cost function is 8.92098610063\n",
      "After 18630th iteration, cost function is 10.9546242607\n",
      "After 18640th iteration, cost function is 10.0060473936\n",
      "After 18650th iteration, cost function is 10.3286239555\n",
      "After 18660th iteration, cost function is 10.5957558333\n",
      "After 18670th iteration, cost function is 10.2180904802\n",
      "After 18680th iteration, cost function is 9.6473843167\n",
      "After 18690th iteration, cost function is 10.1897816891\n",
      "After 18700th iteration, cost function is 9.64816447821\n",
      "After 18710th iteration, cost function is 10.0294506873\n",
      "After 18720th iteration, cost function is 9.82527904817\n",
      "After 18730th iteration, cost function is 10.4418499365\n",
      "After 18740th iteration, cost function is 10.2738128422\n",
      "After 18750th iteration, cost function is 9.76922405057\n",
      "After 18760th iteration, cost function is 8.57634498717\n",
      "After 18770th iteration, cost function is 10.724969365\n",
      "After 18780th iteration, cost function is 9.61992832765\n",
      "After 18790th iteration, cost function is 8.61284313535\n",
      "After 18800th iteration, cost function is 9.79672550261\n",
      "After 18810th iteration, cost function is 10.9783260669\n",
      "After 18820th iteration, cost function is 10.6264024358\n",
      "After 18830th iteration, cost function is 10.3544508232\n",
      "After 18840th iteration, cost function is 9.65143708091\n",
      "After 18850th iteration, cost function is 10.7743893387\n",
      "After 18860th iteration, cost function is 11.2333457117\n",
      "After 18870th iteration, cost function is 9.66326365506\n",
      "After 18880th iteration, cost function is 9.85351887991\n",
      "After 18890th iteration, cost function is 9.73623310101\n",
      "After 18900th iteration, cost function is 11.4155080239\n",
      "After 18910th iteration, cost function is 8.34655853669\n",
      "After 18920th iteration, cost function is 10.2039006186\n",
      "After 18930th iteration, cost function is 9.79770256484\n",
      "After 18940th iteration, cost function is 10.5677535961\n",
      "After 18950th iteration, cost function is 10.0246428664\n",
      "After 18960th iteration, cost function is 12.0531238204\n",
      "After 18970th iteration, cost function is 11.8416150948\n",
      "After 18980th iteration, cost function is 10.7833758176\n",
      "After 18990th iteration, cost function is 9.66909845316\n",
      "After 19000th iteration, cost function is 8.56715365533\n",
      "After 19010th iteration, cost function is 11.4610523232\n",
      "After 19020th iteration, cost function is 9.64165373192\n",
      "After 19030th iteration, cost function is 11.6052893552\n",
      "After 19040th iteration, cost function is 10.17629107\n",
      "After 19050th iteration, cost function is 9.77389583532\n",
      "After 19060th iteration, cost function is 10.2358207723\n",
      "After 19070th iteration, cost function is 10.6907821363\n",
      "After 19080th iteration, cost function is 10.6952370405\n",
      "After 19090th iteration, cost function is 10.1095211017\n",
      "After 19100th iteration, cost function is 10.5144159911\n",
      "After 19110th iteration, cost function is 9.55376884007\n",
      "After 19120th iteration, cost function is 10.5639939773\n",
      "After 19130th iteration, cost function is 11.6722049691\n",
      "After 19140th iteration, cost function is 10.2505550428\n",
      "After 19150th iteration, cost function is 10.6736059475\n",
      "After 19160th iteration, cost function is 10.6210483793\n",
      "After 19170th iteration, cost function is 10.6595672156\n",
      "After 19180th iteration, cost function is 9.00092618621\n",
      "After 19190th iteration, cost function is 12.093315273\n",
      "After 19200th iteration, cost function is 8.93681473595\n",
      "After 19210th iteration, cost function is 10.7538405907\n",
      "After 19220th iteration, cost function is 9.46437523053\n",
      "After 19230th iteration, cost function is 9.63216953161\n",
      "After 19240th iteration, cost function is 9.83128062485\n",
      "After 19250th iteration, cost function is 10.704439376\n",
      "After 19260th iteration, cost function is 10.5876006555\n",
      "After 19270th iteration, cost function is 9.52347234779\n",
      "After 19280th iteration, cost function is 10.7486349037\n",
      "After 19290th iteration, cost function is 10.3954624576\n",
      "After 19300th iteration, cost function is 9.10788504213\n",
      "After 19310th iteration, cost function is 9.44068747767\n",
      "After 19320th iteration, cost function is 11.1636324531\n",
      "After 19330th iteration, cost function is 11.6262074428\n",
      "After 19340th iteration, cost function is 11.4420423637\n",
      "After 19350th iteration, cost function is 9.95220677407\n",
      "After 19360th iteration, cost function is 9.90337045785\n",
      "After 19370th iteration, cost function is 11.1747242308\n",
      "After 19380th iteration, cost function is 10.9455367605\n",
      "After 19390th iteration, cost function is 9.9586716415\n",
      "After 19400th iteration, cost function is 10.0896329421\n",
      "After 19410th iteration, cost function is 9.98801773638\n",
      "After 19420th iteration, cost function is 10.6589705128\n",
      "After 19430th iteration, cost function is 8.67150203056\n",
      "After 19440th iteration, cost function is 9.05822001796\n",
      "After 19450th iteration, cost function is 10.0661022252\n",
      "After 19460th iteration, cost function is 10.5005387578\n",
      "After 19470th iteration, cost function is 11.0585911472\n",
      "After 19480th iteration, cost function is 9.39857829259\n",
      "After 19490th iteration, cost function is 11.0913733638\n",
      "After 19500th iteration, cost function is 8.65530012063\n",
      "After 19510th iteration, cost function is 10.3064596846\n",
      "After 19520th iteration, cost function is 10.9020183608\n",
      "After 19530th iteration, cost function is 9.36106614631\n",
      "After 19540th iteration, cost function is 11.0061450864\n",
      "After 19550th iteration, cost function is 10.3236936632\n",
      "After 19560th iteration, cost function is 9.90491662672\n",
      "After 19570th iteration, cost function is 7.9027266139\n",
      "After 19580th iteration, cost function is 11.2594247668\n",
      "After 19590th iteration, cost function is 10.8786457646\n",
      "After 19600th iteration, cost function is 10.7628325072\n",
      "After 19610th iteration, cost function is 9.34841668052\n",
      "After 19620th iteration, cost function is 11.5038857195\n",
      "After 19630th iteration, cost function is 10.2227808802\n",
      "After 19640th iteration, cost function is 9.57686878949\n",
      "After 19650th iteration, cost function is 11.0795751922\n",
      "After 19660th iteration, cost function is 10.9910738087\n",
      "After 19670th iteration, cost function is 10.9453232359\n",
      "After 19680th iteration, cost function is 10.6223319365\n",
      "After 19690th iteration, cost function is 9.6896889336\n",
      "After 19700th iteration, cost function is 9.28830692381\n",
      "After 19710th iteration, cost function is 11.1654866902\n",
      "After 19720th iteration, cost function is 11.1916050773\n",
      "After 19730th iteration, cost function is 9.62961917009\n",
      "After 19740th iteration, cost function is 9.57814388461\n",
      "After 19750th iteration, cost function is 9.86467111604\n",
      "After 19760th iteration, cost function is 9.53431408337\n",
      "After 19770th iteration, cost function is 9.62645920829\n",
      "After 19780th iteration, cost function is 10.0781686099\n",
      "After 19790th iteration, cost function is 11.3475265038\n",
      "After 19800th iteration, cost function is 9.5304665753\n",
      "After 19810th iteration, cost function is 9.15195016307\n",
      "After 19820th iteration, cost function is 9.29689085993\n",
      "After 19830th iteration, cost function is 9.79440118389\n",
      "After 19840th iteration, cost function is 11.9820326829\n",
      "After 19850th iteration, cost function is 9.68158892522\n",
      "After 19860th iteration, cost function is 9.24301643784\n",
      "After 19870th iteration, cost function is 10.5633934227\n",
      "After 19880th iteration, cost function is 11.7960114656\n",
      "After 19890th iteration, cost function is 9.74220098513\n",
      "After 19900th iteration, cost function is 9.18742599133\n",
      "After 19910th iteration, cost function is 10.9050503338\n",
      "After 19920th iteration, cost function is 10.8002260497\n",
      "After 19930th iteration, cost function is 10.9271036862\n",
      "After 19940th iteration, cost function is 8.52432829009\n",
      "After 19950th iteration, cost function is 11.2744946329\n",
      "After 19960th iteration, cost function is 10.5193748808\n",
      "After 19970th iteration, cost function is 7.87617053198\n",
      "After 19980th iteration, cost function is 9.52277515683\n",
      "After 19990th iteration, cost function is 10.5607873347\n",
      "After 20000th iteration, cost function is 9.73464469412\n",
      "After 20010th iteration, cost function is 10.5200318447\n",
      "After 20020th iteration, cost function is 10.7968421693\n",
      "After 20030th iteration, cost function is 10.3637616427\n",
      "After 20040th iteration, cost function is 10.2935982772\n",
      "After 20050th iteration, cost function is 9.26181118275\n",
      "After 20060th iteration, cost function is 12.5665684691\n",
      "After 20070th iteration, cost function is 9.66631015676\n",
      "After 20080th iteration, cost function is 10.5080037516\n",
      "After 20090th iteration, cost function is 10.9461136249\n",
      "After 20100th iteration, cost function is 10.9931625425\n",
      "After 20110th iteration, cost function is 10.5313629552\n",
      "After 20120th iteration, cost function is 10.1934032065\n",
      "After 20130th iteration, cost function is 9.46292013422\n",
      "After 20140th iteration, cost function is 8.33433744941\n",
      "After 20150th iteration, cost function is 10.1367519478\n",
      "After 20160th iteration, cost function is 9.61370401096\n",
      "After 20170th iteration, cost function is 9.51250964999\n",
      "After 20180th iteration, cost function is 9.94271343038\n",
      "After 20190th iteration, cost function is 9.29960652574\n",
      "After 20200th iteration, cost function is 10.9830474833\n",
      "After 20210th iteration, cost function is 10.341161828\n",
      "After 20220th iteration, cost function is 10.7443315976\n",
      "After 20230th iteration, cost function is 9.79023652543\n",
      "After 20240th iteration, cost function is 8.95884976973\n",
      "After 20250th iteration, cost function is 9.60283410341\n",
      "After 20260th iteration, cost function is 9.22331910153\n",
      "After 20270th iteration, cost function is 9.91283042538\n",
      "After 20280th iteration, cost function is 11.2679952357\n",
      "After 20290th iteration, cost function is 9.21821152525\n",
      "After 20300th iteration, cost function is 9.55022232687\n",
      "After 20310th iteration, cost function is 11.3908027131\n",
      "After 20320th iteration, cost function is 10.9885886277\n",
      "After 20330th iteration, cost function is 9.08067887149\n",
      "After 20340th iteration, cost function is 11.0500200173\n",
      "After 20350th iteration, cost function is 11.3541714022\n",
      "After 20360th iteration, cost function is 10.4773826002\n",
      "After 20370th iteration, cost function is 10.016823752\n",
      "After 20380th iteration, cost function is 8.49920168077\n",
      "After 20390th iteration, cost function is 8.6609326522\n",
      "After 20400th iteration, cost function is 9.48919599558\n",
      "After 20410th iteration, cost function is 10.6654553318\n",
      "After 20420th iteration, cost function is 10.4163314032\n",
      "After 20430th iteration, cost function is 9.34226955527\n",
      "After 20440th iteration, cost function is 9.81131633377\n",
      "After 20450th iteration, cost function is 9.86317319662\n",
      "After 20460th iteration, cost function is 10.9947248534\n",
      "After 20470th iteration, cost function is 9.16473229048\n",
      "After 20480th iteration, cost function is 10.5412341552\n",
      "After 20490th iteration, cost function is 10.3693891506\n",
      "After 20500th iteration, cost function is 10.3557376281\n",
      "After 20510th iteration, cost function is 10.9249906215\n",
      "After 20520th iteration, cost function is 10.0977917108\n",
      "After 20530th iteration, cost function is 9.57992719799\n",
      "After 20540th iteration, cost function is 9.36666109134\n",
      "After 20550th iteration, cost function is 8.69213243774\n",
      "After 20560th iteration, cost function is 10.079194374\n",
      "After 20570th iteration, cost function is 10.090881107\n",
      "After 20580th iteration, cost function is 11.2333513924\n",
      "After 20590th iteration, cost function is 9.98375518561\n",
      "After 20600th iteration, cost function is 8.39419785534\n",
      "After 20610th iteration, cost function is 10.1663410997\n",
      "After 20620th iteration, cost function is 9.61185143626\n",
      "After 20630th iteration, cost function is 9.7931396834\n",
      "After 20640th iteration, cost function is 10.1231941966\n",
      "After 20650th iteration, cost function is 9.7634427419\n",
      "After 20660th iteration, cost function is 9.73747887203\n",
      "After 20670th iteration, cost function is 10.63668988\n",
      "After 20680th iteration, cost function is 11.6916780219\n",
      "After 20690th iteration, cost function is 10.6630448444\n",
      "After 20700th iteration, cost function is 10.1131720814\n",
      "After 20710th iteration, cost function is 10.5974101792\n",
      "After 20720th iteration, cost function is 10.7575483349\n",
      "After 20730th iteration, cost function is 9.02547063414\n",
      "After 20740th iteration, cost function is 9.3262229782\n",
      "After 20750th iteration, cost function is 8.99820662247\n",
      "After 20760th iteration, cost function is 9.63049691765\n",
      "After 20770th iteration, cost function is 10.5325027344\n",
      "After 20780th iteration, cost function is 10.1137823462\n",
      "After 20790th iteration, cost function is 10.6914944904\n",
      "After 20800th iteration, cost function is 8.94049291037\n",
      "After 20810th iteration, cost function is 10.712916617\n",
      "After 20820th iteration, cost function is 10.9952853938\n",
      "After 20830th iteration, cost function is 10.8289556807\n",
      "After 20840th iteration, cost function is 9.80541821818\n",
      "After 20850th iteration, cost function is 9.16178035332\n",
      "After 20860th iteration, cost function is 8.64075762864\n",
      "After 20870th iteration, cost function is 10.2885041727\n",
      "After 20880th iteration, cost function is 10.4997465329\n",
      "After 20890th iteration, cost function is 9.93097972389\n",
      "After 20900th iteration, cost function is 8.93025575935\n",
      "After 20910th iteration, cost function is 10.3209662945\n",
      "After 20920th iteration, cost function is 10.2395808492\n",
      "After 20930th iteration, cost function is 9.04221583617\n",
      "After 20940th iteration, cost function is 9.6686753199\n",
      "After 20950th iteration, cost function is 10.1492905889\n",
      "After 20960th iteration, cost function is 9.04335713195\n",
      "After 20970th iteration, cost function is 10.3616399702\n",
      "After 20980th iteration, cost function is 9.84488506171\n",
      "After 20990th iteration, cost function is 10.0572878967\n",
      "After 21000th iteration, cost function is 11.015238426\n",
      "After 21010th iteration, cost function is 8.44662334987\n",
      "After 21020th iteration, cost function is 10.4514817319\n",
      "After 21030th iteration, cost function is 9.36511637994\n",
      "After 21040th iteration, cost function is 10.1042096865\n",
      "After 21050th iteration, cost function is 10.7468669263\n",
      "After 21060th iteration, cost function is 9.05813584876\n",
      "After 21070th iteration, cost function is 10.2508745297\n",
      "After 21080th iteration, cost function is 10.330579435\n",
      "After 21090th iteration, cost function is 9.93592118977\n",
      "After 21100th iteration, cost function is 10.0436702934\n",
      "After 21110th iteration, cost function is 10.2024390488\n",
      "After 21120th iteration, cost function is 8.91328059004\n",
      "After 21130th iteration, cost function is 10.2984000973\n",
      "After 21140th iteration, cost function is 10.7098942894\n",
      "After 21150th iteration, cost function is 10.3068336466\n",
      "After 21160th iteration, cost function is 9.88657077906\n",
      "After 21170th iteration, cost function is 8.98691562876\n",
      "After 21180th iteration, cost function is 10.5433667343\n",
      "After 21190th iteration, cost function is 9.64129746749\n",
      "After 21200th iteration, cost function is 10.660915176\n",
      "After 21210th iteration, cost function is 9.27760731021\n",
      "After 21220th iteration, cost function is 10.5034749749\n",
      "After 21230th iteration, cost function is 10.9596707289\n",
      "After 21240th iteration, cost function is 9.9047691287\n",
      "After 21250th iteration, cost function is 10.0256792419\n",
      "After 21260th iteration, cost function is 11.2308229594\n",
      "After 21270th iteration, cost function is 10.650553776\n",
      "After 21280th iteration, cost function is 8.79498914331\n",
      "After 21290th iteration, cost function is 9.48676840649\n",
      "After 21300th iteration, cost function is 10.170604111\n",
      "After 21310th iteration, cost function is 11.8424009847\n",
      "After 21320th iteration, cost function is 9.8720525088\n",
      "After 21330th iteration, cost function is 10.4939463048\n",
      "After 21340th iteration, cost function is 9.01028346746\n",
      "After 21350th iteration, cost function is 10.8946868859\n",
      "After 21360th iteration, cost function is 9.17514226023\n",
      "After 21370th iteration, cost function is 10.4265875984\n",
      "After 21380th iteration, cost function is 8.15558480369\n",
      "After 21390th iteration, cost function is 8.28789578197\n",
      "After 21400th iteration, cost function is 11.7543997958\n",
      "After 21410th iteration, cost function is 9.46959145407\n",
      "After 21420th iteration, cost function is 11.4594955924\n",
      "After 21430th iteration, cost function is 10.4429992369\n",
      "After 21440th iteration, cost function is 9.53257953256\n",
      "After 21450th iteration, cost function is 11.6917552601\n",
      "After 21460th iteration, cost function is 8.36790155713\n",
      "After 21470th iteration, cost function is 9.75658821675\n",
      "After 21480th iteration, cost function is 10.2014928342\n",
      "After 21490th iteration, cost function is 10.6461216136\n",
      "After 21500th iteration, cost function is 10.0697042764\n",
      "After 21510th iteration, cost function is 10.063401921\n",
      "After 21520th iteration, cost function is 9.68577823813\n",
      "After 21530th iteration, cost function is 9.08994853049\n",
      "After 21540th iteration, cost function is 9.12506783566\n",
      "After 21550th iteration, cost function is 9.96951584801\n",
      "After 21560th iteration, cost function is 10.6032433717\n",
      "After 21570th iteration, cost function is 9.48788406719\n",
      "After 21580th iteration, cost function is 9.26810050886\n",
      "After 21590th iteration, cost function is 10.0099755712\n",
      "After 21600th iteration, cost function is 10.4018581549\n",
      "After 21610th iteration, cost function is 10.669006453\n",
      "After 21620th iteration, cost function is 9.8564814702\n",
      "After 21630th iteration, cost function is 8.40321514038\n",
      "After 21640th iteration, cost function is 10.0433657252\n",
      "After 21650th iteration, cost function is 9.73986846599\n",
      "After 21660th iteration, cost function is 9.52663706221\n",
      "After 21670th iteration, cost function is 10.6247882324\n",
      "After 21680th iteration, cost function is 10.2300535151\n",
      "After 21690th iteration, cost function is 10.6030691203\n",
      "After 21700th iteration, cost function is 9.0094160477\n",
      "After 21710th iteration, cost function is 9.94358552008\n",
      "After 21720th iteration, cost function is 8.76621548335\n",
      "After 21730th iteration, cost function is 10.7927930709\n",
      "After 21740th iteration, cost function is 9.66764360788\n",
      "After 21750th iteration, cost function is 9.96780333375\n",
      "After 21760th iteration, cost function is 11.4136044604\n",
      "After 21770th iteration, cost function is 10.4547846509\n",
      "After 21780th iteration, cost function is 11.0712995169\n",
      "After 21790th iteration, cost function is 10.912325609\n",
      "After 21800th iteration, cost function is 9.01912094835\n",
      "After 21810th iteration, cost function is 9.15128968451\n",
      "After 21820th iteration, cost function is 10.4464715062\n",
      "After 21830th iteration, cost function is 10.3208555733\n",
      "After 21840th iteration, cost function is 8.47094164636\n",
      "After 21850th iteration, cost function is 10.5654122461\n",
      "After 21860th iteration, cost function is 9.77448940071\n",
      "After 21870th iteration, cost function is 9.66797209666\n",
      "After 21880th iteration, cost function is 9.81895767263\n",
      "After 21890th iteration, cost function is 9.30803447328\n",
      "After 21900th iteration, cost function is 11.3570569646\n",
      "After 21910th iteration, cost function is 12.4331659426\n",
      "After 21920th iteration, cost function is 10.2047176523\n",
      "After 21930th iteration, cost function is 11.3418413705\n",
      "After 21940th iteration, cost function is 11.553693741\n",
      "After 21950th iteration, cost function is 9.92995900329\n",
      "After 21960th iteration, cost function is 10.1615552461\n",
      "After 21970th iteration, cost function is 9.06288288439\n",
      "After 21980th iteration, cost function is 10.1698857258\n",
      "After 21990th iteration, cost function is 10.5847878475\n",
      "After 22000th iteration, cost function is 11.0346568444\n",
      "After 22010th iteration, cost function is 10.0067385159\n",
      "After 22020th iteration, cost function is 9.93338821214\n",
      "After 22030th iteration, cost function is 11.2933353241\n",
      "After 22040th iteration, cost function is 9.36806867665\n",
      "After 22050th iteration, cost function is 9.04639728568\n",
      "After 22060th iteration, cost function is 9.42946332157\n",
      "After 22070th iteration, cost function is 8.80114079774\n",
      "After 22080th iteration, cost function is 10.9705055052\n",
      "After 22090th iteration, cost function is 9.91860183866\n",
      "After 22100th iteration, cost function is 11.2699057376\n",
      "After 22110th iteration, cost function is 11.1156504304\n",
      "After 22120th iteration, cost function is 10.274969834\n",
      "After 22130th iteration, cost function is 10.168027955\n",
      "After 22140th iteration, cost function is 11.4610338765\n",
      "After 22150th iteration, cost function is 9.41176791404\n",
      "After 22160th iteration, cost function is 10.2581229352\n",
      "After 22170th iteration, cost function is 9.21976319446\n",
      "After 22180th iteration, cost function is 10.7767984606\n",
      "After 22190th iteration, cost function is 10.3313202149\n",
      "After 22200th iteration, cost function is 9.75373688377\n",
      "After 22210th iteration, cost function is 9.20480145932\n",
      "After 22220th iteration, cost function is 9.33793884947\n",
      "After 22230th iteration, cost function is 8.42388955374\n",
      "After 22240th iteration, cost function is 9.17455073823\n",
      "After 22250th iteration, cost function is 9.509340501\n",
      "After 22260th iteration, cost function is 10.2660917015\n",
      "After 22270th iteration, cost function is 10.1707310864\n",
      "After 22280th iteration, cost function is 9.62830165979\n",
      "After 22290th iteration, cost function is 8.93214156272\n",
      "After 22300th iteration, cost function is 10.9797257996\n",
      "After 22310th iteration, cost function is 8.57591129091\n",
      "After 22320th iteration, cost function is 10.723920574\n",
      "After 22330th iteration, cost function is 9.71275657333\n",
      "After 22340th iteration, cost function is 10.2550682751\n",
      "After 22350th iteration, cost function is 10.7196327588\n",
      "After 22360th iteration, cost function is 9.59783761238\n",
      "After 22370th iteration, cost function is 9.08484799142\n",
      "After 22380th iteration, cost function is 9.77815134363\n",
      "After 22390th iteration, cost function is 9.2940860962\n",
      "After 22400th iteration, cost function is 9.60157294068\n",
      "After 22410th iteration, cost function is 9.8891460895\n",
      "After 22420th iteration, cost function is 10.7604432169\n",
      "After 22430th iteration, cost function is 7.47747404589\n",
      "After 22440th iteration, cost function is 11.0767997295\n",
      "After 22450th iteration, cost function is 9.40358299774\n",
      "After 22460th iteration, cost function is 10.1177579037\n",
      "After 22470th iteration, cost function is 10.2410021663\n",
      "After 22480th iteration, cost function is 8.2287437583\n",
      "After 22490th iteration, cost function is 9.64349653028\n",
      "After 22500th iteration, cost function is 10.5986191511\n",
      "After 22510th iteration, cost function is 9.20937316477\n",
      "After 22520th iteration, cost function is 10.8201819117\n",
      "After 22530th iteration, cost function is 10.8718698109\n",
      "After 22540th iteration, cost function is 10.4961281473\n",
      "After 22550th iteration, cost function is 9.66347120055\n",
      "After 22560th iteration, cost function is 9.92030651752\n",
      "After 22570th iteration, cost function is 10.3703227122\n",
      "After 22580th iteration, cost function is 8.05837965336\n",
      "After 22590th iteration, cost function is 10.6502330872\n",
      "After 22600th iteration, cost function is 10.5223613596\n",
      "After 22610th iteration, cost function is 11.438291492\n",
      "After 22620th iteration, cost function is 10.078556243\n",
      "After 22630th iteration, cost function is 8.82905153092\n",
      "After 22640th iteration, cost function is 11.2397213127\n",
      "After 22650th iteration, cost function is 9.85087552364\n",
      "After 22660th iteration, cost function is 9.26646943578\n",
      "After 22670th iteration, cost function is 10.1704705759\n",
      "After 22680th iteration, cost function is 8.57531159923\n",
      "After 22690th iteration, cost function is 10.1894364783\n",
      "After 22700th iteration, cost function is 10.1169327243\n",
      "After 22710th iteration, cost function is 10.6007922058\n",
      "After 22720th iteration, cost function is 8.7131237139\n",
      "After 22730th iteration, cost function is 9.82707491528\n",
      "After 22740th iteration, cost function is 10.0730861682\n",
      "After 22750th iteration, cost function is 10.0684425109\n",
      "After 22760th iteration, cost function is 9.49054885297\n",
      "After 22770th iteration, cost function is 10.7139937464\n",
      "After 22780th iteration, cost function is 10.4667543051\n",
      "After 22790th iteration, cost function is 10.0446613453\n",
      "After 22800th iteration, cost function is 10.5015582679\n",
      "After 22810th iteration, cost function is 9.17301224499\n",
      "After 22820th iteration, cost function is 11.7287238061\n",
      "After 22830th iteration, cost function is 10.8022756682\n",
      "After 22840th iteration, cost function is 9.76664326828\n",
      "After 22850th iteration, cost function is 9.31327179138\n",
      "After 22860th iteration, cost function is 10.1322456025\n",
      "After 22870th iteration, cost function is 10.8391440201\n",
      "After 22880th iteration, cost function is 10.5701417474\n",
      "After 22890th iteration, cost function is 9.90016016789\n",
      "After 22900th iteration, cost function is 9.33792048459\n",
      "After 22910th iteration, cost function is 9.67068402669\n",
      "After 22920th iteration, cost function is 10.2658042187\n",
      "After 22930th iteration, cost function is 10.4878078245\n",
      "After 22940th iteration, cost function is 8.75714193056\n",
      "After 22950th iteration, cost function is 10.4247603085\n",
      "After 22960th iteration, cost function is 10.2356862665\n",
      "After 22970th iteration, cost function is 10.1687069624\n",
      "After 22980th iteration, cost function is 9.69723038777\n",
      "After 22990th iteration, cost function is 10.8035726844\n",
      "After 23000th iteration, cost function is 9.23650358686\n",
      "After 23010th iteration, cost function is 10.6815545627\n",
      "After 23020th iteration, cost function is 10.0097810911\n",
      "After 23030th iteration, cost function is 10.4303170856\n",
      "After 23040th iteration, cost function is 9.91248118648\n",
      "After 23050th iteration, cost function is 11.5946504\n",
      "After 23060th iteration, cost function is 9.46751482656\n",
      "After 23070th iteration, cost function is 10.054199597\n",
      "After 23080th iteration, cost function is 10.6291524014\n",
      "After 23090th iteration, cost function is 8.65310767584\n",
      "After 23100th iteration, cost function is 8.37612996724\n",
      "After 23110th iteration, cost function is 7.62870620689\n",
      "After 23120th iteration, cost function is 9.69098594126\n",
      "After 23130th iteration, cost function is 10.8160421082\n",
      "After 23140th iteration, cost function is 9.83096043234\n",
      "After 23150th iteration, cost function is 10.263461641\n",
      "After 23160th iteration, cost function is 9.84720081095\n",
      "After 23170th iteration, cost function is 10.3094911714\n",
      "After 23180th iteration, cost function is 10.2430835509\n",
      "After 23190th iteration, cost function is 9.1142351312\n",
      "After 23200th iteration, cost function is 11.8183329727\n",
      "After 23210th iteration, cost function is 10.2308335932\n",
      "After 23220th iteration, cost function is 9.93277359251\n",
      "After 23230th iteration, cost function is 10.4894430919\n",
      "After 23240th iteration, cost function is 9.67197498965\n",
      "After 23250th iteration, cost function is 10.3257404114\n",
      "After 23260th iteration, cost function is 8.83944946728\n",
      "After 23270th iteration, cost function is 8.53329541363\n",
      "After 23280th iteration, cost function is 8.53782005937\n",
      "After 23290th iteration, cost function is 8.61579671811\n",
      "After 23300th iteration, cost function is 9.93085639894\n",
      "After 23310th iteration, cost function is 10.523990676\n",
      "After 23320th iteration, cost function is 12.1418071634\n",
      "After 23330th iteration, cost function is 8.97915361253\n",
      "After 23340th iteration, cost function is 9.93791320976\n",
      "After 23350th iteration, cost function is 10.6752707367\n",
      "After 23360th iteration, cost function is 9.84379556923\n",
      "After 23370th iteration, cost function is 10.7450623157\n",
      "After 23380th iteration, cost function is 11.3438982542\n",
      "After 23390th iteration, cost function is 10.9200908445\n",
      "After 23400th iteration, cost function is 8.71211811719\n",
      "After 23410th iteration, cost function is 10.9914752247\n",
      "After 23420th iteration, cost function is 9.96896993696\n",
      "After 23430th iteration, cost function is 8.26178522202\n",
      "After 23440th iteration, cost function is 11.3536390639\n",
      "After 23450th iteration, cost function is 11.2002072141\n",
      "After 23460th iteration, cost function is 10.4642048809\n",
      "After 23470th iteration, cost function is 9.40600225111\n",
      "After 23480th iteration, cost function is 9.00300991658\n",
      "After 23490th iteration, cost function is 9.97289577118\n",
      "After 23500th iteration, cost function is 11.070812782\n",
      "After 23510th iteration, cost function is 9.25157502932\n",
      "After 23520th iteration, cost function is 10.8965597322\n",
      "After 23530th iteration, cost function is 9.5199027496\n",
      "After 23540th iteration, cost function is 10.6711704321\n",
      "After 23550th iteration, cost function is 9.12662097781\n",
      "After 23560th iteration, cost function is 9.51377515652\n",
      "After 23570th iteration, cost function is 9.98913131369\n",
      "After 23580th iteration, cost function is 9.4778379489\n",
      "After 23590th iteration, cost function is 8.92154411278\n",
      "After 23600th iteration, cost function is 11.4891392037\n",
      "After 23610th iteration, cost function is 10.6436139527\n",
      "After 23620th iteration, cost function is 9.37061235308\n",
      "After 23630th iteration, cost function is 9.30570704238\n",
      "After 23640th iteration, cost function is 10.7938098684\n",
      "After 23650th iteration, cost function is 9.95574725304\n",
      "After 23660th iteration, cost function is 9.99676321246\n",
      "After 23670th iteration, cost function is 10.7399231667\n",
      "After 23680th iteration, cost function is 9.27280883346\n",
      "After 23690th iteration, cost function is 10.8002665896\n",
      "After 23700th iteration, cost function is 10.1230874842\n",
      "After 23710th iteration, cost function is 9.1626493682\n",
      "After 23720th iteration, cost function is 8.8001990173\n",
      "After 23730th iteration, cost function is 10.5783175088\n",
      "After 23740th iteration, cost function is 10.0379623504\n",
      "After 23750th iteration, cost function is 9.24123351172\n",
      "After 23760th iteration, cost function is 9.21849214141\n",
      "After 23770th iteration, cost function is 9.57880778233\n",
      "After 23780th iteration, cost function is 10.731207762\n",
      "After 23790th iteration, cost function is 9.05223046793\n",
      "After 23800th iteration, cost function is 9.58915216296\n",
      "After 23810th iteration, cost function is 10.3508257996\n",
      "After 23820th iteration, cost function is 9.10678101139\n",
      "After 23830th iteration, cost function is 10.881134799\n",
      "After 23840th iteration, cost function is 10.0311496304\n",
      "After 23850th iteration, cost function is 8.9701140913\n",
      "After 23860th iteration, cost function is 9.72443524526\n",
      "After 23870th iteration, cost function is 11.4262409872\n",
      "After 23880th iteration, cost function is 9.34430746873\n",
      "After 23890th iteration, cost function is 10.3027743048\n",
      "After 23900th iteration, cost function is 9.84948559826\n",
      "After 23910th iteration, cost function is 11.4677494428\n",
      "After 23920th iteration, cost function is 10.8632278897\n",
      "After 23930th iteration, cost function is 9.61435750078\n",
      "After 23940th iteration, cost function is 10.1346425891\n",
      "After 23950th iteration, cost function is 10.3831027849\n",
      "After 23960th iteration, cost function is 11.2924165519\n",
      "After 23970th iteration, cost function is 9.91598106269\n",
      "After 23980th iteration, cost function is 10.0887408348\n",
      "After 23990th iteration, cost function is 9.52237334871\n",
      "After 24000th iteration, cost function is 11.3693412249\n",
      "After 24010th iteration, cost function is 10.4125149275\n",
      "After 24020th iteration, cost function is 9.49858743543\n",
      "After 24030th iteration, cost function is 10.2848444019\n",
      "After 24040th iteration, cost function is 9.83566015181\n",
      "After 24050th iteration, cost function is 10.2773203489\n",
      "After 24060th iteration, cost function is 10.4126683491\n",
      "After 24070th iteration, cost function is 10.6300988271\n",
      "After 24080th iteration, cost function is 9.26938873496\n",
      "After 24090th iteration, cost function is 9.80097158778\n",
      "After 24100th iteration, cost function is 10.0245335991\n",
      "After 24110th iteration, cost function is 9.80930050899\n",
      "After 24120th iteration, cost function is 10.8592205691\n",
      "After 24130th iteration, cost function is 9.30411762025\n",
      "After 24140th iteration, cost function is 9.39139341483\n",
      "After 24150th iteration, cost function is 9.88987059903\n",
      "After 24160th iteration, cost function is 8.95853683116\n",
      "After 24170th iteration, cost function is 10.2497284312\n",
      "After 24180th iteration, cost function is 9.17218231113\n",
      "After 24190th iteration, cost function is 9.98884791339\n",
      "After 24200th iteration, cost function is 9.86346346911\n",
      "After 24210th iteration, cost function is 9.62571421498\n",
      "After 24220th iteration, cost function is 11.1870406161\n",
      "After 24230th iteration, cost function is 9.62799157755\n",
      "After 24240th iteration, cost function is 9.47232185144\n",
      "After 24250th iteration, cost function is 9.12740938935\n",
      "After 24260th iteration, cost function is 8.8007021376\n",
      "After 24270th iteration, cost function is 10.6673617344\n",
      "After 24280th iteration, cost function is 9.27934434045\n",
      "After 24290th iteration, cost function is 9.46688299473\n",
      "After 24300th iteration, cost function is 10.4535760776\n",
      "After 24310th iteration, cost function is 9.6268790522\n",
      "After 24320th iteration, cost function is 10.07140518\n",
      "After 24330th iteration, cost function is 10.2851179148\n",
      "After 24340th iteration, cost function is 8.85449767214\n",
      "After 24350th iteration, cost function is 8.48052573754\n",
      "After 24360th iteration, cost function is 11.0442755413\n",
      "After 24370th iteration, cost function is 9.90798848022\n",
      "After 24380th iteration, cost function is 11.393870776\n",
      "After 24390th iteration, cost function is 10.5548346849\n",
      "After 24400th iteration, cost function is 7.85951383113\n",
      "After 24410th iteration, cost function is 10.1151901907\n",
      "After 24420th iteration, cost function is 9.21523859955\n",
      "After 24430th iteration, cost function is 10.9106912091\n",
      "After 24440th iteration, cost function is 11.2251469809\n",
      "After 24450th iteration, cost function is 10.6236966931\n",
      "After 24460th iteration, cost function is 8.17027132283\n",
      "After 24470th iteration, cost function is 10.4690058449\n",
      "After 24480th iteration, cost function is 9.08271729049\n",
      "After 24490th iteration, cost function is 10.9964605281\n",
      "After 24500th iteration, cost function is 9.6715994291\n",
      "After 24510th iteration, cost function is 8.97000962754\n",
      "After 24520th iteration, cost function is 9.28441538385\n",
      "After 24530th iteration, cost function is 10.1822216317\n",
      "After 24540th iteration, cost function is 9.90523837565\n",
      "After 24550th iteration, cost function is 9.67987672567\n",
      "After 24560th iteration, cost function is 9.01762390233\n",
      "After 24570th iteration, cost function is 10.6360881908\n",
      "After 24580th iteration, cost function is 9.48108665258\n",
      "After 24590th iteration, cost function is 11.0661800074\n",
      "After 24600th iteration, cost function is 9.76493157971\n",
      "After 24610th iteration, cost function is 9.51825134091\n",
      "After 24620th iteration, cost function is 9.11477741275\n",
      "After 24630th iteration, cost function is 9.81842801044\n",
      "After 24640th iteration, cost function is 10.5380804487\n",
      "After 24650th iteration, cost function is 11.3720795198\n",
      "After 24660th iteration, cost function is 10.8116786092\n",
      "After 24670th iteration, cost function is 10.1708704699\n",
      "After 24680th iteration, cost function is 11.629600396\n",
      "After 24690th iteration, cost function is 9.25704930346\n",
      "After 24700th iteration, cost function is 10.3669942243\n",
      "After 24710th iteration, cost function is 10.5373019773\n",
      "After 24720th iteration, cost function is 8.1721157213\n",
      "After 24730th iteration, cost function is 10.9558703815\n",
      "After 24740th iteration, cost function is 9.4181794695\n",
      "After 24750th iteration, cost function is 9.37681091282\n",
      "After 24760th iteration, cost function is 9.73840312167\n",
      "After 24770th iteration, cost function is 10.9576635087\n",
      "After 24780th iteration, cost function is 10.4572918439\n",
      "After 24790th iteration, cost function is 10.4749534487\n",
      "After 24800th iteration, cost function is 12.2144292798\n",
      "After 24810th iteration, cost function is 9.24104516368\n",
      "After 24820th iteration, cost function is 9.28324396346\n",
      "After 24830th iteration, cost function is 9.31907734176\n",
      "After 24840th iteration, cost function is 9.14182984163\n",
      "After 24850th iteration, cost function is 8.53837146632\n",
      "After 24860th iteration, cost function is 10.1709756215\n",
      "After 24870th iteration, cost function is 10.751387189\n",
      "After 24880th iteration, cost function is 9.32314720038\n",
      "After 24890th iteration, cost function is 8.85239377711\n",
      "After 24900th iteration, cost function is 9.76450711715\n",
      "After 24910th iteration, cost function is 10.1544413301\n",
      "After 24920th iteration, cost function is 9.1785426919\n",
      "After 24930th iteration, cost function is 9.86309508582\n",
      "After 24940th iteration, cost function is 8.65673738471\n",
      "After 24950th iteration, cost function is 9.39525027533\n",
      "After 24960th iteration, cost function is 10.5654819223\n",
      "After 24970th iteration, cost function is 9.60002229113\n",
      "After 24980th iteration, cost function is 8.67342276515\n",
      "After 24990th iteration, cost function is 10.8228512655\n",
      "After 25000th iteration, cost function is 10.0527952011\n",
      "After 25010th iteration, cost function is 10.3288911348\n",
      "After 25020th iteration, cost function is 9.98847837811\n",
      "After 25030th iteration, cost function is 8.19400250193\n",
      "After 25040th iteration, cost function is 10.4477425049\n",
      "After 25050th iteration, cost function is 10.5508929636\n",
      "After 25060th iteration, cost function is 8.60151795506\n",
      "After 25070th iteration, cost function is 9.00496648083\n",
      "After 25080th iteration, cost function is 10.8115936324\n",
      "After 25090th iteration, cost function is 9.65729983517\n",
      "After 25100th iteration, cost function is 10.6982031643\n",
      "After 25110th iteration, cost function is 9.20762701899\n",
      "After 25120th iteration, cost function is 10.4516384176\n",
      "After 25130th iteration, cost function is 10.3842228734\n",
      "After 25140th iteration, cost function is 10.213783261\n",
      "After 25150th iteration, cost function is 12.0622474741\n",
      "After 25160th iteration, cost function is 11.529179402\n",
      "After 25170th iteration, cost function is 9.30314859562\n",
      "After 25180th iteration, cost function is 8.90608478959\n",
      "After 25190th iteration, cost function is 10.3709039363\n",
      "After 25200th iteration, cost function is 9.11680966456\n",
      "After 25210th iteration, cost function is 8.58319604881\n",
      "After 25220th iteration, cost function is 9.76435765049\n",
      "After 25230th iteration, cost function is 8.56470032105\n",
      "After 25240th iteration, cost function is 10.9380607067\n",
      "After 25250th iteration, cost function is 10.185213758\n",
      "After 25260th iteration, cost function is 9.69639065343\n",
      "After 25270th iteration, cost function is 8.01348431963\n",
      "After 25280th iteration, cost function is 11.3402122324\n",
      "After 25290th iteration, cost function is 9.86193251142\n",
      "After 25300th iteration, cost function is 9.21017880736\n",
      "After 25310th iteration, cost function is 9.62629279587\n",
      "After 25320th iteration, cost function is 12.0503854339\n",
      "After 25330th iteration, cost function is 10.2646637344\n",
      "After 25340th iteration, cost function is 10.6937939155\n",
      "After 25350th iteration, cost function is 11.9389517892\n",
      "After 25360th iteration, cost function is 10.3285588802\n",
      "After 25370th iteration, cost function is 9.6686990773\n",
      "After 25380th iteration, cost function is 9.63417341627\n",
      "After 25390th iteration, cost function is 10.0190888865\n",
      "After 25400th iteration, cost function is 11.0786293787\n",
      "After 25410th iteration, cost function is 9.09689362118\n",
      "After 25420th iteration, cost function is 10.4539787517\n",
      "After 25430th iteration, cost function is 10.0054770975\n",
      "After 25440th iteration, cost function is 11.2533499541\n",
      "After 25450th iteration, cost function is 9.67193691804\n",
      "After 25460th iteration, cost function is 10.1472058147\n",
      "After 25470th iteration, cost function is 11.2661317434\n",
      "After 25480th iteration, cost function is 9.80159887242\n",
      "After 25490th iteration, cost function is 10.3580364143\n",
      "After 25500th iteration, cost function is 10.2238117758\n",
      "After 25510th iteration, cost function is 9.57276286117\n",
      "After 25520th iteration, cost function is 9.21356247169\n",
      "After 25530th iteration, cost function is 10.170611963\n",
      "After 25540th iteration, cost function is 9.68080066644\n",
      "After 25550th iteration, cost function is 9.21812635435\n",
      "After 25560th iteration, cost function is 9.5600278073\n",
      "After 25570th iteration, cost function is 9.82324749366\n",
      "After 25580th iteration, cost function is 9.89011130567\n",
      "After 25590th iteration, cost function is 11.0055053042\n",
      "After 25600th iteration, cost function is 9.8059827791\n",
      "After 25610th iteration, cost function is 10.1042864403\n",
      "After 25620th iteration, cost function is 8.48412166693\n",
      "After 25630th iteration, cost function is 10.3632940681\n",
      "After 25640th iteration, cost function is 9.55935482137\n",
      "After 25650th iteration, cost function is 8.55966084692\n",
      "After 25660th iteration, cost function is 8.27269409044\n",
      "After 25670th iteration, cost function is 9.8218538089\n",
      "After 25680th iteration, cost function is 10.193412465\n",
      "After 25690th iteration, cost function is 10.4411843514\n",
      "After 25700th iteration, cost function is 9.67925220064\n",
      "After 25710th iteration, cost function is 9.52609812618\n",
      "After 25720th iteration, cost function is 10.2502574544\n",
      "After 25730th iteration, cost function is 10.0805063634\n",
      "After 25740th iteration, cost function is 9.62994526866\n",
      "After 25750th iteration, cost function is 9.78251181551\n",
      "After 25760th iteration, cost function is 10.6996758038\n",
      "After 25770th iteration, cost function is 10.1385508353\n",
      "After 25780th iteration, cost function is 9.15540610563\n",
      "After 25790th iteration, cost function is 10.742150998\n",
      "After 25800th iteration, cost function is 10.0953337565\n",
      "After 25810th iteration, cost function is 10.4276308092\n",
      "After 25820th iteration, cost function is 9.46602161341\n",
      "After 25830th iteration, cost function is 10.1032770338\n",
      "After 25840th iteration, cost function is 10.0658451299\n",
      "After 25850th iteration, cost function is 10.2985976181\n",
      "After 25860th iteration, cost function is 9.06946666928\n",
      "After 25870th iteration, cost function is 9.84278444394\n",
      "After 25880th iteration, cost function is 12.1179584739\n",
      "After 25890th iteration, cost function is 9.46421621951\n",
      "After 25900th iteration, cost function is 8.78947210419\n",
      "After 25910th iteration, cost function is 9.94349564218\n",
      "After 25920th iteration, cost function is 9.35610119885\n",
      "After 25930th iteration, cost function is 9.78656017051\n",
      "After 25940th iteration, cost function is 9.58041652315\n",
      "After 25950th iteration, cost function is 11.3040411596\n",
      "After 25960th iteration, cost function is 9.13782466306\n",
      "After 25970th iteration, cost function is 11.1908126848\n",
      "After 25980th iteration, cost function is 9.32064845867\n",
      "After 25990th iteration, cost function is 8.23639257093\n",
      "After 26000th iteration, cost function is 9.88856231573\n",
      "After 26010th iteration, cost function is 8.47048070892\n",
      "After 26020th iteration, cost function is 10.2160517803\n",
      "After 26030th iteration, cost function is 10.6892508427\n",
      "After 26040th iteration, cost function is 10.2641471629\n",
      "After 26050th iteration, cost function is 10.8603524481\n",
      "After 26060th iteration, cost function is 9.1482640747\n",
      "After 26070th iteration, cost function is 10.5586644175\n",
      "After 26080th iteration, cost function is 10.7353041141\n",
      "After 26090th iteration, cost function is 9.82374178742\n",
      "After 26100th iteration, cost function is 10.7096457594\n",
      "After 26110th iteration, cost function is 11.4226116499\n",
      "After 26120th iteration, cost function is 7.98563948267\n",
      "After 26130th iteration, cost function is 10.1602110207\n",
      "After 26140th iteration, cost function is 9.78130626812\n",
      "After 26150th iteration, cost function is 8.7938418753\n",
      "After 26160th iteration, cost function is 11.1014737888\n",
      "After 26170th iteration, cost function is 9.690803885\n",
      "After 26180th iteration, cost function is 8.74288127655\n",
      "After 26190th iteration, cost function is 10.0661514706\n",
      "After 26200th iteration, cost function is 10.0480973856\n",
      "After 26210th iteration, cost function is 10.1827632605\n",
      "After 26220th iteration, cost function is 9.05555851517\n",
      "After 26230th iteration, cost function is 8.92809908971\n",
      "After 26240th iteration, cost function is 10.0062177087\n",
      "After 26250th iteration, cost function is 9.15259317026\n",
      "After 26260th iteration, cost function is 10.3212432502\n",
      "After 26270th iteration, cost function is 10.721031197\n",
      "After 26280th iteration, cost function is 8.11890702354\n",
      "After 26290th iteration, cost function is 9.43808162576\n",
      "After 26300th iteration, cost function is 8.61101401377\n",
      "After 26310th iteration, cost function is 10.2562008678\n",
      "After 26320th iteration, cost function is 9.87560469562\n",
      "After 26330th iteration, cost function is 9.91222607113\n",
      "After 26340th iteration, cost function is 10.636060711\n",
      "After 26350th iteration, cost function is 10.5233945736\n",
      "After 26360th iteration, cost function is 9.90599543389\n",
      "After 26370th iteration, cost function is 10.2096308977\n",
      "After 26380th iteration, cost function is 9.60211965756\n",
      "After 26390th iteration, cost function is 10.273390179\n",
      "After 26400th iteration, cost function is 9.86442629524\n",
      "After 26410th iteration, cost function is 9.73704456305\n",
      "After 26420th iteration, cost function is 8.88997806683\n",
      "After 26430th iteration, cost function is 9.75827917633\n",
      "After 26440th iteration, cost function is 10.2390570262\n",
      "After 26450th iteration, cost function is 8.89682295577\n",
      "After 26460th iteration, cost function is 10.4430403961\n",
      "After 26470th iteration, cost function is 8.70325780898\n",
      "After 26480th iteration, cost function is 11.4367559733\n",
      "After 26490th iteration, cost function is 8.47002042045\n",
      "After 26500th iteration, cost function is 9.66259869117\n",
      "After 26510th iteration, cost function is 9.65315743617\n",
      "After 26520th iteration, cost function is 11.5642953427\n",
      "After 26530th iteration, cost function is 9.21077741401\n",
      "After 26540th iteration, cost function is 10.4335489448\n",
      "After 26550th iteration, cost function is 9.42526707006\n",
      "After 26560th iteration, cost function is 10.3088241781\n",
      "After 26570th iteration, cost function is 9.76369124698\n",
      "After 26580th iteration, cost function is 9.42968623184\n",
      "After 26590th iteration, cost function is 9.21533977867\n",
      "After 26600th iteration, cost function is 9.94947279633\n",
      "After 26610th iteration, cost function is 12.0889146436\n",
      "After 26620th iteration, cost function is 11.1702674223\n",
      "After 26630th iteration, cost function is 9.08310881824\n",
      "After 26640th iteration, cost function is 9.68310838845\n",
      "After 26650th iteration, cost function is 10.3471146811\n",
      "After 26660th iteration, cost function is 10.7860201975\n",
      "After 26670th iteration, cost function is 10.4624792921\n",
      "After 26680th iteration, cost function is 9.31246906406\n",
      "After 26690th iteration, cost function is 8.56982840307\n",
      "After 26700th iteration, cost function is 9.48597249351\n",
      "After 26710th iteration, cost function is 8.24494415511\n",
      "After 26720th iteration, cost function is 9.62875722747\n",
      "After 26730th iteration, cost function is 10.0406225732\n",
      "After 26740th iteration, cost function is 9.04195084615\n",
      "After 26750th iteration, cost function is 10.5443843172\n",
      "After 26760th iteration, cost function is 9.60836760642\n",
      "After 26770th iteration, cost function is 10.3161287821\n",
      "After 26780th iteration, cost function is 10.0500315633\n",
      "After 26790th iteration, cost function is 11.2499842362\n",
      "After 26800th iteration, cost function is 10.0984907175\n",
      "After 26810th iteration, cost function is 8.37380947721\n",
      "After 26820th iteration, cost function is 9.79395573473\n",
      "After 26830th iteration, cost function is 10.1811762586\n",
      "After 26840th iteration, cost function is 9.79278580365\n",
      "After 26850th iteration, cost function is 8.83111172981\n",
      "After 26860th iteration, cost function is 9.75280185339\n",
      "After 26870th iteration, cost function is 10.7837273617\n",
      "After 26880th iteration, cost function is 9.28755088763\n",
      "After 26890th iteration, cost function is 9.90682738308\n",
      "After 26900th iteration, cost function is 9.80412318257\n",
      "After 26910th iteration, cost function is 10.2050446737\n",
      "After 26920th iteration, cost function is 10.8500077323\n",
      "After 26930th iteration, cost function is 9.47965614445\n",
      "After 26940th iteration, cost function is 8.42651806059\n",
      "After 26950th iteration, cost function is 10.021037006\n",
      "After 26960th iteration, cost function is 10.7466082073\n",
      "After 26970th iteration, cost function is 9.92281775918\n",
      "After 26980th iteration, cost function is 9.49177149554\n",
      "After 26990th iteration, cost function is 10.7532814911\n",
      "After 27000th iteration, cost function is 8.78419934116\n",
      "After 27010th iteration, cost function is 9.93393416117\n",
      "After 27020th iteration, cost function is 10.2850201312\n",
      "After 27030th iteration, cost function is 9.8342393824\n",
      "After 27040th iteration, cost function is 10.1077338697\n",
      "After 27050th iteration, cost function is 8.89738687837\n",
      "After 27060th iteration, cost function is 9.08062884875\n",
      "After 27070th iteration, cost function is 9.94517903831\n",
      "After 27080th iteration, cost function is 10.1009354482\n",
      "After 27090th iteration, cost function is 9.93896486117\n",
      "After 27100th iteration, cost function is 10.372607368\n",
      "After 27110th iteration, cost function is 10.3921426581\n",
      "After 27120th iteration, cost function is 11.3134257151\n",
      "After 27130th iteration, cost function is 10.3094982485\n",
      "After 27140th iteration, cost function is 9.11843401439\n",
      "After 27150th iteration, cost function is 9.62208673935\n",
      "After 27160th iteration, cost function is 9.12013817908\n",
      "After 27170th iteration, cost function is 9.24977342789\n",
      "After 27180th iteration, cost function is 9.76161718008\n",
      "After 27190th iteration, cost function is 10.5102780407\n",
      "After 27200th iteration, cost function is 9.26643649924\n",
      "After 27210th iteration, cost function is 9.51907239268\n",
      "After 27220th iteration, cost function is 7.55658676808\n",
      "After 27230th iteration, cost function is 9.85544135764\n",
      "After 27240th iteration, cost function is 9.77905984127\n",
      "After 27250th iteration, cost function is 9.61534556914\n",
      "After 27260th iteration, cost function is 10.1519253641\n",
      "After 27270th iteration, cost function is 9.48879745333\n",
      "After 27280th iteration, cost function is 8.95597963447\n",
      "After 27290th iteration, cost function is 10.3650931074\n",
      "After 27300th iteration, cost function is 10.0209178503\n",
      "After 27310th iteration, cost function is 9.30973176121\n",
      "After 27320th iteration, cost function is 8.38861824417\n",
      "After 27330th iteration, cost function is 7.17708880287\n",
      "After 27340th iteration, cost function is 9.08567534768\n",
      "After 27350th iteration, cost function is 9.54994256122\n",
      "After 27360th iteration, cost function is 9.83746267734\n",
      "After 27370th iteration, cost function is 12.4844751371\n",
      "After 27380th iteration, cost function is 9.11227915277\n",
      "After 27390th iteration, cost function is 9.77050351937\n",
      "After 27400th iteration, cost function is 9.04374230948\n",
      "After 27410th iteration, cost function is 10.111627601\n",
      "After 27420th iteration, cost function is 8.75714411106\n",
      "After 27430th iteration, cost function is 9.95731353288\n",
      "After 27440th iteration, cost function is 9.89309156275\n",
      "After 27450th iteration, cost function is 9.32816488602\n",
      "After 27460th iteration, cost function is 8.80337645015\n",
      "After 27470th iteration, cost function is 8.6243650786\n",
      "After 27480th iteration, cost function is 10.9396040341\n",
      "After 27490th iteration, cost function is 11.5553064419\n",
      "After 27500th iteration, cost function is 8.96859457957\n",
      "After 27510th iteration, cost function is 10.8658326695\n",
      "After 27520th iteration, cost function is 9.29919874324\n",
      "After 27530th iteration, cost function is 10.126784919\n",
      "After 27540th iteration, cost function is 8.13754147036\n",
      "After 27550th iteration, cost function is 11.6709586071\n",
      "After 27560th iteration, cost function is 11.1550042083\n",
      "After 27570th iteration, cost function is 9.37257799519\n",
      "After 27580th iteration, cost function is 11.0675972765\n",
      "After 27590th iteration, cost function is 9.1937931656\n",
      "After 27600th iteration, cost function is 11.7554022213\n",
      "After 27610th iteration, cost function is 10.369914207\n",
      "After 27620th iteration, cost function is 9.04298233991\n",
      "After 27630th iteration, cost function is 9.6990087355\n",
      "After 27640th iteration, cost function is 9.02435363172\n",
      "After 27650th iteration, cost function is 9.5891019118\n",
      "After 27660th iteration, cost function is 9.81295335362\n",
      "After 27670th iteration, cost function is 10.9253113437\n",
      "After 27680th iteration, cost function is 11.2877459478\n",
      "After 27690th iteration, cost function is 9.85628067189\n",
      "After 27700th iteration, cost function is 9.13474988429\n",
      "After 27710th iteration, cost function is 9.91095892135\n",
      "After 27720th iteration, cost function is 8.74146847699\n",
      "After 27730th iteration, cost function is 9.52873109779\n",
      "After 27740th iteration, cost function is 11.5346717846\n",
      "After 27750th iteration, cost function is 9.6882484141\n",
      "After 27760th iteration, cost function is 8.6965705293\n",
      "After 27770th iteration, cost function is 9.1799862011\n",
      "After 27780th iteration, cost function is 9.66931077003\n",
      "After 27790th iteration, cost function is 10.0086483262\n",
      "After 27800th iteration, cost function is 8.95509697195\n",
      "After 27810th iteration, cost function is 9.42626082148\n",
      "After 27820th iteration, cost function is 10.3415769624\n",
      "After 27830th iteration, cost function is 10.2099075729\n",
      "After 27840th iteration, cost function is 9.35263765343\n",
      "After 27850th iteration, cost function is 9.58637679198\n",
      "After 27860th iteration, cost function is 8.45661853082\n",
      "After 27870th iteration, cost function is 9.43021429962\n",
      "After 27880th iteration, cost function is 9.49115364852\n",
      "After 27890th iteration, cost function is 9.49491909249\n",
      "After 27900th iteration, cost function is 9.71687379374\n",
      "After 27910th iteration, cost function is 10.0177562702\n",
      "After 27920th iteration, cost function is 10.2095365367\n",
      "After 27930th iteration, cost function is 9.96582394078\n",
      "After 27940th iteration, cost function is 9.92964485573\n",
      "After 27950th iteration, cost function is 10.1818837298\n",
      "After 27960th iteration, cost function is 11.1395578047\n",
      "After 27970th iteration, cost function is 10.3992759454\n",
      "After 27980th iteration, cost function is 9.19451908694\n",
      "After 27990th iteration, cost function is 9.7703459785\n",
      "After 28000th iteration, cost function is 9.76865645528\n",
      "After 28010th iteration, cost function is 10.686736545\n",
      "After 28020th iteration, cost function is 9.5794858435\n",
      "After 28030th iteration, cost function is 8.83739346839\n",
      "After 28040th iteration, cost function is 10.5222860732\n",
      "After 28050th iteration, cost function is 8.5556922193\n",
      "After 28060th iteration, cost function is 8.15839270129\n",
      "After 28070th iteration, cost function is 10.7034034673\n",
      "After 28080th iteration, cost function is 9.14407778256\n",
      "After 28090th iteration, cost function is 8.15275867549\n",
      "After 28100th iteration, cost function is 10.6603403524\n",
      "After 28110th iteration, cost function is 10.0308747523\n",
      "After 28120th iteration, cost function is 9.35585988351\n",
      "After 28130th iteration, cost function is 10.3564470063\n",
      "After 28140th iteration, cost function is 9.8982296355\n",
      "After 28150th iteration, cost function is 8.93736622431\n",
      "After 28160th iteration, cost function is 9.7069072653\n",
      "After 28170th iteration, cost function is 10.1310389499\n",
      "After 28180th iteration, cost function is 10.5375834719\n",
      "After 28190th iteration, cost function is 9.28024316784\n",
      "After 28200th iteration, cost function is 10.2176153248\n",
      "After 28210th iteration, cost function is 10.3317339644\n",
      "After 28220th iteration, cost function is 9.79338042557\n",
      "After 28230th iteration, cost function is 8.43193819854\n",
      "After 28240th iteration, cost function is 9.8624602219\n",
      "After 28250th iteration, cost function is 9.44415526191\n",
      "After 28260th iteration, cost function is 10.819361541\n",
      "After 28270th iteration, cost function is 9.85017427676\n",
      "After 28280th iteration, cost function is 10.9483288021\n",
      "After 28290th iteration, cost function is 10.4448985026\n",
      "After 28300th iteration, cost function is 9.6625941722\n",
      "After 28310th iteration, cost function is 10.1101954503\n",
      "After 28320th iteration, cost function is 9.60358408139\n",
      "After 28330th iteration, cost function is 10.043937344\n",
      "After 28340th iteration, cost function is 9.35829762626\n",
      "After 28350th iteration, cost function is 8.77344842331\n",
      "After 28360th iteration, cost function is 8.89243616454\n",
      "After 28370th iteration, cost function is 9.83075353206\n",
      "After 28380th iteration, cost function is 9.72082080781\n",
      "After 28390th iteration, cost function is 10.0290733597\n",
      "After 28400th iteration, cost function is 8.65373098171\n",
      "After 28410th iteration, cost function is 10.1067734573\n",
      "After 28420th iteration, cost function is 9.2361274718\n",
      "After 28430th iteration, cost function is 9.53916961362\n",
      "After 28440th iteration, cost function is 9.55206791584\n",
      "After 28450th iteration, cost function is 9.35979686674\n",
      "After 28460th iteration, cost function is 10.3284677098\n",
      "After 28470th iteration, cost function is 11.5972173866\n",
      "After 28480th iteration, cost function is 9.64021180414\n",
      "After 28490th iteration, cost function is 8.57806600638\n",
      "After 28500th iteration, cost function is 9.42776518742\n",
      "After 28510th iteration, cost function is 10.089988088\n",
      "After 28520th iteration, cost function is 9.56581077208\n",
      "After 28530th iteration, cost function is 8.96635517499\n",
      "After 28540th iteration, cost function is 9.75116917188\n",
      "After 28550th iteration, cost function is 9.26451667623\n",
      "After 28560th iteration, cost function is 9.48445158929\n",
      "After 28570th iteration, cost function is 10.0283476168\n",
      "After 28580th iteration, cost function is 9.7745015334\n",
      "After 28590th iteration, cost function is 9.75534735516\n",
      "After 28600th iteration, cost function is 11.002648615\n",
      "After 28610th iteration, cost function is 10.7678535572\n",
      "After 28620th iteration, cost function is 8.84621665062\n",
      "After 28630th iteration, cost function is 9.95360446966\n",
      "After 28640th iteration, cost function is 9.02669278644\n",
      "After 28650th iteration, cost function is 9.02524687651\n",
      "After 28660th iteration, cost function is 8.22931031247\n",
      "After 28670th iteration, cost function is 7.0226557499\n",
      "After 28680th iteration, cost function is 9.71920797712\n",
      "After 28690th iteration, cost function is 9.50061662253\n",
      "After 28700th iteration, cost function is 10.2541913916\n",
      "After 28710th iteration, cost function is 9.022572492\n",
      "After 28720th iteration, cost function is 8.3885837869\n",
      "After 28730th iteration, cost function is 9.89908843763\n",
      "After 28740th iteration, cost function is 9.4740245444\n",
      "After 28750th iteration, cost function is 11.3612698949\n",
      "After 28760th iteration, cost function is 9.81857030627\n",
      "After 28770th iteration, cost function is 8.51309040683\n",
      "After 28780th iteration, cost function is 10.7803279683\n",
      "After 28790th iteration, cost function is 9.67733948596\n",
      "After 28800th iteration, cost function is 10.562455517\n",
      "After 28810th iteration, cost function is 11.4933823526\n",
      "After 28820th iteration, cost function is 9.73995196197\n",
      "After 28830th iteration, cost function is 10.0997831737\n",
      "After 28840th iteration, cost function is 10.0859834935\n",
      "After 28850th iteration, cost function is 9.95944364908\n",
      "After 28860th iteration, cost function is 9.62602057656\n",
      "After 28870th iteration, cost function is 11.5456759715\n",
      "After 28880th iteration, cost function is 10.3718495675\n",
      "After 28890th iteration, cost function is 8.59692950503\n",
      "After 28900th iteration, cost function is 10.958322415\n",
      "After 28910th iteration, cost function is 9.00474699952\n",
      "After 28920th iteration, cost function is 10.3798313332\n",
      "After 28930th iteration, cost function is 8.27604524585\n",
      "After 28940th iteration, cost function is 9.40888171662\n",
      "After 28950th iteration, cost function is 9.85888387664\n",
      "After 28960th iteration, cost function is 9.73166858113\n",
      "After 28970th iteration, cost function is 10.6616451661\n",
      "After 28980th iteration, cost function is 10.9622564582\n",
      "After 28990th iteration, cost function is 10.595393151\n",
      "After 29000th iteration, cost function is 10.0656643265\n",
      "After 29010th iteration, cost function is 9.90659504895\n",
      "After 29020th iteration, cost function is 10.590011646\n",
      "After 29030th iteration, cost function is 11.4192721271\n",
      "After 29040th iteration, cost function is 8.9841009755\n",
      "After 29050th iteration, cost function is 9.60651978799\n",
      "After 29060th iteration, cost function is 9.23583656562\n",
      "After 29070th iteration, cost function is 10.0965305049\n",
      "After 29080th iteration, cost function is 10.7205694043\n",
      "After 29090th iteration, cost function is 11.5699287532\n",
      "After 29100th iteration, cost function is 10.0757907347\n",
      "After 29110th iteration, cost function is 11.4051530727\n",
      "After 29120th iteration, cost function is 10.6685971257\n",
      "After 29130th iteration, cost function is 10.671719791\n",
      "After 29140th iteration, cost function is 10.7908382157\n",
      "After 29150th iteration, cost function is 9.56963448954\n",
      "After 29160th iteration, cost function is 11.2239471195\n",
      "After 29170th iteration, cost function is 9.23230122121\n",
      "After 29180th iteration, cost function is 9.77183277515\n",
      "After 29190th iteration, cost function is 9.43695095793\n",
      "After 29200th iteration, cost function is 9.82966610091\n",
      "After 29210th iteration, cost function is 9.81975029271\n",
      "After 29220th iteration, cost function is 9.30720363859\n",
      "After 29230th iteration, cost function is 9.95411502912\n",
      "After 29240th iteration, cost function is 9.26259960644\n",
      "After 29250th iteration, cost function is 9.62599763926\n",
      "After 29260th iteration, cost function is 10.9628341304\n",
      "After 29270th iteration, cost function is 8.51515873962\n",
      "After 29280th iteration, cost function is 9.52173737724\n",
      "After 29290th iteration, cost function is 9.74734477055\n",
      "After 29300th iteration, cost function is 11.1209107111\n",
      "After 29310th iteration, cost function is 9.29474943745\n",
      "After 29320th iteration, cost function is 9.13372683512\n",
      "After 29330th iteration, cost function is 9.38420509146\n",
      "After 29340th iteration, cost function is 11.0198690189\n",
      "After 29350th iteration, cost function is 9.41550032312\n",
      "After 29360th iteration, cost function is 9.94502985471\n",
      "After 29370th iteration, cost function is 10.231431425\n",
      "After 29380th iteration, cost function is 8.69249326029\n",
      "After 29390th iteration, cost function is 9.54988363209\n",
      "After 29400th iteration, cost function is 8.71417513996\n",
      "After 29410th iteration, cost function is 9.15615663114\n",
      "After 29420th iteration, cost function is 9.00385065802\n",
      "After 29430th iteration, cost function is 8.41591895857\n",
      "After 29440th iteration, cost function is 9.53447914363\n",
      "After 29450th iteration, cost function is 9.76433787201\n",
      "After 29460th iteration, cost function is 9.70011467149\n",
      "After 29470th iteration, cost function is 9.99023751123\n",
      "After 29480th iteration, cost function is 8.89542793561\n",
      "After 29490th iteration, cost function is 10.7940516074\n",
      "After 29500th iteration, cost function is 11.0666569507\n",
      "After 29510th iteration, cost function is 9.5414487196\n",
      "After 29520th iteration, cost function is 9.52490319751\n",
      "After 29530th iteration, cost function is 10.8943399867\n",
      "After 29540th iteration, cost function is 10.5541035639\n",
      "After 29550th iteration, cost function is 12.3715673862\n",
      "After 29560th iteration, cost function is 9.5376095125\n",
      "After 29570th iteration, cost function is 8.20467478789\n",
      "After 29580th iteration, cost function is 10.7722299328\n",
      "After 29590th iteration, cost function is 10.2909082504\n",
      "After 29600th iteration, cost function is 9.63673567266\n",
      "After 29610th iteration, cost function is 9.19692221121\n",
      "After 29620th iteration, cost function is 9.11530255374\n",
      "After 29630th iteration, cost function is 9.0547318936\n",
      "After 29640th iteration, cost function is 10.1806202467\n",
      "After 29650th iteration, cost function is 9.5736402771\n",
      "After 29660th iteration, cost function is 8.37122851478\n",
      "After 29670th iteration, cost function is 10.4146650686\n",
      "After 29680th iteration, cost function is 11.2558420485\n",
      "After 29690th iteration, cost function is 9.91385242287\n",
      "After 29700th iteration, cost function is 10.1217212693\n",
      "After 29710th iteration, cost function is 10.1089807257\n",
      "After 29720th iteration, cost function is 8.52981174418\n",
      "After 29730th iteration, cost function is 9.1871278796\n",
      "After 29740th iteration, cost function is 10.9578182301\n",
      "After 29750th iteration, cost function is 9.24336567234\n",
      "After 29760th iteration, cost function is 10.1449149319\n",
      "After 29770th iteration, cost function is 10.0799697712\n",
      "After 29780th iteration, cost function is 7.8193765735\n",
      "After 29790th iteration, cost function is 8.49477720993\n",
      "After 29800th iteration, cost function is 9.29541094664\n",
      "After 29810th iteration, cost function is 8.40273063936\n",
      "After 29820th iteration, cost function is 8.64896217536\n",
      "After 29830th iteration, cost function is 8.73235128422\n",
      "After 29840th iteration, cost function is 9.52020891761\n",
      "After 29850th iteration, cost function is 10.3732468544\n",
      "After 29860th iteration, cost function is 10.0412563403\n",
      "After 29870th iteration, cost function is 9.51558398597\n",
      "After 29880th iteration, cost function is 9.28570232384\n",
      "After 29890th iteration, cost function is 9.31194856009\n",
      "After 29900th iteration, cost function is 9.04909487189\n",
      "After 29910th iteration, cost function is 8.96751346129\n",
      "After 29920th iteration, cost function is 9.34978244783\n",
      "After 29930th iteration, cost function is 10.0059924501\n",
      "After 29940th iteration, cost function is 10.3424755884\n",
      "After 29950th iteration, cost function is 8.47447596571\n",
      "After 29960th iteration, cost function is 10.247452862\n",
      "After 29970th iteration, cost function is 9.95207147112\n",
      "After 29980th iteration, cost function is 10.1041193185\n",
      "After 29990th iteration, cost function is 10.6746891358\n",
      "After 30000th iteration, cost function is 8.88830271612\n",
      "After 30010th iteration, cost function is 11.9033261268\n",
      "After 30020th iteration, cost function is 10.8021343813\n",
      "After 30030th iteration, cost function is 10.2535689842\n",
      "After 30040th iteration, cost function is 10.6526764431\n",
      "After 30050th iteration, cost function is 10.1907933285\n",
      "After 30060th iteration, cost function is 9.18155328921\n",
      "After 30070th iteration, cost function is 10.645453013\n",
      "After 30080th iteration, cost function is 9.69595501265\n",
      "After 30090th iteration, cost function is 10.4014060275\n",
      "After 30100th iteration, cost function is 9.25580707343\n",
      "After 30110th iteration, cost function is 9.82288123285\n",
      "After 30120th iteration, cost function is 9.56719953226\n",
      "After 30130th iteration, cost function is 9.28282974085\n",
      "After 30140th iteration, cost function is 9.66586805466\n",
      "After 30150th iteration, cost function is 11.6824053561\n",
      "After 30160th iteration, cost function is 8.82608947882\n",
      "After 30170th iteration, cost function is 10.1627799153\n",
      "After 30180th iteration, cost function is 10.2705256239\n",
      "After 30190th iteration, cost function is 9.80255331711\n",
      "After 30200th iteration, cost function is 10.0276770194\n",
      "After 30210th iteration, cost function is 10.4003358911\n",
      "After 30220th iteration, cost function is 9.2364209851\n",
      "After 30230th iteration, cost function is 9.39510479005\n",
      "After 30240th iteration, cost function is 10.6456250386\n",
      "After 30250th iteration, cost function is 9.95478324167\n",
      "After 30260th iteration, cost function is 10.5432230225\n",
      "After 30270th iteration, cost function is 9.1363003966\n",
      "After 30280th iteration, cost function is 10.996351916\n",
      "After 30290th iteration, cost function is 9.59006691277\n",
      "After 30300th iteration, cost function is 10.0865941221\n",
      "After 30310th iteration, cost function is 10.4107269257\n",
      "After 30320th iteration, cost function is 10.2195921158\n",
      "After 30330th iteration, cost function is 10.0198414994\n",
      "After 30340th iteration, cost function is 11.0518474849\n",
      "After 30350th iteration, cost function is 10.9749617526\n",
      "After 30360th iteration, cost function is 9.88111601839\n",
      "After 30370th iteration, cost function is 9.54938968374\n",
      "After 30380th iteration, cost function is 9.53609390852\n",
      "After 30390th iteration, cost function is 8.87603784724\n",
      "After 30400th iteration, cost function is 8.84904842118\n",
      "After 30410th iteration, cost function is 8.7519536839\n",
      "After 30420th iteration, cost function is 8.65603566481\n",
      "After 30430th iteration, cost function is 11.0574263584\n",
      "After 30440th iteration, cost function is 9.4163950494\n",
      "After 30450th iteration, cost function is 9.89667762931\n",
      "After 30460th iteration, cost function is 10.0561718459\n",
      "After 30470th iteration, cost function is 10.2179205255\n",
      "After 30480th iteration, cost function is 8.96191179233\n",
      "After 30490th iteration, cost function is 10.4803741445\n",
      "After 30500th iteration, cost function is 8.59077521368\n",
      "After 30510th iteration, cost function is 10.1853238946\n",
      "After 30520th iteration, cost function is 8.52474067406\n",
      "After 30530th iteration, cost function is 9.99591855147\n",
      "After 30540th iteration, cost function is 9.3464833658\n",
      "After 30550th iteration, cost function is 9.0358201015\n",
      "After 30560th iteration, cost function is 10.4635954201\n",
      "After 30570th iteration, cost function is 9.92366517016\n",
      "After 30580th iteration, cost function is 9.37628215024\n",
      "After 30590th iteration, cost function is 10.4834960744\n",
      "After 30600th iteration, cost function is 10.3683611889\n",
      "After 30610th iteration, cost function is 8.31188784499\n",
      "After 30620th iteration, cost function is 7.84788638202\n",
      "After 30630th iteration, cost function is 10.0422857481\n",
      "After 30640th iteration, cost function is 9.96902151677\n",
      "After 30650th iteration, cost function is 9.85108262189\n",
      "After 30660th iteration, cost function is 9.13547390442\n",
      "After 30670th iteration, cost function is 9.90972820047\n",
      "After 30680th iteration, cost function is 10.2818976871\n",
      "After 30690th iteration, cost function is 11.2849395682\n",
      "After 30700th iteration, cost function is 9.51203933546\n",
      "After 30710th iteration, cost function is 10.2114548749\n",
      "After 30720th iteration, cost function is 10.2668278292\n",
      "After 30730th iteration, cost function is 9.06748624442\n",
      "After 30740th iteration, cost function is 9.61175552245\n",
      "After 30750th iteration, cost function is 11.298774926\n",
      "After 30760th iteration, cost function is 10.6948624461\n",
      "After 30770th iteration, cost function is 10.0915244425\n",
      "After 30780th iteration, cost function is 10.373635226\n",
      "After 30790th iteration, cost function is 9.20900803355\n",
      "After 30800th iteration, cost function is 10.0960213361\n",
      "After 30810th iteration, cost function is 9.57038715818\n",
      "After 30820th iteration, cost function is 10.8728102338\n",
      "After 30830th iteration, cost function is 10.3892470963\n",
      "After 30840th iteration, cost function is 10.3397400188\n",
      "After 30850th iteration, cost function is 10.1382546382\n",
      "After 30860th iteration, cost function is 9.07853848598\n",
      "After 30870th iteration, cost function is 10.1528073067\n",
      "After 30880th iteration, cost function is 8.05935148204\n",
      "After 30890th iteration, cost function is 10.8611271207\n",
      "After 30900th iteration, cost function is 10.4546842671\n",
      "After 30910th iteration, cost function is 10.8606530152\n",
      "After 30920th iteration, cost function is 10.1983477015\n",
      "After 30930th iteration, cost function is 10.9541038757\n",
      "After 30940th iteration, cost function is 10.6169464537\n",
      "After 30950th iteration, cost function is 10.239426971\n",
      "After 30960th iteration, cost function is 9.15344306079\n",
      "After 30970th iteration, cost function is 8.7166197545\n",
      "After 30980th iteration, cost function is 9.44623743127\n",
      "After 30990th iteration, cost function is 10.7076860829\n",
      "After 31000th iteration, cost function is 9.35287300815\n",
      "After 31010th iteration, cost function is 9.96887185675\n",
      "After 31020th iteration, cost function is 10.4925332427\n",
      "After 31030th iteration, cost function is 9.18375601173\n",
      "After 31040th iteration, cost function is 9.61139945085\n",
      "After 31050th iteration, cost function is 9.90320305694\n",
      "After 31060th iteration, cost function is 9.29346749735\n",
      "After 31070th iteration, cost function is 10.9761958567\n",
      "After 31080th iteration, cost function is 9.39906534057\n",
      "After 31090th iteration, cost function is 11.2396180472\n",
      "After 31100th iteration, cost function is 8.87535568259\n",
      "After 31110th iteration, cost function is 8.79590447553\n",
      "After 31120th iteration, cost function is 10.5451902036\n",
      "After 31130th iteration, cost function is 9.87542236407\n",
      "After 31140th iteration, cost function is 10.4888297736\n",
      "After 31150th iteration, cost function is 11.355201694\n",
      "After 31160th iteration, cost function is 10.8272662278\n",
      "After 31170th iteration, cost function is 9.07481710701\n",
      "After 31180th iteration, cost function is 9.0553330565\n",
      "After 31190th iteration, cost function is 10.7919909123\n",
      "After 31200th iteration, cost function is 10.273886577\n",
      "After 31210th iteration, cost function is 10.5316262239\n",
      "After 31220th iteration, cost function is 10.2855628634\n",
      "After 31230th iteration, cost function is 9.21859642544\n",
      "After 31240th iteration, cost function is 9.29776375311\n",
      "After 31250th iteration, cost function is 9.49009011631\n",
      "After 31260th iteration, cost function is 10.229650601\n",
      "After 31270th iteration, cost function is 9.76694128223\n",
      "After 31280th iteration, cost function is 10.6860488543\n",
      "After 31290th iteration, cost function is 9.01890341893\n",
      "After 31300th iteration, cost function is 8.26789605123\n",
      "After 31310th iteration, cost function is 9.94482885692\n",
      "After 31320th iteration, cost function is 9.3799106742\n",
      "After 31330th iteration, cost function is 10.2441281664\n",
      "After 31340th iteration, cost function is 9.93124613639\n",
      "After 31350th iteration, cost function is 10.138115391\n",
      "After 31360th iteration, cost function is 10.1610956306\n",
      "After 31370th iteration, cost function is 10.415574733\n",
      "After 31380th iteration, cost function is 10.0378639215\n",
      "After 31390th iteration, cost function is 9.97246618492\n",
      "After 31400th iteration, cost function is 10.8766241779\n",
      "After 31410th iteration, cost function is 10.4415070867\n",
      "After 31420th iteration, cost function is 9.20603020429\n",
      "After 31430th iteration, cost function is 9.15193495507\n",
      "After 31440th iteration, cost function is 9.46631974502\n",
      "After 31450th iteration, cost function is 8.95836998528\n",
      "After 31460th iteration, cost function is 8.74738293877\n",
      "After 31470th iteration, cost function is 8.78651429286\n",
      "After 31480th iteration, cost function is 10.0292414067\n",
      "After 31490th iteration, cost function is 9.40768900481\n",
      "After 31500th iteration, cost function is 10.8390282744\n",
      "After 31510th iteration, cost function is 9.3253286605\n",
      "After 31520th iteration, cost function is 9.96650160787\n",
      "After 31530th iteration, cost function is 8.35918394759\n",
      "After 31540th iteration, cost function is 10.2433748114\n",
      "After 31550th iteration, cost function is 11.2116411657\n",
      "After 31560th iteration, cost function is 10.3033179907\n",
      "After 31570th iteration, cost function is 11.6545175915\n",
      "After 31580th iteration, cost function is 9.23736390696\n",
      "After 31590th iteration, cost function is 9.53955550382\n",
      "After 31600th iteration, cost function is 8.39879943162\n",
      "After 31610th iteration, cost function is 11.3569812664\n",
      "After 31620th iteration, cost function is 9.14580247971\n",
      "After 31630th iteration, cost function is 10.2683655219\n",
      "After 31640th iteration, cost function is 8.33188808152\n",
      "After 31650th iteration, cost function is 9.94645759428\n",
      "After 31660th iteration, cost function is 8.94381405152\n",
      "After 31670th iteration, cost function is 9.68360406981\n",
      "After 31680th iteration, cost function is 9.17028462617\n",
      "After 31690th iteration, cost function is 9.03355369795\n",
      "After 31700th iteration, cost function is 7.93767215871\n",
      "After 31710th iteration, cost function is 9.08773756178\n",
      "After 31720th iteration, cost function is 8.88920875392\n",
      "After 31730th iteration, cost function is 8.90706906302\n",
      "After 31740th iteration, cost function is 10.2417823003\n",
      "After 31750th iteration, cost function is 10.1897432876\n",
      "After 31760th iteration, cost function is 9.8144192193\n",
      "After 31770th iteration, cost function is 10.6729321062\n",
      "After 31780th iteration, cost function is 9.39058654233\n",
      "After 31790th iteration, cost function is 10.6031554475\n",
      "After 31800th iteration, cost function is 10.2556675875\n",
      "After 31810th iteration, cost function is 9.26047302712\n",
      "After 31820th iteration, cost function is 10.7948977351\n",
      "After 31830th iteration, cost function is 9.34854140822\n",
      "After 31840th iteration, cost function is 8.81364432982\n",
      "After 31850th iteration, cost function is 8.75205664099\n",
      "After 31860th iteration, cost function is 8.42111868917\n",
      "After 31870th iteration, cost function is 9.91759216468\n",
      "After 31880th iteration, cost function is 10.5091971374\n",
      "After 31890th iteration, cost function is 7.98069435789\n",
      "After 31900th iteration, cost function is 9.73642519532\n",
      "After 31910th iteration, cost function is 8.86412737398\n",
      "After 31920th iteration, cost function is 9.00144790306\n",
      "After 31930th iteration, cost function is 11.2614808176\n",
      "After 31940th iteration, cost function is 10.3871264818\n",
      "After 31950th iteration, cost function is 9.26867264364\n",
      "After 31960th iteration, cost function is 10.3932984145\n",
      "After 31970th iteration, cost function is 10.1846173701\n",
      "After 31980th iteration, cost function is 10.488390944\n",
      "After 31990th iteration, cost function is 10.4110320977\n",
      "After 32000th iteration, cost function is 9.58127430653\n",
      "After 32010th iteration, cost function is 10.5341146936\n",
      "After 32020th iteration, cost function is 9.49388353612\n",
      "After 32030th iteration, cost function is 9.30210564721\n",
      "After 32040th iteration, cost function is 8.91800040712\n",
      "After 32050th iteration, cost function is 10.1876880478\n",
      "After 32060th iteration, cost function is 9.64445719126\n",
      "After 32070th iteration, cost function is 8.87102281916\n",
      "After 32080th iteration, cost function is 8.32996753782\n",
      "After 32090th iteration, cost function is 9.6992379635\n",
      "After 32100th iteration, cost function is 9.82065516095\n",
      "After 32110th iteration, cost function is 9.74779652279\n",
      "After 32120th iteration, cost function is 10.0613286632\n",
      "After 32130th iteration, cost function is 8.64910859871\n",
      "After 32140th iteration, cost function is 9.09835730636\n",
      "After 32150th iteration, cost function is 8.42777318398\n",
      "After 32160th iteration, cost function is 9.70268473469\n",
      "After 32170th iteration, cost function is 10.7813289594\n",
      "After 32180th iteration, cost function is 9.36499349077\n",
      "After 32190th iteration, cost function is 9.97592312691\n",
      "After 32200th iteration, cost function is 9.25547647628\n",
      "After 32210th iteration, cost function is 9.80796978581\n",
      "After 32220th iteration, cost function is 9.50167005124\n",
      "After 32230th iteration, cost function is 9.90638579675\n",
      "After 32240th iteration, cost function is 9.86027341277\n",
      "After 32250th iteration, cost function is 7.66429917512\n",
      "After 32260th iteration, cost function is 9.01001130114\n",
      "After 32270th iteration, cost function is 10.4219170221\n",
      "After 32280th iteration, cost function is 9.21620729141\n",
      "After 32290th iteration, cost function is 9.9867887177\n",
      "After 32300th iteration, cost function is 9.46536985301\n",
      "After 32310th iteration, cost function is 10.2913432265\n",
      "After 32320th iteration, cost function is 10.0889835416\n",
      "After 32330th iteration, cost function is 10.3808009028\n",
      "After 32340th iteration, cost function is 9.58881768938\n",
      "After 32350th iteration, cost function is 10.9340697377\n",
      "After 32360th iteration, cost function is 9.51569213424\n",
      "After 32370th iteration, cost function is 10.3233213725\n",
      "After 32380th iteration, cost function is 9.03180235873\n",
      "After 32390th iteration, cost function is 8.07058992664\n",
      "After 32400th iteration, cost function is 11.3220003958\n",
      "After 32410th iteration, cost function is 10.454393395\n",
      "After 32420th iteration, cost function is 9.96981285627\n",
      "After 32430th iteration, cost function is 10.3819136826\n",
      "After 32440th iteration, cost function is 10.7167015421\n",
      "After 32450th iteration, cost function is 10.0987989532\n",
      "After 32460th iteration, cost function is 9.6691685509\n",
      "After 32470th iteration, cost function is 10.0699602657\n",
      "After 32480th iteration, cost function is 9.98536435255\n",
      "After 32490th iteration, cost function is 9.99341556145\n",
      "After 32500th iteration, cost function is 8.65180850616\n",
      "After 32510th iteration, cost function is 9.58883798984\n",
      "After 32520th iteration, cost function is 8.23577358027\n",
      "After 32530th iteration, cost function is 9.46761493342\n",
      "After 32540th iteration, cost function is 8.84497819883\n",
      "After 32550th iteration, cost function is 11.2350352023\n",
      "After 32560th iteration, cost function is 8.6035673157\n",
      "After 32570th iteration, cost function is 11.0091984394\n",
      "After 32580th iteration, cost function is 9.5637122433\n",
      "After 32590th iteration, cost function is 9.00119283595\n",
      "After 32600th iteration, cost function is 9.35042934469\n",
      "After 32610th iteration, cost function is 9.85471645877\n",
      "After 32620th iteration, cost function is 10.4042702224\n",
      "After 32630th iteration, cost function is 9.70308388007\n",
      "After 32640th iteration, cost function is 9.54435151756\n",
      "After 32650th iteration, cost function is 11.3298358814\n",
      "After 32660th iteration, cost function is 9.41111801209\n",
      "After 32670th iteration, cost function is 9.66281462324\n",
      "After 32680th iteration, cost function is 9.33568949655\n",
      "After 32690th iteration, cost function is 8.82956161105\n",
      "After 32700th iteration, cost function is 10.5586015795\n",
      "After 32710th iteration, cost function is 9.16389291608\n",
      "After 32720th iteration, cost function is 9.34806227151\n",
      "After 32730th iteration, cost function is 10.8071571088\n",
      "After 32740th iteration, cost function is 9.59894004273\n",
      "After 32750th iteration, cost function is 8.01090396381\n",
      "After 32760th iteration, cost function is 7.81309219132\n",
      "After 32770th iteration, cost function is 10.4228295468\n",
      "After 32780th iteration, cost function is 8.44047066973\n",
      "After 32790th iteration, cost function is 10.3648666459\n",
      "After 32800th iteration, cost function is 9.66313969043\n",
      "After 32810th iteration, cost function is 9.78892963062\n",
      "After 32820th iteration, cost function is 9.746891516\n",
      "After 32830th iteration, cost function is 9.51206618883\n",
      "After 32840th iteration, cost function is 10.1532002447\n",
      "After 32850th iteration, cost function is 11.0782267149\n",
      "After 32860th iteration, cost function is 9.73651231085\n",
      "After 32870th iteration, cost function is 10.280394681\n",
      "After 32880th iteration, cost function is 9.43266394413\n",
      "After 32890th iteration, cost function is 10.0428348297\n",
      "After 32900th iteration, cost function is 9.54621741681\n",
      "After 32910th iteration, cost function is 8.47330854233\n",
      "After 32920th iteration, cost function is 10.9998426852\n",
      "After 32930th iteration, cost function is 10.3663575119\n",
      "After 32940th iteration, cost function is 9.22195689233\n",
      "After 32950th iteration, cost function is 10.4421420096\n",
      "After 32960th iteration, cost function is 9.87514626011\n",
      "After 32970th iteration, cost function is 8.52195743786\n",
      "After 32980th iteration, cost function is 9.74572442837\n",
      "After 32990th iteration, cost function is 8.75415474722\n",
      "After 33000th iteration, cost function is 9.08525809074\n",
      "After 33010th iteration, cost function is 10.5503573702\n",
      "After 33020th iteration, cost function is 10.0318526096\n",
      "After 33030th iteration, cost function is 9.72838984472\n",
      "After 33040th iteration, cost function is 9.39875219477\n",
      "After 33050th iteration, cost function is 9.17634470209\n",
      "After 33060th iteration, cost function is 9.3172939934\n",
      "After 33070th iteration, cost function is 9.04217779685\n",
      "After 33080th iteration, cost function is 10.0690459664\n",
      "After 33090th iteration, cost function is 9.04772444847\n",
      "After 33100th iteration, cost function is 9.45466772619\n",
      "After 33110th iteration, cost function is 10.1183407066\n",
      "After 33120th iteration, cost function is 10.4653779562\n",
      "After 33130th iteration, cost function is 9.89973782983\n",
      "After 33140th iteration, cost function is 9.02726568037\n",
      "After 33150th iteration, cost function is 9.41461353002\n",
      "After 33160th iteration, cost function is 9.99980337207\n",
      "After 33170th iteration, cost function is 8.83797415691\n",
      "After 33180th iteration, cost function is 9.78864534569\n",
      "After 33190th iteration, cost function is 9.92743580699\n",
      "After 33200th iteration, cost function is 10.3869543676\n",
      "After 33210th iteration, cost function is 10.2815301511\n",
      "After 33220th iteration, cost function is 8.89589692783\n",
      "After 33230th iteration, cost function is 9.8560259857\n",
      "After 33240th iteration, cost function is 9.61138076884\n",
      "After 33250th iteration, cost function is 9.48893767545\n",
      "After 33260th iteration, cost function is 7.83742952222\n",
      "After 33270th iteration, cost function is 9.70488239194\n",
      "After 33280th iteration, cost function is 10.4675138506\n",
      "After 33290th iteration, cost function is 9.54226780616\n",
      "After 33300th iteration, cost function is 9.76055501998\n",
      "After 33310th iteration, cost function is 9.00170208868\n",
      "After 33320th iteration, cost function is 10.3926232217\n",
      "After 33330th iteration, cost function is 9.0298910891\n",
      "After 33340th iteration, cost function is 9.55283297204\n",
      "After 33350th iteration, cost function is 9.7542186179\n",
      "After 33360th iteration, cost function is 11.3128585546\n",
      "After 33370th iteration, cost function is 10.5896438904\n",
      "After 33380th iteration, cost function is 10.0958651687\n",
      "After 33390th iteration, cost function is 10.5122095947\n",
      "After 33400th iteration, cost function is 9.11604573654\n",
      "After 33410th iteration, cost function is 10.2053812803\n",
      "After 33420th iteration, cost function is 8.29510971498\n",
      "After 33430th iteration, cost function is 10.446428696\n",
      "After 33440th iteration, cost function is 10.5950456208\n",
      "After 33450th iteration, cost function is 8.64499085764\n",
      "After 33460th iteration, cost function is 8.5143109464\n",
      "After 33470th iteration, cost function is 9.29439488597\n",
      "After 33480th iteration, cost function is 10.0783711633\n",
      "After 33490th iteration, cost function is 9.93890868799\n",
      "After 33500th iteration, cost function is 10.4959796148\n",
      "After 33510th iteration, cost function is 9.1701591783\n",
      "After 33520th iteration, cost function is 10.2470352068\n",
      "After 33530th iteration, cost function is 10.1727796235\n",
      "After 33540th iteration, cost function is 10.2778315094\n",
      "After 33550th iteration, cost function is 9.61487727502\n",
      "After 33560th iteration, cost function is 8.51417489558\n",
      "After 33570th iteration, cost function is 9.44744477284\n",
      "After 33580th iteration, cost function is 9.96567183898\n",
      "After 33590th iteration, cost function is 9.81945553636\n",
      "After 33600th iteration, cost function is 9.87405286892\n",
      "After 33610th iteration, cost function is 10.7019981921\n",
      "After 33620th iteration, cost function is 8.53372010596\n",
      "After 33630th iteration, cost function is 10.2800155866\n",
      "After 33640th iteration, cost function is 10.2998855699\n",
      "After 33650th iteration, cost function is 10.4125630809\n",
      "After 33660th iteration, cost function is 8.34868180472\n",
      "After 33670th iteration, cost function is 8.78744069773\n",
      "After 33680th iteration, cost function is 8.22722786238\n",
      "After 33690th iteration, cost function is 10.8990183044\n",
      "After 33700th iteration, cost function is 9.0532145681\n",
      "After 33710th iteration, cost function is 10.0965841238\n",
      "After 33720th iteration, cost function is 9.97869364822\n",
      "After 33730th iteration, cost function is 9.40518504198\n",
      "After 33740th iteration, cost function is 8.17786862669\n",
      "After 33750th iteration, cost function is 9.61301498161\n",
      "After 33760th iteration, cost function is 11.2224241188\n",
      "After 33770th iteration, cost function is 9.71242352297\n",
      "After 33780th iteration, cost function is 8.39716096024\n",
      "After 33790th iteration, cost function is 10.3281933448\n",
      "After 33800th iteration, cost function is 8.97821890996\n",
      "After 33810th iteration, cost function is 10.1138740151\n",
      "After 33820th iteration, cost function is 10.0379665104\n",
      "After 33830th iteration, cost function is 9.81325936637\n",
      "After 33840th iteration, cost function is 9.54579498021\n",
      "After 33850th iteration, cost function is 9.32487760729\n",
      "After 33860th iteration, cost function is 9.43267776888\n",
      "After 33870th iteration, cost function is 10.4769775569\n",
      "After 33880th iteration, cost function is 9.60597081377\n",
      "After 33890th iteration, cost function is 8.00224505369\n",
      "After 33900th iteration, cost function is 8.89035548721\n",
      "After 33910th iteration, cost function is 10.7916383202\n",
      "After 33920th iteration, cost function is 11.7316007761\n",
      "After 33930th iteration, cost function is 8.95880326176\n",
      "After 33940th iteration, cost function is 9.07778382479\n",
      "After 33950th iteration, cost function is 8.90591894114\n",
      "After 33960th iteration, cost function is 10.3580277566\n",
      "After 33970th iteration, cost function is 10.6227036415\n",
      "After 33980th iteration, cost function is 8.74257250539\n",
      "After 33990th iteration, cost function is 9.4087475772\n",
      "After 34000th iteration, cost function is 9.45228206956\n",
      "After 34010th iteration, cost function is 8.90855354468\n",
      "After 34020th iteration, cost function is 8.77000152736\n",
      "After 34030th iteration, cost function is 9.65162318699\n",
      "After 34040th iteration, cost function is 9.36271096391\n",
      "After 34050th iteration, cost function is 9.87331480144\n",
      "After 34060th iteration, cost function is 8.74567253031\n",
      "After 34070th iteration, cost function is 10.2139523551\n",
      "After 34080th iteration, cost function is 9.07599628201\n",
      "After 34090th iteration, cost function is 8.64335664116\n",
      "After 34100th iteration, cost function is 8.77744149729\n",
      "After 34110th iteration, cost function is 8.32221693832\n",
      "After 34120th iteration, cost function is 10.9882313499\n",
      "After 34130th iteration, cost function is 9.95476672691\n",
      "After 34140th iteration, cost function is 11.4649847367\n",
      "After 34150th iteration, cost function is 9.39353987146\n",
      "After 34160th iteration, cost function is 9.01643132337\n",
      "After 34170th iteration, cost function is 9.98747507251\n",
      "After 34180th iteration, cost function is 10.2191405237\n",
      "After 34190th iteration, cost function is 9.95568649929\n",
      "After 34200th iteration, cost function is 9.59787266352\n",
      "After 34210th iteration, cost function is 11.5726834713\n",
      "After 34220th iteration, cost function is 10.2622116209\n",
      "After 34230th iteration, cost function is 9.28290101719\n",
      "After 34240th iteration, cost function is 9.07526989214\n",
      "After 34250th iteration, cost function is 9.57779783133\n",
      "After 34260th iteration, cost function is 9.67750438264\n",
      "After 34270th iteration, cost function is 9.67216479907\n",
      "After 34280th iteration, cost function is 10.3716984856\n",
      "After 34290th iteration, cost function is 10.5608701192\n",
      "After 34300th iteration, cost function is 8.76220910084\n",
      "After 34310th iteration, cost function is 10.2535915378\n",
      "After 34320th iteration, cost function is 10.6917624298\n",
      "After 34330th iteration, cost function is 10.3140921509\n",
      "After 34340th iteration, cost function is 9.62255310698\n",
      "After 34350th iteration, cost function is 9.25296535922\n",
      "After 34360th iteration, cost function is 11.0011408917\n",
      "After 34370th iteration, cost function is 9.57197960406\n",
      "After 34380th iteration, cost function is 10.6773311614\n",
      "After 34390th iteration, cost function is 8.92087021745\n",
      "After 34400th iteration, cost function is 10.1055271767\n",
      "After 34410th iteration, cost function is 9.38793953209\n",
      "After 34420th iteration, cost function is 8.43517965538\n",
      "After 34430th iteration, cost function is 8.67418658052\n",
      "After 34440th iteration, cost function is 10.2551353277\n",
      "After 34450th iteration, cost function is 9.43367447238\n",
      "After 34460th iteration, cost function is 10.1756064678\n",
      "After 34470th iteration, cost function is 9.90358084245\n",
      "After 34480th iteration, cost function is 11.2296198206\n",
      "After 34490th iteration, cost function is 9.03501978838\n",
      "After 34500th iteration, cost function is 9.3847164558\n",
      "After 34510th iteration, cost function is 8.80788557333\n",
      "After 34520th iteration, cost function is 11.1799915886\n",
      "After 34530th iteration, cost function is 11.5834604971\n",
      "After 34540th iteration, cost function is 12.5474624516\n",
      "After 34550th iteration, cost function is 9.44259733831\n",
      "After 34560th iteration, cost function is 10.432562757\n",
      "After 34570th iteration, cost function is 10.7795106144\n",
      "After 34580th iteration, cost function is 9.46523658569\n",
      "After 34590th iteration, cost function is 12.2785598027\n",
      "After 34600th iteration, cost function is 10.9170565842\n",
      "After 34610th iteration, cost function is 11.1177911064\n",
      "After 34620th iteration, cost function is 9.56056813408\n",
      "After 34630th iteration, cost function is 9.53803164642\n",
      "After 34640th iteration, cost function is 8.66307662915\n",
      "After 34650th iteration, cost function is 9.96488077032\n",
      "After 34660th iteration, cost function is 10.4901512838\n",
      "After 34670th iteration, cost function is 9.22635575077\n",
      "After 34680th iteration, cost function is 10.3860304755\n",
      "After 34690th iteration, cost function is 9.07107005604\n",
      "After 34700th iteration, cost function is 8.79196593242\n",
      "After 34710th iteration, cost function is 9.6924144881\n",
      "After 34720th iteration, cost function is 9.44278278133\n",
      "After 34730th iteration, cost function is 8.08852360458\n",
      "After 34740th iteration, cost function is 9.21666209861\n",
      "After 34750th iteration, cost function is 11.1303826969\n",
      "After 34760th iteration, cost function is 9.27656801008\n",
      "After 34770th iteration, cost function is 10.1847540691\n",
      "After 34780th iteration, cost function is 9.36207838433\n",
      "After 34790th iteration, cost function is 9.52186892569\n",
      "After 34800th iteration, cost function is 11.573557008\n",
      "After 34810th iteration, cost function is 9.64719809815\n",
      "After 34820th iteration, cost function is 10.2926498136\n",
      "After 34830th iteration, cost function is 10.6867187983\n",
      "After 34840th iteration, cost function is 11.062623848\n",
      "After 34850th iteration, cost function is 10.8524874407\n",
      "After 34860th iteration, cost function is 10.0311488469\n",
      "After 34870th iteration, cost function is 9.5697787014\n",
      "After 34880th iteration, cost function is 10.5152015646\n",
      "After 34890th iteration, cost function is 9.07834048396\n",
      "After 34900th iteration, cost function is 9.06191651176\n",
      "After 34910th iteration, cost function is 8.40923581644\n",
      "After 34920th iteration, cost function is 10.1316964822\n",
      "After 34930th iteration, cost function is 9.82405160674\n",
      "After 34940th iteration, cost function is 10.1551065687\n",
      "After 34950th iteration, cost function is 9.9429730425\n",
      "After 34960th iteration, cost function is 10.0927850372\n",
      "After 34970th iteration, cost function is 11.7545387408\n",
      "After 34980th iteration, cost function is 8.84374071339\n",
      "After 34990th iteration, cost function is 8.45900093059\n",
      "After 35000th iteration, cost function is 9.62019426176\n",
      "After 35010th iteration, cost function is 9.07758916804\n",
      "After 35020th iteration, cost function is 10.81839396\n",
      "After 35030th iteration, cost function is 8.68040213958\n",
      "After 35040th iteration, cost function is 9.52666383957\n",
      "After 35050th iteration, cost function is 9.50942686596\n",
      "After 35060th iteration, cost function is 10.3829969809\n",
      "After 35070th iteration, cost function is 8.98447411258\n",
      "After 35080th iteration, cost function is 11.2714399707\n",
      "After 35090th iteration, cost function is 9.03822073517\n",
      "After 35100th iteration, cost function is 7.86242245746\n",
      "After 35110th iteration, cost function is 9.51088525638\n",
      "After 35120th iteration, cost function is 10.4367651264\n",
      "After 35130th iteration, cost function is 9.40976761286\n",
      "After 35140th iteration, cost function is 9.06069333401\n",
      "After 35150th iteration, cost function is 9.54642801929\n",
      "After 35160th iteration, cost function is 8.40575669504\n",
      "After 35170th iteration, cost function is 8.35066211662\n",
      "After 35180th iteration, cost function is 9.05689743799\n",
      "After 35190th iteration, cost function is 8.53992045656\n",
      "After 35200th iteration, cost function is 9.6006234046\n",
      "After 35210th iteration, cost function is 10.8358245314\n",
      "After 35220th iteration, cost function is 8.61242483881\n",
      "After 35230th iteration, cost function is 9.13036796271\n",
      "After 35240th iteration, cost function is 8.37331127916\n",
      "After 35250th iteration, cost function is 8.35114769686\n",
      "After 35260th iteration, cost function is 10.2029272557\n",
      "After 35270th iteration, cost function is 9.34277736074\n",
      "After 35280th iteration, cost function is 8.15113126254\n",
      "After 35290th iteration, cost function is 10.5612993257\n",
      "After 35300th iteration, cost function is 9.63405339475\n",
      "After 35310th iteration, cost function is 9.93389480285\n",
      "After 35320th iteration, cost function is 11.0943030183\n",
      "After 35330th iteration, cost function is 9.81577747758\n",
      "After 35340th iteration, cost function is 10.4053518244\n",
      "After 35350th iteration, cost function is 11.3593017003\n",
      "After 35360th iteration, cost function is 8.80342019662\n",
      "After 35370th iteration, cost function is 8.49435402756\n",
      "After 35380th iteration, cost function is 10.0315911791\n",
      "After 35390th iteration, cost function is 10.162094259\n",
      "After 35400th iteration, cost function is 10.9914487739\n",
      "After 35410th iteration, cost function is 8.99090609083\n",
      "After 35420th iteration, cost function is 10.0559422959\n",
      "After 35430th iteration, cost function is 9.2342673434\n",
      "After 35440th iteration, cost function is 10.3343592788\n",
      "After 35450th iteration, cost function is 9.67502695093\n",
      "After 35460th iteration, cost function is 9.9980625508\n",
      "After 35470th iteration, cost function is 9.87142654382\n",
      "After 35480th iteration, cost function is 9.08574596139\n",
      "After 35490th iteration, cost function is 10.0104570888\n",
      "After 35500th iteration, cost function is 9.38945904141\n",
      "After 35510th iteration, cost function is 9.44267045587\n",
      "After 35520th iteration, cost function is 10.5495029109\n",
      "After 35530th iteration, cost function is 10.361068724\n",
      "After 35540th iteration, cost function is 10.9019515843\n",
      "After 35550th iteration, cost function is 8.98379617953\n",
      "After 35560th iteration, cost function is 9.91233892894\n",
      "After 35570th iteration, cost function is 9.1900490931\n",
      "After 35580th iteration, cost function is 9.83248030856\n",
      "After 35590th iteration, cost function is 10.3137122538\n",
      "After 35600th iteration, cost function is 9.4246972517\n",
      "After 35610th iteration, cost function is 9.5324124358\n",
      "After 35620th iteration, cost function is 9.9983023235\n",
      "After 35630th iteration, cost function is 9.52628887268\n",
      "After 35640th iteration, cost function is 9.14790139842\n",
      "After 35650th iteration, cost function is 8.86945643371\n",
      "After 35660th iteration, cost function is 8.65888303088\n",
      "After 35670th iteration, cost function is 8.75045241195\n",
      "After 35680th iteration, cost function is 9.51603797536\n",
      "After 35690th iteration, cost function is 9.99370842516\n",
      "After 35700th iteration, cost function is 9.84208707682\n",
      "After 35710th iteration, cost function is 8.83403320373\n",
      "After 35720th iteration, cost function is 9.9377374838\n",
      "After 35730th iteration, cost function is 9.14023402345\n",
      "After 35740th iteration, cost function is 11.0749068123\n",
      "After 35750th iteration, cost function is 8.21316182931\n",
      "After 35760th iteration, cost function is 9.38109229465\n",
      "After 35770th iteration, cost function is 8.99127667544\n",
      "After 35780th iteration, cost function is 10.8843552826\n",
      "After 35790th iteration, cost function is 9.6353238555\n",
      "After 35800th iteration, cost function is 10.1645701781\n",
      "After 35810th iteration, cost function is 12.0347492416\n",
      "After 35820th iteration, cost function is 9.29525969401\n",
      "After 35830th iteration, cost function is 8.38138093187\n",
      "After 35840th iteration, cost function is 11.2866472361\n",
      "After 35850th iteration, cost function is 9.68035087893\n",
      "After 35860th iteration, cost function is 9.77616158455\n",
      "After 35870th iteration, cost function is 8.63277090777\n",
      "After 35880th iteration, cost function is 8.30593270366\n",
      "After 35890th iteration, cost function is 11.4497879376\n",
      "After 35900th iteration, cost function is 10.0428713148\n",
      "After 35910th iteration, cost function is 9.77455774552\n",
      "After 35920th iteration, cost function is 8.99307778791\n",
      "After 35930th iteration, cost function is 9.15590516745\n",
      "After 35940th iteration, cost function is 9.28140437424\n",
      "After 35950th iteration, cost function is 9.01605639024\n",
      "After 35960th iteration, cost function is 11.3677339997\n",
      "After 35970th iteration, cost function is 9.25679954564\n",
      "After 35980th iteration, cost function is 11.4168688426\n",
      "After 35990th iteration, cost function is 8.56640765388\n",
      "After 36000th iteration, cost function is 10.0393395524\n",
      "After 36010th iteration, cost function is 9.02906917782\n",
      "After 36020th iteration, cost function is 9.74771979446\n",
      "After 36030th iteration, cost function is 8.41719535691\n",
      "After 36040th iteration, cost function is 8.83962917959\n",
      "After 36050th iteration, cost function is 9.15326730739\n",
      "After 36060th iteration, cost function is 9.71205484097\n",
      "After 36070th iteration, cost function is 10.3454658823\n",
      "After 36080th iteration, cost function is 9.55481630716\n",
      "After 36090th iteration, cost function is 9.49951026405\n",
      "After 36100th iteration, cost function is 9.72594046613\n",
      "After 36110th iteration, cost function is 10.559431649\n",
      "After 36120th iteration, cost function is 8.65412204667\n",
      "After 36130th iteration, cost function is 8.3323753473\n",
      "After 36140th iteration, cost function is 7.61192163867\n",
      "After 36150th iteration, cost function is 10.9537469789\n",
      "After 36160th iteration, cost function is 10.7276443612\n",
      "After 36170th iteration, cost function is 8.99933712708\n",
      "After 36180th iteration, cost function is 9.67060515456\n",
      "After 36190th iteration, cost function is 9.11974930989\n",
      "After 36200th iteration, cost function is 8.11996800283\n",
      "After 36210th iteration, cost function is 10.8209525539\n",
      "After 36220th iteration, cost function is 9.08163115081\n",
      "After 36230th iteration, cost function is 10.1217424714\n",
      "After 36240th iteration, cost function is 8.84418401341\n",
      "After 36250th iteration, cost function is 10.4784654463\n",
      "After 36260th iteration, cost function is 8.78214052734\n",
      "After 36270th iteration, cost function is 9.15547704676\n",
      "After 36280th iteration, cost function is 11.1353611647\n",
      "After 36290th iteration, cost function is 9.88757975749\n",
      "After 36300th iteration, cost function is 10.3376937676\n",
      "After 36310th iteration, cost function is 8.88999178973\n",
      "After 36320th iteration, cost function is 9.12320370464\n",
      "After 36330th iteration, cost function is 9.86779119493\n",
      "After 36340th iteration, cost function is 9.63371652743\n",
      "After 36350th iteration, cost function is 9.01938900307\n",
      "After 36360th iteration, cost function is 9.88382857044\n",
      "After 36370th iteration, cost function is 10.2722910931\n",
      "After 36380th iteration, cost function is 9.47870142363\n",
      "After 36390th iteration, cost function is 10.0418769836\n",
      "After 36400th iteration, cost function is 10.844145706\n",
      "After 36410th iteration, cost function is 9.85858959801\n",
      "After 36420th iteration, cost function is 9.6352684417\n",
      "After 36430th iteration, cost function is 9.54229380521\n",
      "After 36440th iteration, cost function is 10.1369355944\n",
      "After 36450th iteration, cost function is 10.1125876466\n",
      "After 36460th iteration, cost function is 10.8632495339\n",
      "After 36470th iteration, cost function is 10.3934757465\n",
      "After 36480th iteration, cost function is 8.00491744846\n",
      "After 36490th iteration, cost function is 8.8626885443\n",
      "After 36500th iteration, cost function is 9.09237444334\n",
      "After 36510th iteration, cost function is 10.3814609746\n",
      "After 36520th iteration, cost function is 8.92228786664\n",
      "After 36530th iteration, cost function is 9.61493118814\n",
      "After 36540th iteration, cost function is 9.05120000751\n",
      "After 36550th iteration, cost function is 9.85658730008\n",
      "After 36560th iteration, cost function is 9.51973489945\n",
      "After 36570th iteration, cost function is 9.58351285791\n",
      "After 36580th iteration, cost function is 11.1016468018\n",
      "After 36590th iteration, cost function is 11.0863866723\n",
      "After 36600th iteration, cost function is 10.0502971418\n",
      "After 36610th iteration, cost function is 7.10223049955\n",
      "After 36620th iteration, cost function is 11.0730322109\n",
      "After 36630th iteration, cost function is 8.98882871927\n",
      "After 36640th iteration, cost function is 9.43407063283\n",
      "After 36650th iteration, cost function is 10.2708162071\n",
      "After 36660th iteration, cost function is 8.93308105507\n",
      "After 36670th iteration, cost function is 9.36949394578\n",
      "After 36680th iteration, cost function is 10.8896449933\n",
      "After 36690th iteration, cost function is 9.61437855338\n",
      "After 36700th iteration, cost function is 9.13900999891\n",
      "After 36710th iteration, cost function is 10.44167086\n",
      "After 36720th iteration, cost function is 9.169799738\n",
      "After 36730th iteration, cost function is 9.19659737552\n",
      "After 36740th iteration, cost function is 10.4110780261\n",
      "After 36750th iteration, cost function is 8.71369068815\n",
      "After 36760th iteration, cost function is 11.0662888234\n",
      "After 36770th iteration, cost function is 10.1189367966\n",
      "After 36780th iteration, cost function is 8.97538980323\n",
      "After 36790th iteration, cost function is 10.0325350406\n",
      "After 36800th iteration, cost function is 10.9144076729\n",
      "After 36810th iteration, cost function is 9.46584592916\n",
      "After 36820th iteration, cost function is 8.79262392978\n",
      "After 36830th iteration, cost function is 9.81923818539\n",
      "After 36840th iteration, cost function is 9.47712288291\n",
      "After 36850th iteration, cost function is 10.3473888688\n",
      "After 36860th iteration, cost function is 10.077794553\n",
      "After 36870th iteration, cost function is 8.42816713661\n",
      "After 36880th iteration, cost function is 9.13336140011\n",
      "After 36890th iteration, cost function is 9.35169899583\n",
      "After 36900th iteration, cost function is 8.53052968361\n",
      "After 36910th iteration, cost function is 11.6551056187\n",
      "After 36920th iteration, cost function is 8.36117186439\n",
      "After 36930th iteration, cost function is 9.25353577596\n",
      "After 36940th iteration, cost function is 9.65649110059\n",
      "After 36950th iteration, cost function is 7.42608655556\n",
      "After 36960th iteration, cost function is 9.38172995554\n",
      "After 36970th iteration, cost function is 10.3739517322\n",
      "After 36980th iteration, cost function is 10.6290567868\n",
      "After 36990th iteration, cost function is 10.1260750942\n",
      "After 37000th iteration, cost function is 10.6479841684\n",
      "After 37010th iteration, cost function is 9.40166729628\n",
      "After 37020th iteration, cost function is 8.88791299693\n",
      "After 37030th iteration, cost function is 10.8895194406\n",
      "After 37040th iteration, cost function is 10.4470551579\n",
      "After 37050th iteration, cost function is 12.1643545979\n",
      "After 37060th iteration, cost function is 9.93096912249\n",
      "After 37070th iteration, cost function is 9.23164186231\n",
      "After 37080th iteration, cost function is 9.24047210269\n",
      "After 37090th iteration, cost function is 10.4128149473\n",
      "After 37100th iteration, cost function is 9.64578398225\n",
      "After 37110th iteration, cost function is 10.6042276908\n",
      "After 37120th iteration, cost function is 9.72856666213\n",
      "After 37130th iteration, cost function is 8.03586193524\n",
      "After 37140th iteration, cost function is 9.92453403137\n",
      "After 37150th iteration, cost function is 9.59689707684\n",
      "After 37160th iteration, cost function is 10.7099136559\n",
      "After 37170th iteration, cost function is 9.26274009404\n",
      "After 37180th iteration, cost function is 9.23758098213\n",
      "After 37190th iteration, cost function is 8.6254423905\n",
      "After 37200th iteration, cost function is 10.4474103182\n",
      "After 37210th iteration, cost function is 10.3479242511\n",
      "After 37220th iteration, cost function is 8.97561542166\n",
      "After 37230th iteration, cost function is 11.9073296736\n",
      "After 37240th iteration, cost function is 7.77605516147\n",
      "After 37250th iteration, cost function is 8.85271700881\n",
      "After 37260th iteration, cost function is 10.1242524154\n",
      "After 37270th iteration, cost function is 10.4495222475\n",
      "After 37280th iteration, cost function is 9.97090432705\n",
      "After 37290th iteration, cost function is 8.8735202639\n",
      "After 37300th iteration, cost function is 9.9081585812\n",
      "After 37310th iteration, cost function is 9.04000269328\n",
      "After 37320th iteration, cost function is 9.50482957797\n",
      "After 37330th iteration, cost function is 10.4401032654\n",
      "After 37340th iteration, cost function is 7.68791461613\n",
      "After 37350th iteration, cost function is 10.0354490711\n",
      "After 37360th iteration, cost function is 11.3200368241\n",
      "After 37370th iteration, cost function is 8.51820180175\n",
      "After 37380th iteration, cost function is 10.3565619069\n",
      "After 37390th iteration, cost function is 10.4645594701\n",
      "After 37400th iteration, cost function is 9.03037377593\n",
      "After 37410th iteration, cost function is 10.1275369601\n",
      "After 37420th iteration, cost function is 10.1873848091\n",
      "After 37430th iteration, cost function is 8.77473305406\n",
      "After 37440th iteration, cost function is 9.91568961573\n",
      "After 37450th iteration, cost function is 8.59314455702\n",
      "After 37460th iteration, cost function is 9.92453382785\n",
      "After 37470th iteration, cost function is 10.3072322504\n",
      "After 37480th iteration, cost function is 10.1045388493\n",
      "After 37490th iteration, cost function is 11.4560580725\n",
      "After 37500th iteration, cost function is 10.1158169578\n",
      "After 37510th iteration, cost function is 10.4660039613\n",
      "After 37520th iteration, cost function is 8.32409383109\n",
      "After 37530th iteration, cost function is 7.4357793877\n",
      "After 37540th iteration, cost function is 11.1765082185\n",
      "After 37550th iteration, cost function is 9.56792353568\n",
      "After 37560th iteration, cost function is 11.0403382382\n",
      "After 37570th iteration, cost function is 8.51648734547\n",
      "After 37580th iteration, cost function is 8.85513624506\n",
      "After 37590th iteration, cost function is 10.2715112013\n",
      "After 37600th iteration, cost function is 8.64423158009\n",
      "After 37610th iteration, cost function is 10.3523088457\n",
      "After 37620th iteration, cost function is 8.65843802646\n",
      "After 37630th iteration, cost function is 9.97993100233\n",
      "After 37640th iteration, cost function is 9.56611427363\n",
      "After 37650th iteration, cost function is 9.97608814034\n",
      "After 37660th iteration, cost function is 9.2477565993\n",
      "After 37670th iteration, cost function is 8.64173793306\n",
      "After 37680th iteration, cost function is 9.41146109657\n",
      "After 37690th iteration, cost function is 9.90473596468\n",
      "After 37700th iteration, cost function is 9.22383997837\n",
      "After 37710th iteration, cost function is 9.46438368439\n",
      "After 37720th iteration, cost function is 10.6019086845\n",
      "After 37730th iteration, cost function is 8.87071848746\n",
      "After 37740th iteration, cost function is 9.06915491078\n",
      "After 37750th iteration, cost function is 10.1619314141\n",
      "After 37760th iteration, cost function is 9.80790017951\n",
      "After 37770th iteration, cost function is 11.062406921\n",
      "After 37780th iteration, cost function is 10.0390066396\n",
      "After 37790th iteration, cost function is 9.32494136172\n",
      "After 37800th iteration, cost function is 8.71335503984\n",
      "After 37810th iteration, cost function is 8.74271292541\n",
      "After 37820th iteration, cost function is 10.0650333935\n",
      "After 37830th iteration, cost function is 9.50222821019\n",
      "After 37840th iteration, cost function is 8.38770496472\n",
      "After 37850th iteration, cost function is 8.59228375778\n",
      "After 37860th iteration, cost function is 10.766066119\n",
      "After 37870th iteration, cost function is 9.17248061932\n",
      "After 37880th iteration, cost function is 8.7595247388\n",
      "After 37890th iteration, cost function is 10.2655618631\n",
      "After 37900th iteration, cost function is 10.7174656248\n",
      "After 37910th iteration, cost function is 8.35837794293\n",
      "After 37920th iteration, cost function is 10.6957025688\n",
      "After 37930th iteration, cost function is 8.62098700462\n",
      "After 37940th iteration, cost function is 8.68709206141\n",
      "After 37950th iteration, cost function is 8.60470296562\n",
      "After 37960th iteration, cost function is 10.4054353376\n",
      "After 37970th iteration, cost function is 9.19293720507\n",
      "After 37980th iteration, cost function is 9.60768658791\n",
      "After 37990th iteration, cost function is 9.85174565763\n",
      "After 38000th iteration, cost function is 10.1504511249\n",
      "After 38010th iteration, cost function is 10.4482723376\n",
      "After 38020th iteration, cost function is 8.81943666174\n",
      "After 38030th iteration, cost function is 11.2493357122\n",
      "After 38040th iteration, cost function is 10.4243408858\n",
      "After 38050th iteration, cost function is 9.26333714715\n",
      "After 38060th iteration, cost function is 9.48955801101\n",
      "After 38070th iteration, cost function is 9.99009615778\n",
      "After 38080th iteration, cost function is 9.05994165961\n",
      "After 38090th iteration, cost function is 11.3191054394\n",
      "After 38100th iteration, cost function is 10.9612073408\n",
      "After 38110th iteration, cost function is 10.482990482\n",
      "After 38120th iteration, cost function is 9.95357833659\n",
      "After 38130th iteration, cost function is 9.23471310126\n",
      "After 38140th iteration, cost function is 11.0285161692\n",
      "After 38150th iteration, cost function is 10.030881342\n",
      "After 38160th iteration, cost function is 9.51171851925\n",
      "After 38170th iteration, cost function is 10.6854485929\n",
      "After 38180th iteration, cost function is 9.22381297595\n",
      "After 38190th iteration, cost function is 9.2291349183\n",
      "After 38200th iteration, cost function is 9.85355196837\n",
      "After 38210th iteration, cost function is 10.0026084055\n",
      "After 38220th iteration, cost function is 9.98031269753\n",
      "After 38230th iteration, cost function is 9.00009754746\n",
      "After 38240th iteration, cost function is 10.9308371536\n",
      "After 38250th iteration, cost function is 8.87289267648\n",
      "After 38260th iteration, cost function is 9.0777256338\n",
      "After 38270th iteration, cost function is 10.8720255465\n",
      "After 38280th iteration, cost function is 8.64140288723\n",
      "After 38290th iteration, cost function is 10.2570638311\n",
      "After 38300th iteration, cost function is 10.1727308991\n",
      "After 38310th iteration, cost function is 10.8490796934\n",
      "After 38320th iteration, cost function is 9.39985810128\n",
      "After 38330th iteration, cost function is 10.0144403546\n",
      "After 38340th iteration, cost function is 9.55311791794\n",
      "After 38350th iteration, cost function is 9.07256096464\n",
      "After 38360th iteration, cost function is 9.03164469956\n",
      "After 38370th iteration, cost function is 9.32818370541\n",
      "After 38380th iteration, cost function is 11.4468465256\n",
      "After 38390th iteration, cost function is 9.52048689178\n",
      "After 38400th iteration, cost function is 9.62129126967\n",
      "After 38410th iteration, cost function is 9.62551587009\n",
      "After 38420th iteration, cost function is 9.82452334457\n",
      "After 38430th iteration, cost function is 8.92767834512\n",
      "After 38440th iteration, cost function is 8.67226696112\n",
      "After 38450th iteration, cost function is 9.03997251482\n",
      "After 38460th iteration, cost function is 8.31737892122\n",
      "After 38470th iteration, cost function is 10.0130338135\n",
      "After 38480th iteration, cost function is 10.0428888015\n",
      "After 38490th iteration, cost function is 9.34344388052\n",
      "After 38500th iteration, cost function is 11.1359609544\n",
      "After 38510th iteration, cost function is 9.24664042577\n",
      "After 38520th iteration, cost function is 9.47000520397\n",
      "After 38530th iteration, cost function is 10.4654606494\n",
      "After 38540th iteration, cost function is 11.1402507673\n",
      "After 38550th iteration, cost function is 11.1831647901\n",
      "After 38560th iteration, cost function is 9.36474334634\n",
      "After 38570th iteration, cost function is 9.11642022843\n",
      "After 38580th iteration, cost function is 10.4488582381\n",
      "After 38590th iteration, cost function is 7.74791995975\n",
      "After 38600th iteration, cost function is 9.50872544526\n",
      "After 38610th iteration, cost function is 8.93174000685\n",
      "After 38620th iteration, cost function is 10.9076503832\n",
      "After 38630th iteration, cost function is 9.50495477412\n",
      "After 38640th iteration, cost function is 9.66422959269\n",
      "After 38650th iteration, cost function is 8.92070809239\n",
      "After 38660th iteration, cost function is 9.29218887059\n",
      "After 38670th iteration, cost function is 9.19594341337\n",
      "After 38680th iteration, cost function is 10.3980896031\n",
      "After 38690th iteration, cost function is 10.0497529948\n",
      "After 38700th iteration, cost function is 7.74326920141\n",
      "After 38710th iteration, cost function is 9.20488228359\n",
      "After 38720th iteration, cost function is 9.23531226127\n",
      "After 38730th iteration, cost function is 10.2931731831\n",
      "After 38740th iteration, cost function is 8.72673411621\n",
      "After 38750th iteration, cost function is 9.80480996988\n",
      "After 38760th iteration, cost function is 8.97719479273\n",
      "After 38770th iteration, cost function is 10.7095488606\n",
      "After 38780th iteration, cost function is 11.546510539\n",
      "After 38790th iteration, cost function is 9.6353584539\n",
      "After 38800th iteration, cost function is 9.93514673026\n",
      "After 38810th iteration, cost function is 8.86933981122\n",
      "After 38820th iteration, cost function is 9.38956692124\n",
      "After 38830th iteration, cost function is 9.34083406363\n",
      "After 38840th iteration, cost function is 7.94250800331\n",
      "After 38850th iteration, cost function is 10.8629915316\n",
      "After 38860th iteration, cost function is 9.02571027662\n",
      "After 38870th iteration, cost function is 8.63529984306\n",
      "After 38880th iteration, cost function is 8.98240310635\n",
      "After 38890th iteration, cost function is 10.0335237486\n",
      "After 38900th iteration, cost function is 9.24520794719\n",
      "After 38910th iteration, cost function is 8.38956636665\n",
      "After 38920th iteration, cost function is 9.28823878175\n",
      "After 38930th iteration, cost function is 10.8047529901\n",
      "After 38940th iteration, cost function is 9.53932932434\n",
      "After 38950th iteration, cost function is 8.53025759789\n",
      "After 38960th iteration, cost function is 10.2874159134\n",
      "After 38970th iteration, cost function is 11.3902070317\n",
      "After 38980th iteration, cost function is 8.7362047649\n",
      "After 38990th iteration, cost function is 10.5650030097\n",
      "After 39000th iteration, cost function is 9.29426840841\n",
      "After 39010th iteration, cost function is 9.13804742948\n",
      "After 39020th iteration, cost function is 8.17588556067\n",
      "After 39030th iteration, cost function is 9.13176322145\n",
      "After 39040th iteration, cost function is 9.52639059977\n",
      "After 39050th iteration, cost function is 10.6879887478\n",
      "After 39060th iteration, cost function is 9.64419460372\n",
      "After 39070th iteration, cost function is 8.96238796593\n",
      "After 39080th iteration, cost function is 9.48458879141\n",
      "After 39090th iteration, cost function is 8.10785345286\n",
      "After 39100th iteration, cost function is 8.83225129533\n",
      "After 39110th iteration, cost function is 9.40594264974\n",
      "After 39120th iteration, cost function is 11.4073981838\n",
      "After 39130th iteration, cost function is 9.58976256729\n",
      "After 39140th iteration, cost function is 9.83478022084\n",
      "After 39150th iteration, cost function is 10.0341183471\n",
      "After 39160th iteration, cost function is 10.1550855932\n",
      "After 39170th iteration, cost function is 10.3211110678\n",
      "After 39180th iteration, cost function is 8.53645645261\n",
      "After 39190th iteration, cost function is 10.3145846017\n",
      "After 39200th iteration, cost function is 8.77621718737\n",
      "After 39210th iteration, cost function is 10.4342121545\n",
      "After 39220th iteration, cost function is 9.05881251441\n",
      "After 39230th iteration, cost function is 10.5466683578\n",
      "After 39240th iteration, cost function is 10.9920672959\n",
      "After 39250th iteration, cost function is 9.65411738115\n",
      "After 39260th iteration, cost function is 9.34729944637\n",
      "After 39270th iteration, cost function is 9.61020444104\n",
      "After 39280th iteration, cost function is 10.7404331002\n",
      "After 39290th iteration, cost function is 8.58188337429\n",
      "After 39300th iteration, cost function is 8.44843547364\n",
      "After 39310th iteration, cost function is 8.47344561691\n",
      "After 39320th iteration, cost function is 9.97148893267\n",
      "After 39330th iteration, cost function is 9.13513211117\n",
      "After 39340th iteration, cost function is 9.52037891535\n",
      "After 39350th iteration, cost function is 8.92471122317\n",
      "After 39360th iteration, cost function is 8.10055421742\n",
      "After 39370th iteration, cost function is 11.4275333294\n",
      "After 39380th iteration, cost function is 8.94534761024\n",
      "After 39390th iteration, cost function is 10.022445067\n",
      "After 39400th iteration, cost function is 9.84036124314\n",
      "After 39410th iteration, cost function is 9.16840297188\n",
      "After 39420th iteration, cost function is 9.02465052453\n",
      "After 39430th iteration, cost function is 9.86049776801\n",
      "After 39440th iteration, cost function is 8.9419806586\n",
      "After 39450th iteration, cost function is 8.23506615545\n",
      "After 39460th iteration, cost function is 10.7695608803\n",
      "After 39470th iteration, cost function is 8.87053311114\n",
      "After 39480th iteration, cost function is 9.92442200974\n",
      "After 39490th iteration, cost function is 7.84337244203\n",
      "After 39500th iteration, cost function is 9.23536054312\n",
      "After 39510th iteration, cost function is 9.07153007668\n",
      "After 39520th iteration, cost function is 9.95374462341\n",
      "After 39530th iteration, cost function is 10.0848356931\n",
      "After 39540th iteration, cost function is 9.46635092679\n",
      "After 39550th iteration, cost function is 9.72043048123\n",
      "After 39560th iteration, cost function is 10.1615829097\n",
      "After 39570th iteration, cost function is 8.92736519026\n",
      "After 39580th iteration, cost function is 8.78655201872\n",
      "After 39590th iteration, cost function is 9.51848557025\n",
      "After 39600th iteration, cost function is 9.94991310797\n",
      "After 39610th iteration, cost function is 10.0749363341\n",
      "After 39620th iteration, cost function is 10.3699652252\n",
      "After 39630th iteration, cost function is 9.95278167628\n",
      "After 39640th iteration, cost function is 10.0702910523\n",
      "After 39650th iteration, cost function is 8.81031975685\n",
      "After 39660th iteration, cost function is 10.8822444654\n",
      "After 39670th iteration, cost function is 9.44206009058\n",
      "After 39680th iteration, cost function is 11.2758813972\n",
      "After 39690th iteration, cost function is 8.42420620713\n",
      "After 39700th iteration, cost function is 8.89579766036\n",
      "After 39710th iteration, cost function is 9.06560549548\n",
      "After 39720th iteration, cost function is 8.60528768481\n",
      "After 39730th iteration, cost function is 10.5418462889\n",
      "After 39740th iteration, cost function is 8.84042716803\n",
      "After 39750th iteration, cost function is 8.9372896603\n",
      "After 39760th iteration, cost function is 9.17855002469\n",
      "After 39770th iteration, cost function is 10.8831292794\n",
      "After 39780th iteration, cost function is 8.83213990796\n",
      "After 39790th iteration, cost function is 8.71205771301\n",
      "After 39800th iteration, cost function is 9.44321461126\n",
      "After 39810th iteration, cost function is 8.99654525526\n",
      "After 39820th iteration, cost function is 10.2370997363\n",
      "After 39830th iteration, cost function is 9.05190190554\n",
      "After 39840th iteration, cost function is 9.14739083678\n",
      "After 39850th iteration, cost function is 8.62026180871\n",
      "After 39860th iteration, cost function is 10.0858545978\n",
      "After 39870th iteration, cost function is 9.62916053847\n",
      "After 39880th iteration, cost function is 9.22147581034\n",
      "After 39890th iteration, cost function is 8.42125455833\n",
      "After 39900th iteration, cost function is 8.26694008687\n",
      "After 39910th iteration, cost function is 9.23972736309\n",
      "After 39920th iteration, cost function is 9.62349563669\n",
      "After 39930th iteration, cost function is 10.7917611373\n",
      "After 39940th iteration, cost function is 9.14241079486\n",
      "After 39950th iteration, cost function is 9.12899573056\n",
      "After 39960th iteration, cost function is 11.3901076087\n",
      "After 39970th iteration, cost function is 9.3578115714\n",
      "After 39980th iteration, cost function is 8.57226857706\n",
      "After 39990th iteration, cost function is 9.34152328377\n",
      "After 40000th iteration, cost function is 8.55938095605\n",
      "\n",
      "=== For autograder ===\n",
      "[[-0.67131358 -0.25156749 -0.5112404   0.46609369  0.81964006 -0.17678717\n",
      "   0.04727608  0.91698403 -0.57413986 -0.02978244]\n",
      " [-0.68194618 -0.15229774 -0.51321841  0.39254603  0.79362069 -0.21699707\n",
      "  -0.01172248  0.80166188 -0.54150303 -0.22063975]\n",
      " [-0.50124453  0.01231413 -0.42058395  0.37085274  0.6478261  -0.04703697\n",
      "   0.04613347  0.61446384 -0.25082859 -0.0563656 ]\n",
      " [-0.5691748  -0.17675577 -0.41760259  0.3573051   0.61275163 -0.06743699\n",
      "   0.01619132  0.71738941 -0.31445712 -0.04710073]\n",
      " [-0.21333579 -0.00206362 -0.17378362  0.13142703  0.17503769  0.0060375\n",
      "  -0.02556432  0.15208457 -0.01253734 -0.0388439 ]\n",
      " [-0.58614977 -0.15229928 -0.40548632  0.43981577  0.63795691 -0.13161872\n",
      "  -0.03071489  0.64779522 -0.29058703 -0.07918343]\n",
      " [-0.65398113 -0.10053422 -0.53109336  0.42034709  0.7793295  -0.1049117\n",
      "  -0.03424799  0.84674949 -0.49451618 -0.15451428]]\n"
     ]
    }
   ],
   "source": [
    "# Train word vectors (this could take a while!)\n",
    "\n",
    "# Reset the random seed to make sure that everyone gets the same results\n",
    "random.seed(31415)\n",
    "np.random.seed(9265)\n",
    "wordVectors = np.concatenate(((np.random.rand(nWords, dimVectors) - .5) / dimVectors, \n",
    "                              np.zeros((nWords, dimVectors))), axis=0)\n",
    "wordVectors0 = sgd(lambda vec: word2vec_sgd_wrapper(skipgram, tokens, vec, dataset, C, negSamplingCostAndGradient), \n",
    "                   wordVectors, 0.3, 40000, None, True, PRINT_EVERY=10)\n",
    "# sanity check: cost at convergence should be around or below 10\n",
    "\n",
    "# sum the input and output word vectors\n",
    "wordVectors = (wordVectors0[:nWords,:] + wordVectors0[nWords:,:])\n",
    "\n",
    "print \"\\n=== For autograder ===\"\n",
    "checkWords = [\"the\", \"a\", \"an\", \"movie\", \"ordinary\", \"but\", \"and\"]\n",
    "checkIdx = [tokens[word] for word in checkWords]\n",
    "checkVecs = wordVectors[checkIdx, :]\n",
    "print checkVecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.11444211912786527, 0.1600046435734222)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": [
       "iVBORw0KGgoAAAANSUhEUgAAAl4AAAHiCAYAAAA5wcIVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\n",
       "AAALEgAACxIB0t1+/AAAIABJREFUeJzs3XecFdX9//HX2QbsKsIaUESCqBjUKJZYiImCIqLGEjtf\n",
       "E8WvGstPY4uxBUSwo8ZUNXYTxV5IbIBxbV8FRARUIEgEFSMgi9LZdn5/cN3swsIue3fnbnk9Hw/N\n",
       "nZkzM5+5Gn17zrlnQowRSZIkNb6sTBcgSZLUWhi8JEmSEmLwkiRJSkhOpguQJEmtR+gculNIXrWd\n",
       "xZTEBXFuhkpKlMFLkiQlp5A8BrG82r5RFGSomsQ51ChJkpQQg5ckSVJCDF6SJEkJMXhJkiQlxOAl\n",
       "SZKUEIOXJElSQgxekiRJCTF4SZKkzLiWx3iFzpkuI0khxpjpGjYohNC0C5QkSXWXC7QFIrAcKABW\n",
       "A6WZLKphxRjD+o41i5XrN/QAmRJCGBZjHJbpOpozv8P0+P2lz+8wPX5/6WuN32HoFXoyiOU8zg58\n",
       "won8ihGMoiDOiLM2+lpN8PurrcOoWQQvSZLUwpzAv4ARmS4jac7xkiRJSog9XvVXlOkCWoCiTBfQ\n",
       "zBVluoAWoCjTBTRzRZkuoAUoynQBiSumZJ2XYhdTUs+rFaVdT8KaxeT6pjjHS5IkaW215RaHGiVJ\n",
       "khJi8JIkSUqIwUuSJCkhBi9JkqSEGLwkSZISYvCSJElKSNrBK4QwMIQwI4QwK4RwWQ3He4UQ3g4h\n",
       "rAohXLLWsTkhhKkhhMkhhAnp1iJJktSUpbWAagghG/gj0B+YB0wMIYyOMU6v0mwRcD5wdA2XiEDf\n",
       "GGNxOnVIkiQ1B+n2eO0NfBxjnBNjLAUeBY6q2iDGuDDG+C7rf++4i6NKkqRWId3g1RX4rMr256l9\n",
       "dRWBcSGEd0MIZ6ZZiyRJUpOW7rsa033f0H4xxv+EEDoBY0MIM2KMb6R5TUmSpCYp3eA1D+hWZbsb\n",
       "a3q96iTG+J/U/y4MITzDmqHLdYJXCGFYlc2iGGNRfYqVJElqSCGEvkDfOrdP5yXZIYQcYCZwEPAF\n",
       "MAEYtNbk+m/bDgOWxhhvTW3nA9kxxqUhhAJgDHBNjHHMWuf5kmxJktQs1JZb0urxijGWhRDOA14G\n",
       "soF7Y4zTQwhnpY7fFULYEpgItAcqQggXADsBnYGnQwjf1vHw2qFLkiSpJUmrxysJ9nhJkqTmorbc\n",
       "4sr1kiRJCTF4SZIkJcTgJUmSlBCDlyRJUkIMXpIkSQkxeEmSJCXE4CVJkpQQg5ckSVJCDF6SJEkJ\n",
       "MXhJkiQlxOAlSZKUEIOXJElSQgxekiRJCTF4SZIkJcTgJUmSlBCDlyRJUkIMXpIkSQkxeEmSJCXE\n",
       "4CVJkpQQg5ckSVJCDF6SJEkJMXhJkiQlxOAlSZKUEIOXJElSQgxekiRJCTF4SZIkJcTgJUmSlBCD\n",
       "lyRJUkIMXpIkSQkxeEmSJCUkJ9MFrE/oHLpTSB65EHqFnpmup06KKYkL4txMlyFJkpqmJhu8KCSP\n",
       "QSznVmAQyzNdTp2MoiDTJUiSpKbLoUZJkqSEGLyqGsGzmS5BkiS1XAavqoZwdKZLkCRJLVfTneNV\n",
       "1XXcSwVbEWnDZtzDBTzCMGaRzwOs4iCyWMB3uZlPuYoKutCZqzmbsTzP1kzm90TyAfguV3EqkxjJ\n",
       "r1jFwQBU8B3yKOIKLmEYsxhGT+6lD//hErJYRBm9yGEqV3I+AHdxIPO5msAK8niXMrpxFYMz9dVI\n",
       "kqTmo3n0eA3gYoZwKD/jML7hdMbTAWhHB95kKAcSWManXMovOZ4dOJ2F/AqAHfmKwZzEEAayC+fw\n",
       "KSMAuJRbGMIh/ITjCCymO/en7hQr71nGzuzNUK7gAMr5Lg/wA+bShi+5iR/wPwzhUMoprHaOJEnS\n",
       "BjSPHq8izuBFDgGggi7MpAdQwi94DYA8ppPFatpTwZHM4Ga6AfANubzEdZSyE4Fyytmu8pqlwAv8\n",
       "kQ7cxf/wwTr3zOF9+jMfgFw+ZCnd+D9Wks1cDmMeAIU8yyJObsQnlyRJLUjT7/EqA1bxI07lCIYy\n",
       "gBw+pIw2qSPfigRKAcgn8m2gHMcvyGY+Q+nPBRwK5FaecTuXkM08fskTNd43sLrKVgWRHNbt3Qrp\n",
       "PZwkSWpNmn7wAsjia7qzmifZnjL2qPN5FWxCDgsBeIDjgWwA7uRgVvFjTmdona8ViPyQ2ZTTnRfo\n",
       "CkAxR+JQoyRJqqOmP9SYDZSRw3CKyGY2OUxKHVk78MR1PvfiQaZwN8M5jrYUQWoh1q84kwq24E6e\n",
       "B6AtY7iUW2u8RlXdWc0WXMG7PMIkVpDL+1QYvCRJUt2EGJtmbgi9Qs/UyvXzuCTVw9QUzKAdvVgJ\n",
       "wI1cRx7/5mLuBWAUBXFGnJXJ8iRJUuaEEGKMcb1TkZp+j1dT8wIn8wTHE8kjl2kcy98yXZIkSWoe\n",
       "DF4b62LuAe7JdBmSJKn5abrBq5gSRlHAKprPy6eLKcl0CZIkqelqsnO8vlXbWKkkSVJTUVtuaR7L\n",
       "SUiSJLUABi9JkqSEGLwkSZISYvCSJElKiMFLkiQpIQYvSZKkhBi8JEmSEmLwkiRJSojBS5IkKSEG\n",
       "L0mSpIQYvCRJkhJi8JIkSUqIwUuSJCkhBi9JkqSEGLwkSZISYvCSJElKiMFLkiQpIQYvSZKkhBi8\n",
       "JEmSEmLwkiRJSojBS5IkKSE5mS5AkiQ1f6Fz6E4heQ1ysWJK4oI4t0Gu1cQYvCRJUvoKyWMQyxvk\n",
       "WqMoaJDrNEEONUqSJCXE4CVJkhrOZDbldk4B4F76cB0PZLagpsXgJUmSGs4XbMYSTs10GU2Vc7wk\n",
       "SVLDmcKVVLANI3gZKCOwguu5izJ6kcNUruR8AB5mFz7haiIFBIrZjwvpx8LMFt/40u7xCiEMDCHM\n",
       "CCHMCiFcVsPxXiGEt0MIq0IIl2zMuZIkqZnZjevIYg5DOISujKCM77M3Q7mCAyjnuzzAXiwkh39z\n",
       "LQdxJkM4lI48xjtcnunSk5BWj1cIIRv4I9AfmAdMDCGMjjFOr9JsEXA+cHQ9zpUkSc1JJFT7nMP7\n",
       "9Gc+ALl8yFK25lWWUM73GMejjAMi2WSl2rRw6Q417g18HGOcAxBCeBQ4CqgMTzHGhcDCEMLhG3uu\n",
       "JElq5gKrq2xVEFPZI5uZDOGozBSVOekONXYFPquy/XlqX2OfK0mSmqJClhPZZL3HA5F+zCayOQ+x\n",
       "BwALyeEJeiZVYial2+MVkzg3hDCsymZRjLEojftKkqTG0ofFvMpEhvMKgVVksWCdNp0ooye/YDYj\n",
       "GM6mQA6b8RdgVuL1pimE0BfoW9f26QaveUC3KtvdWNNz1aDnxhiH1ac4SZKUAVdyXo37L+c3lZ8H\n",
       "8RFwbEIVNZpUZ1DRt9shhKs31D7d4PUu0DOEsA3wBXAiMGg9bcNa2xtz7gY16PuhMqUFv5dKkiSt\n",
       "kVbwijGWhRDOA14GsoF7Y4zTQwhnpY7fFULYEpgItAcqQggXADvFGJfVdG69CmnI90NlSgt+L5Uk\n",
       "SVojxJjONK3GF0KIMca1e8uqt+kVemY0eD3MLnzO8VzG0HpfYxQFcUZsdmPbkiRBA48+NeNRoNpy\n",
       "iyvXN4STmQZMy3QZkiRlSnMNSklrecHrOu6lgq2ItGEz7uECHmEYsyjgblbSn8AqDuA09mcRN/Bb\n",
       "slhKCbsS6cx3uJZzeYFS4Lf8hlX0AyKb8zv+H3/nBm6nAy9wDmMAuJ4/UshoclnKl5zFVQxmJJdQ\n",
       "xlaU810q6Mqm3M1F3A/ALVzICo4hsIhsvqAtU7mYuzL3ZUmSpCS1vJdkD+BihnAoP+MwvuF0xtMB\n",
       "aEd7JjGUAbRhPBM4ubJ9OZ0YwtHsxCl8xZUA3M1hlLAzV3AQfTmRrxjCq3RiC0ZRzInAmrevl7In\n",
       "pzB2nRrK2I6zGMTBHM4SLmEJWfyV3qzkUM7kII7lZMrYlfSW45AkSc1MywteRZzBcMbwN0ZTQRdm\n",
       "0gMo4SxeAaCAqZRWLmMRac9LABzHx1TQCYCl7E17niEX2J9F5PE2M9mN/2U85fTgLTryGkfTjn+Q\n",
       "v054iuQzjk6U0YfFBL5iPJ1ZyF605WW6UMpOrKANY1n3l56SJKkFa1nB6176sIofcSpHMJQB5PAh\n",
       "ZbQByirbBCpY8yvKNbIorXKFb4NQpHooCnzbO1XAk4znOJZyAtvxaI11hGrXLKeU7PVcU5IktSIt\n",
       "K3iVsilZfE13VvMk21OWehXBxmrPeJZwJCsIvEkhJezDTkwGYC8eYylnApFjmV3D2esGqkCkMxNZ\n",
       "xcF8Th4fkc9qDsKhRkmSWpWWFbyO4lUgh+EUMZMryGFS6kjVgBNr2K7++RxeIo+PuIVx/JPH+Q4j\n",
       "2J9FwJqhx2z+RXseqzwrVLvm2tdf42dMpS1juI9xPM3fyGEG2SxJ63klSVKz4jpeG2sWbRnFK/yU\n",
       "AeyykfecQTt6sZJZtOVRnmZ7LmUQHwKu4yVJUgvgOl4N6R5+zDxuoT13bXToAniakZTTk0hbCnis\n",
       "MnRJkqRWwR6vpsIeL0mSmr3ackvLmuMlSZLUhLWMocZiSpr9S6aLKcl0CZIkqXG1iKFGSZKkpsCh\n",
       "RkmSpCbC4CVJkpQQg5ckSVJCDF6SJEkJMXhJkiQlxOAlSZKUEIOXJElSQgxekiRJCTF4SZIkJcTg\n",
       "JUmSlBCDlyRJUkIMXpIkSQkxeEmSJCXE4CVJkpQQg5ckSVJCDF6SJEkJMXhJkiQlxOAlSZKUEIOX\n",
       "JElSQgxekiRJCTF4SZIkJcTgJUmSlBCDlyRJUkIMXpIkSQkxeEmSJCXE4CVJkpQQg5ckSVJCDF6S\n",
       "JEkJMXhJkiQlxOAlSZKUEIOXJElSQgxekiRJCTF4SZIkJcTgJUmSlBCDlyRJUkIMXpIkSQkxeEmS\n",
       "JCXE4CVJkpQQg5ckSVJCDF6SJEkJMXhJkiQlxOAlSZKUEIOXJElSQgxekiRJCTF4SZIkJSQn0wW0\n",
       "NqFz6E4heZmug2JK4oI4N9NlSJLUmhi8klZIHoNYnukyGEVBpkuQJKm1MXhlyvNszSQeZCgH1ev8\n",
       "kVxCR8ZzBm82cGWSpCao1hETRzKaBYNXc7SCwKXcmukyJEkJqm3ExJGMZsHglVk5XM8fKGMXcpjJ\n",
       "SVzAP/kB/2EIkWxymcJgLqcLpVzDeNrxHKvZn0L+zBL6sRljOZcXuIbx5PM4qziYSA7f5yyOYTZv\n",
       "UkgRf6aCzuQyiRL2ZyCHsA9fZ/rBJUlqjfxVYyZVsB1deYCh9CWwjKc5i3n8ll05i6H0B7IZxSmp\n",
       "1pFsihnCQP4fo4GY+mPNsRwWMYSBtOchZnI2AG9yMe14naEcyOb8g0jX5B9SkiR9y+CVSYEvOJVJ\n",
       "AHTmKVaxH9nM5SjmANCJJ1jJvpXtd2b0eq+1Ky8AUMg0yukGQCl7sSPPAfALXiPY0yVJUiY51JhZ\n",
       "scqnQGAJkY5VjgdClTYdWbHeK21CCQBZlAPZ1a4rSWpZruNeKtiKSBs24x4u4JFMl6S6sccrkyJd\n",
       "eYg9AFjIT2nDFMrpxmi6p/YdSzvervf1c5nIDI4E4G72J9Ih/aIlSRk3gIsZwqH8jMP4htMZ7z/f\n",
       "mwt7vDIlEMliNvMYzHBuI4eZHM9fGMt7TOEvvE82ubzPz/hr6oy4wetVve63bX/EbRTxZ4ZzLHlM\n",
       "IrCAbVnWOA8kSUpMEWfwIocAUEEXZtKDXP6V4apUByHGuv37PFNCCDHG2GKGy0Kv0DOxBVT/Qy4F\n",
       "lNOeCh5kTz7leoak/o86ioI4I85KpA5JUtoq//1xL334gl9zCifRndVcyxNsxS204wP/uZ55teUW\n",
       "e7xasgl0ZSp3peaPlbItv8p0SZKkNJWyKVl8TXdW8xTbUZaasqJmweDVkh3FHI5K9XBJklqGo3iV\n",
       "+/g5wykim9nkpH4dr2bB4CVJUnPShVKu4ufr7Hfl+mYh7eAVQhgI3M6aJQzuiTHeVEOb3wOHAiuA\n",
       "wTHGyan9c4AlQDlQGmPcO916mrxiSprE/zmKU8tPSJKkxKQVvEII2cAfgf7APGBiCGF0jHF6lTaH\n",
       "AdvHGHuGEPYB7oDKRUEj0DfGWJxOHc2JLzCVJKn1SrfHa2/g4xjjHIAQwqPAUcD0Km2OBB4EiDGO\n",
       "DyF0CCFsEWOcnzreYn6xKElSo6ltxMSRjGYh3eDVFfisyvbnwD51aNMVmM+aHq9xIYRy4K4Y491p\n",
       "1iNJUovkiEnLkG7wqusiYOvr1fpRjPGLEEInYGwIYUaM8Y11Tg5hWJXNohhj0caVKUmS1PBCCH2B\n",
       "vnVtn27wmgepFzKv0Y01PVobarN1ah8xxi9S/7swhPAMa4Yu1wleMcZhadYpSZLU4FKdQUXfbocQ\n",
       "rt5Q+3Tf1fgu0DOEsE0IIQ84ERi9VpvRwCmpYvYFvo4xzg8h5IcQNk3tLwAGANPSrEeSJKnJSqvH\n",
       "K8ZYFkI4D3iZNctJ3BtjnB5COCt1/K4Y4wshhMNCCB8Dy4HTUqdvCTwdQvi2jodjjGPSqUeSJKkp\n",
       "812NkiRJDaS23JLuUKMkSZLqyOAlSZKUEIOXJElSQgxekiRJCTF4SZIkJcTgJUmSlBCDlyRJUkIM\n",
       "XpIkSQkxeEmSJCUk3Zdkt3qhc+hOIXmNcvFiSuKCOLdRri1JkhJn8EpXIXkMYnmjXHsUBY1yXUmS\n",
       "lBEONUqSJCXE4NWUjOQSbuOsTJchSZIah8GraYmZLkCSJDUe53g1pD9wHIs5C4jk8hG9Gcl7/JYK\n",
       "OpLFIn7AxQzkC55nayZz2zr7JUlSi2aPV0N5nB1YzC85hOMZygD6czWTuY7NeIyhHEx7nmESIwB4\n",
       "n2tr3C9Jklo0g1dDmcd+tOPv7MPXAOzFN5SxJ6fyDACDeIoy9gZY735JktSiGbwaVlhnT1kN+za0\n",
       "X5IktVgGr4ayNW+ykp8wng4AjKcDObzLwxwFwCiOIYd3ANa7v6bgJkmSWowQY9P+IV0IIcYYm2wg\n",
       "Cb1Cz8oFVNdMrj8HKCeXaezGrUzmzwQ6ks1iduB6tmAhX9KZWVxJOR2q7Z/AaWSzgj15DIA55ANz\n",
       "MvZw6+OK+pIk1ai23GLwSlO14FWTt+lBH1bU6+Lvkc8efFLf2hrNKArijDgr02VIktTU1JZbHGqU\n",
       "JElKiMGrpRjGxvdA/YmfMJwirk0Nba7PNYyvnLsmSZLqzQVU01VMSS0vs86nTT2vXULJRrSu+5hx\n",
       "KVBKYDGD+C6/YjDvNti1JUnSehm80lTbJPPQK8AeLOdWziGLVVzE/dzEMErZkd9wIvewHws4ifaM\n",
       "o5jzgUBbXuHXXA+s6ckq4G5W0p/AKg7gNPZnEf+gG5P5E5F82jGm2k1v5RxW8BMiebTjJS7lVp5n\n",
       "aybxCLm8Rym7ks/fKWMvPuU2buZl2vIvVtCby/kNANfxIF34M//L+Mb55iRJan0cakxKJ95hJfsA\n",
       "UEJvIvkUk81i9iGPf7OIqziY47mQgymhN3cwIHVmO9oziaEMoA3jmcDJAExhOB14gKH0J5f5lfe5\n",
       "m/0pZRuGcDi/YgAl7ML9qQVaK+jB1jzAUA7kV/yWHKawHefya66roWJ7uSRJamAGr6QcyjTK2JVp\n",
       "FBBYTR6T+Ae9Wc3eZPMNebxFHxbTngra8wxL2Dd1Zgln8QoABUyllG4AlLEXp/IsAP14qvI+xRzA\n",
       "ag5gBC9zKy9RznYspQcAgc/5Oe8n99CSJKkqhxqT0okysviUcZxAGyZSwHQWsB/lbEM7PmcVu1a2\n",
       "jVX+DGWV+wMVQHat9+rAH7iAh6vte56tCRtY1iJQRtUFXCNta38oSZK0MezxSlIbJrCEc+jIO3yf\n",
       "8SznFHKYxveYTAl9eJuOLCGLpRzNZpWr2dcsh4k8mFr9/lWOqdxfSBFLOIkZtANgLFvyJoW11rYp\n",
       "n1PKzpQCL7EVZexW/weVJEk1MXglqSPjiXTiQCaxP4sIrKQd4+nHQjbnesbyBLczljymcDZjU2dV\n",
       "nWsVK7d3YwhfM5jhjKOULSr3n8kbbMIzPM7fGc443uFOvq781eX6520NZiLZfMYNvMYkhpPD1IZ+\n",
       "fEmSWjtXrm9kta5s3xy5cr0kSTVy5XpJkqQmwuAlSZKUEH/V2NhqX9m++SneqBX11USEzqE7heQ1\n",
       "6EWLKaltEWFJ0n8ZvBqZ/1JSk1FIXoPPN2xp/1EhSY3MoUZJkqSEGLyk1uZ5tmZ46m0ISZ4rSTJ4\n",
       "SZIkJcU5XlLrlMP1/IEydiGHmZzEBTzNOaykP5G25PEul3MZAA+zC7O5jTUvknots2VLUvNmj5fU\n",
       "GlWwHV15gKH0JbCMZzmVA7iPIRzOUA4i0pY76Q/AbH5LN65kKAMyXLUkNXv2eEmtUeALTmUSAJ15\n",
       "ii85nYl8xkucS6QtkQ4sZyaTmECkPacxEYDuPMVMDsxk6ZLUnNnjJbVOscqnAEQWcj37cgZD6U8+\n",
       "jxBpQ9Za7/dc01aSVE8GL6k1inTlIfYAYCE/pR0TANiBxXxEPiv5CQC7s5TANzzAXgB8yjGZKViS\n",
       "WgaHGqXWJhDJYjbzGMxwbiOHmRzNQzzFZjzIPwksJJfJle234yJmcxsjiLThdVirF0ySVGchxqb9\n",
       "z9Da3vItqW5Cr9CzMVaujzPirAa9piQ1Y7XlFocaJUmSEmLwkiRJSohzvKTWopiSBn+pdTElDXo9\n",
       "SWrhnOMlSZLUQJzjJUmS1EQYvCRJkhJi8JIkSUqIwUuSJCkhBi9JkqSEGLwkSZISYvCSJElKiMFL\n",
       "kiQpIQYvSZKkhBi8JEmSEuK7GpUxoXPoTiF5GSugmJK4IM7N2P0lSa2OwUuZU0geg1iesfs39Auj\n",
       "JUmqhUONkiRJCbHHS63DfexLNqV8jy/JqxzezA+91vsC+Y3n0KUkqRYGL7UOi9iPbJaRxxj2YAUA\n",
       "q4E+DTjU6dClJKkWBi9l3gza8RR3Uc6WQDYFPMUqducqzuQOBjCfO/glO7CUHB7kVYbyQ0bTnalc\n",
       "R2RzAivZiUs5htm8SSGvcyPldAWgG1fTmf+wgp8B5bzAID7jBo7i/Yw+sySpVTJ4KfP+ST+y+ZKr\n",
       "OAWAKWzCc/wMgCXsQzbTGc3uVJBDDu8BMJWb2YXLOIo5PMTufMT1HMOJvM4ItuJuBjORF9mKiTzC\n",
       "YPryIX8lm2X0ZWxlj1d9XMuT9GAYJ/MB1zCegRzCPnyd/pcgSWoNDF7KvK2YzkKGcjNX0omxnMZE\n",
       "/s5cnmI7StmNQv7CIvYhkk0+45lBO8r4AVO5i6mpa8TUvK1SfsxnbM+Iyv0FzKBdaqshJnTF9XyW\n",
       "JKlWBi9l3tF8QjcG8H8cxDwu4xbepC3vMJeDgFJ24w2K+B2RLHZgOKvJJvANQzikhqsFzuAndKG0\n",
       "2t6/r9XqQU5hGRX04VZuYhil7MhvOJF72I8FnEQnHudLfgW0IZs5HMNF9GJlI30DkqRWwuUklHmv\n",
       "0JnvsJrzeYbvcCer2YVCxrOUM2nDu+zHYiroSAXbcgL/ojfLyOJT/szhAJQCj7IjALm8xiOcXnnt\n",
       "UewMQDbLKGeTyv1deY+V9AaghN5E8ikmm8XsQxumM58LOYkTGcJA2jCVf3BWQt+GJKkFs8dLmfdv\n",
       "evEWQwhUAGVsy2X04WMeYnM6Mh6AXD6inE6V5+zBeUzmRoZzAZBLPs8C0+nHEF7lOoYzFsghj7eB\n",
       "K9mWsUzlL7zAEXzG9fTnAybSi2kUEFhNLlP4B71Zzd4U8DLl7MCjPAesGcbM5d2kvxZJUstj8FLm\n",
       "ncnrwMHr7B/GtpWfL+eyascO53MOT03Ar6oPi+nDuevsP5pPOJqDeY8elZPrs/mCcZxAGyZSwHQW\n",
       "sB/lbEM7PmMlr3Ml/y/NJ5MkqRqDlzZKA79fcRveS+MXhhtSQgn7Mm+Dbdowla85h65cxA7M4FWu\n",
       "IYf32YVJjON6RtOdI5nLDNoxgy05mk8apVZJUquRdvAKIQwEbgeygXtijDfV0Ob3wKHACmBwjHFy\n",
       "Xc9VE9OQ71d8mxVpLe2wIe+RX2ub9kxhMT/nQCaxLasoYiXtGM9+LGYGFzKFP/N+KmR25iYweEmS\n",
       "0hNirP8v4kMI2cBMoD8wD5gIDIoxTq/S5jDgvBjjYSGEfYDfxRj3rcu5qfNjjLEB3+uidIReoWeD\n",
       "Ba/X6Upug/WeVTeHfGBODUe2YZtU2CulhP1r6RXbGKMoiDPirAa7niSp2aktt6Tb47U38HGMcU7q\n",
       "Zo8CRwFVw9ORwIMAMcbxIYQOIYQtgR51OFdN1fNszSQeZCgHbbDdSC6hI+9wBm+tZ/HReYzgWYZw\n",
       "dL3q+D3HszOvcRALqu2fU3MICr1Cw74mSJKkjZBu8OoKfFZl+3Ngnzq06QpsVYdz1ZytIHApt1bZ\n",
       "U/Pio/UNXQBLOIEvmQFrBS9JkpqgdINXXccpHSpsmXK4nj9Qxi7kMJOTuIC/8hrteI7V7E8hf2YJ\n",
       "/diMsZzLC+u9yjBmMYyefEQ+T3MfkQ5EcujMzZzNmFTv2sPkMZ4SfkAWX/JzTuN5+lNGb2bzJ0aw\n",
       "klM4ku6s3mDFxZQ02susiylplOtKklqMdIPXPKBble1urOm52lCbrVNtcutwLgAhhGFVNotijEX1\n",
       "K1cNqoLt6MrFnMokbuBWnmEwEMmmmCEMBOAG+lJ7QF9zfGtWcRSnswvLeYuOvMLfgTGpe23DNpzN\n",
       "Sfya67mD0RzG+TzDtQymB9dwMh/UpeS4IM6t17NKklSDEEJfoG9d26cbvN4FeoYQtgG+AE4EBq3V\n",
       "ZjRwHvBoCGFf4OsY4/wQwqI6nAtAjHFYmnWqMQS+4FQmAdCZp/iSMwDYmdH1ut5qsnieK3iGfQhU\n",
       "UMGWvM7mAGTxKSel5v+1YRqrq4V2e1QlSRmR6gwq+nY7hHD1htqnFbxijGUhhPOAl1mzJMS9Mcbp\n",
       "IYSzUsfvijG+EEI4LITwMbAcOG1D56ZTjxIXq3wKQAUAHeu5RMQojqGCQi7kENpTwTW8w3LapI7+\n",
       "dxgvUE6s3F+9DkmSmrC01/GKMb4IvLjWvrvW2j6vrueqGYl05SH24BTeYyE/pR0TWMr36329cjYh\n",
       "m0W0p4J7+SGRrTdw7zW9XIFlrGLTet9TkqQE+ZJs1U8gksVs5jGY4RQR2ZSjeaieV1vTY7Uvz1DC\n",
       "rgxnHAuFIPgMAAAbJElEQVQ4lixmrdOm6v0BOvI487iJEbzM3Gq9YJIkNTlpLaCaBBdQbVoadAHV\n",
       "xuRippKkDKgtt9jjJUmSlBCDlyRJUkLSnlyvVqYxFyBtSC5mKklqgpzjJUmS1ECc4yVJktREONSo\n",
       "GoXOoTuF5GWsgGJKfL2PJKmlMXipZoXkZXTZiOYwj0ySpI1k8FKrkbFePHvvJEkpBi9tnJFcQjbL\n",
       "uJi7am+8AdfyJD24hpOZ1kCV1S5TvXj23kmSUpxcr43VUD+Dbdo/p5UkqRHY46Xa3cIvWcFxBBaR\n",
       "zRdkM5VreYIeDOdkpvEWHRnHi1zNvvyeE1jKQCLtKKcH7bmLCtqwgp8CqxnIz9mLbwD4nOMYwS1E\n",
       "cujBxfycKZl90DTdwQA68W+O4+NMlyJJapoMXqq01hyobXiPFUzne6zkOA7kTErJ4Q3uI5vPCbQF\n",
       "tuI9lrGMzQjk8B49yOY7lLMzBzCYVbThHR5nc/5EP87mn5zP25xFNk8QaEegE4dzNtPYlTn8kXc4\n",
       "iX2Zl8nvoNISsmhPxUad8zWHEhkLBi9JUs0MXvqvqnOg3mYFe7CCiexIR8bxI74GYCpFtKGEFVSw\n",
       "OavYgxXMII8JRPZgBe9TwiZM4ACKAZjAEn7MOHqzgveZzhJ6sgcreJlytucf7MEK9uAdRtCOFXSA\n",
       "hILXLVzICo6p7MVry1RW0J9cPqSEvSngGbbgHT7haiIFBIrZjwvpx0J+x/+whJOJ5JLDHE7il7zO\n",
       "9ynhYBayLyO4gN04kyP4NJFnkSQ1GwYv1SYC667AGyinIjVHcPlavxQM1V7XE8lPbQcqiGSv905J\n",
       "vZ/gr/RmJYdyJgexmFye5GVgKgCRHIZwGMVk8yeepj+D6cNi/sSRvMPl9OMS9uUF9uERAEZyKc8x\n",
       "iIu4nxsYw2aM5VxeTOhJWryN+iWqvx6V1AwYvLRh2/Ae73INi7iPleSwlP1pw5Pk8QXz2An4iHfp\n",
       "v97zI22ZzXfpyQfEatEqMJdDgEk8x25ksZTNWNHYjwPAQvaiLS/ThVK6UEobxlYe24LRAIxje8r5\n",
       "HuN4lHFAJJss5gPwIb0Yw2VENiVSQBterfZcajgb80tUfz0qqRkweGnDDmEmsxnDHTxGNsW05QMA\n",
       "fsBDvMFNXMcxtOcNvv2VYlgrXkFbiukOfLDWsUhgNdfxCJDN7lyT0BPB+nrxAPJS4S8SyGYmQzhq\n",
       "nTafcTu9GMyJzOD3HM9y+qx1bTW0YrL5Mw/xPYZxPLPW2ZakZsLlJLSuWzmH9zgGgLu5hAr25jf8\n",
       "lF25kwIgi615n2spIJsuvMb53MEQjuBezucbTiWwB/dyAWPYlU0oYT5n83seoTfv8SMe4Y/8gQLy\n",
       "yWZHDuIKruJEDuOjxJ6vMxNZxcF8Th4fkc/qaj12awLZ/swmsjkPsQcAC8nhCXqm2hTQlQUsJIcl\n",
       "HMu3YSuL5ZSxaWLP0ZoUUk5fzudfXEkx2dW2l/jPMUnNhz1eWlcn3mEBFwF/YyU7ATmsIJsF7E4H\n",
       "JtGHcWzDUlaTxV+4gzfYnq1YyFL6cWEqsM2jgK4s59+8Ride59jUcNwfuZN9uI69+IxxfJ93uYJ9\n",
       "OTvR5/sZUxnJGO5jHFl8RQ4zyGYJawLUmhDVhVJ68gtmM4LhbArksBl/AWaxGTfzCs/zKovIYzIV\n",
       "5AOwBc/xKSMZwf+yG79wcn0D+xHF/IjT1rstSc2AwUvrOpRp3EMvviCfLEpow0e8xU4sZ3e+x028\n",
       "xQBGcwyRbMrpxHx6sDf/JrCaO7mazrzOIbxe5YprepG+pB2r2ZW3uYm3U0cqyE38+QCO4A56cRuz\n",
       "aMujPE1npnIBo6q1GcRHwLHrnHshfwX+us7+wbwL9GucgiVJLYHBS+vqRBmReTzDMZTzIZHZTOeH\n",
       "LKcbX5LFp5zCHpxBe5bzf1zBV7TnPdqyG2fxMXvyCf34E4P4MReynByyyONt8llKASUs44ecUe1+\n",
       "b6d6jOaQz8zUBOniar+MbHhPM5JyehJpSwGPMYgPG/V+kiRh8NL65PIGX3ESXbmIHZjBq7xEDu9T\n",
       "wteUsoQD+YC3+A7L2Js8xtCRL1lAPqfzKJN5ntG8TR8+4XXms4qV9OETAMbzCZPZiXN5nlLgKXbk\n",
       "JKYDMIeCOCMmM1H6Ss5L5D6SJFVh8FLNOjKe5ZzPgUxiW1ZRxEraMZ6TmM4NfMANvE4WX5DLBAD+\n",
       "wya8yf0U0QYIFHI1UH3e0+6cyR6cx2RuZDgXALnk8yykgldjK6YkI0sONHbvnSSp2QgxNu1fv4cQ\n",
       "YozRtZESEHqFnnVeM6kxjEqwx0vNwkb9PenfP5KagNpyiz/DliRJSojBS5IkKSHO8dJ/ZWoOVNX7\n",
       "S5LUghm8VMkXDEuS1LgMXpKaro3phbXHVFIz4K8aJUmSGoi/apQkSWoiDF6SJEkJMXhJkiQlxOAl\n",
       "SZKUEIOXJElSQgxekiRJCTF4SZIkJcTgJUmSlBBXrpe0UULn0J1C8mptWEyJr6GSpOoMXpI2TiF5\n",
       "DGJ5re0y+cJ1SWqiHGqUJElKiMFLkiQpIQYvSZKkhBi8JEmSEmLwkiRJSojBS5IkKSEuJyGpfm7n\n",
       "VJbyPwAEiokUkssULufXGa5Mkposg5ek+rmQB4EHM12GJDUnBi+pFat1FXpXn5ekBmXwkuqpzq/O\n",
       "aQwNFYhqW4Xe1eclqUEZvKT6quurcxqDgUiSmiV/1Sg1FbdxBv+mbeX2MGZlsBpJUiOwx0tqCpaQ\n",
       "xVLOYD5PsS2rUntjYve/hne4mn15nq2ZzG/5Dcevt20xJXXqcSumpCFLlKSWwOAlpetWziGLVVzE\n",
       "/dzEMErZkd9wIvewHws4ifaMo5jzgUBbXuHXXA+s6dFqx0Os5sfk8wKRLRjLE7zCIn7DiQCM5Nes\n",
       "pD+BVRzAaezPogw+KQBOtpek+nOoUUpXJ95hJfsAUEJvIvkUk81i9iGPf7OIqziY47mQgymhN3cw\n",
       "IHVmOzblPYYygF9xO4H5HMJxlaEL8mnPJIYygDaMZwInN9ozZPEVANlUkMXiRruPJLVyBi8pXYcy\n",
       "jTJ2ZRoFBFaTxyT+QW9WszfZfEMeb9GHxbSngvY8wxL2TZ1Zzpk8v4Erl3AWrwBQwFRK6dZozzCE\n",
       "nwAwkC+4kl802n0kqZVzqFENLqPLLDSG2pZu6EQZWXzKOE6gDRMpYDoL2I9ytqEdn7OKXSvbxip/\n",
       "htXkbvDOZZWfAhVAdr2fob5WslXoFZK5l2uGSWoFDF5qeJlcZqEx1GUieRsmsIRz6MpF7MAMXuUa\n",
       "cnif7zGZ1xnB23RkZ75hKUfzHe6t8RqBZXzFJsDXDfwE9dcuwb+WLpEhqRVwqFFNx+38jD9wbINe\n",
       "81qe5GF2WWf/7zmBG7m2we7TkfFEOnEgk9ifRQRW0o7x9GMhm3M9Y3mC2xlLHlM4m7Gps6r/anFT\n",
       "HmYSj3Atj9VwPK7TXpLU7NjjpabjQv7WCFddX1hp2BBzBm8BPSq3h7J/5efzeA54bp1zhvG9atsX\n",
       "cT9wf43Hz+UF4IWGKrdJeJ6tmcSDDOWgTJciSUkxeKlx/YFj+Jr/BXLJZTLnciW3MZMC7l5nmYSR\n",
       "XEI2y7iYuxjFznzMjUTaks1cBnIx8+jIFO5iCAMBeJYeTOMOhjCQW7iIlfQn0pY83uVyLqus4XOO\n",
       "YwS3EMmhBxfzc6ZUq/FNCnmdGymnKwDduJrBvJvYdyRJajUMXmo8T7I9SziCCziS9lRwI9fxIMcA\n",
       "7WjPJC7lZm7mKiZwMvvze6oOp83id3TjSk5jAiO5hHFczGUMYypLGMVODOIj/sWJbMKjABzAfezF\n",
       "bwG4gd9xJ/05m3FAINKWIRzC/ezNJ9wGHAT8d8b464xgK+5mMBN5ka2YyCNA3+S+qGbiFi5kBccQ\n",
       "WEQ2X9CWqXThzXUC8p4sqTE478kSHmYXZnMbEGnLa5l+JElKmsFLjeczfkwZu/I7XgRI/Ut4EWsv\n",
       "k7CkyrAcwBQ2IdKe05gAQC+e4H3+AkAHHuFTTmQFw1jFEfTjMAAmsh8vcQ6RdkQ6sJyZwDgg0oln\n",
       "ATiNCVzDpkxm02r3K+XHfMb2jEhtRwqYRVt6Vq4g33LVtgr9qtTq83+lNys5lDM5iMXk8iQvA1OZ\n",
       "xe1046pqAXlPhtUYnPdkGLP5Ld24gtOYyM1cldBTSlKTYfBS42rHE/yaG6vtG8bZlZ/rskxCrNI7\n",
       "dQQv8iAX8xBvkcNU9uIb5tKGhVzPDxnIwXzJSC4m0ma918uhYq09gTP4CV0orfNzQd1fndMYGuh1\n",
       "PLUt31C5lMRC9qItL9OFUrpQShvGUkE+kc3WCcjrC86T2TS1fyIA3XmKmRzYEM8hSc2FwUuNpxtv\n",
       "8BH38yZ/4UcUM54OLKpDUOnNMp7ja+5nL05jIjM5jjz+D4DurKYNrzGfG+jCxQB8lQpZO7CYj8hn\n",
       "JT8hn7+nrhZYyJHA29zPXgS+YReW82qV++XyGo9wOpdwJwCj2JlBfFhbma1szalI1eHZmlvUfHxj\n",
       "90tSC+ZyEmo8x/Exm3MzrzKK4YxlDI/wFZ2pyzIJPbmQzxnCcMZSwo4MSM3fAujCM0AFp6XmCO3J\n",
       "EvJ5mAf5J0/xCLlMrnb9wGpG8DKfcQPbckmV/Wvu248hrGZXhjOW4bzK3EZ8NU9z1ZmJrOJgPieP\n",
       "j8hnNf3JYgUhFZCByoDcm2U17t+dpQS+4YHU/k85JmPPI0kZEmJs2ksDhRBijNH/Mm5GQq/Qs16L\n",
       "bt7IteQzhV/yxAbb3crZVFDApdxa3xo3yigK4ow4K5F7NTHV/lqO5GJWcjRZfEUWX1HAP+nM1NQk\n",
       "+nZkM5fDuIjdWcoodqpx/8N8n9ncRiDShtdZRT+G0h9o1d+zpJajttziUKOahpFcSim96cPIDba7\n",
       "jnsppxuHcEJClelbR3AHvbiNWbTlUZ6mM9MYxEfAkeu0Xd/+k/kAKl8SDnBdY5UrSU2RwUtNw6WM\n",
       "hFpCF8BVnN74xahGTzOScnoSaUsBj9VlHpwkqTqDl6S6uZLzMl2CJDV3Bi81vEwus9AYGmjphmYp\n",
       "yb+Wrfl7ltRqOLlekiSpgdSWW+q9nEQIoTCEMDaE8K8QwpgQQof1tBsYQpgRQpgVQrisyv5hIYTP\n",
       "QwiTU38MrG8tkiRJzUE663hdDoyNMe4AvJLariaEkA38ERgI7AQMCiHsmDocgdtijLun/ngpjVok\n",
       "SZKavHSC15HAg6nPDwJH19Bmb+DjGOOcGGMp8ChwVJXjDiFKkqRWI53gtUWMcX7q83xgixradAU+\n",
       "q7L9eWrft84PIUwJIdy7vqFKSZKklmKDv2oMIYwFtqzh0FVVN2KMMYRQ0yz9Dc3cvwMYnvo8ArgV\n",
       "al6jKYQwrMpmUYyxaAPXlSRJSkQIoS/Qt67tNxi8YowHb+BG80MIW8YYvwwhdAEW1NBsHtCtynY3\n",
       "1vR6EWOsbB9CuAcqX2pcUx3DNlSnJElSJqQ6g4q+3Q4hXL2h9ukMNY4GTk19PhV4toY27wI9Qwjb\n",
       "hBDygBNT55EKa9/6KTAtjVokSZKavHqv4xVCKAQeB74LzAFOiDF+HULYCrg7xnh4qt2hwO1ANnBv\n",
       "jPGG1P6HgN1YMxz5CXBWlTljVe/jOl6SJKlZqC23uICqJElSA2m0BVQlSZK0cQxekiRJCTF4SZIk\n",
       "JcTgJUmSlBCDlyRJUkIMXpIkSQkxeEmSJCXE4CVJkpQQg5ckSVJCDF6SJEkJMXhJkiQlxOAlSZKU\n",
       "EIOXJElSQgxekiRJCTF4SZIkJcTgJUmSlBCDlyRJUkIMXpIkSQkxeEmSJCXE4CVJkpQQg5ckSVJC\n",
       "DF6SJEkJMXhJkiQlxOAlSZKUEIOXJElSQgxekiRJCTF4SZIkJcTgJUmSlBCDlyRJUkJyMl2AJElS\n",
       "cxc6h+4UkkcuhF6hJwDFlMQFcW7VdvZ4SZIkpauQPAaxnLbAIJYziOUUkrd2M4OXJElSQgxekiRJ\n",
       "CTF4SZIkJcTgJUmSlBCDlyRJUkIMXpIkSQkxeEmSJCXE4CVJkpQQg5ckSVJDWQG8Sqf1HTZ4SZIk\n",
       "NZR8oB8L13fY4CVJkpQQg5ckSVJCcjJdgCRJUrNXTAmjKGAVMIqCyn1rCTHGpEvbKCGEGGMMma5D\n",
       "kiSpNrXlFocaJUmSEmLwkiRJSojBS5IkKSEGL0mSpIQYvCRJkhJi8JIkSUqIwUuSJCkhBi9JkqSE\n",
       "GLwkSZISYvCSJElKiMFLkiQpIQYvSZKkhBi8JEmSEmLwkiRJSojBS5IkKSEGL0mSpIQYvCRJkhJi\n",
       "8JIkSUqIwUuSJCkhBi9JkqSEGLwkSZISYvCSJElKiMFLkiQpIQYvSZKkhBi8JEmSEmLwkiRJSojB\n",
       "S5IkKSH1Dl4hhMIQwtgQwr9CCGNCCB3W0+6+EML8EMK0+pwvSZLUUqTT43U5MDbGuAPwSmq7JvcD\n",
       "A9M4X5IkqUUIMcb6nRjCDOCAGOP8EMKWQFGMsdd62m4D/D3GuMvGnh9CiDHGUK8iJUmSElRbbkmn\n",
       "x2uLGOP81Of5wBYJny9JktSs5GzoYAhhLLBlDYeuqroRY4whhPp1ndXh/BDCsCqbRTHGovreS5Ik\n",
       "qaGEEPoCfevcPs2hxr4xxi9DCF2AV+sx1Fjr+Q41SpKk5qIxhxpHA6emPp8KPJvw+ZIkSc1KOj1e\n",
       "hcDjwHeBOcAJMcavQwhbAXfHGA9PtRsFHABsDiwAhsYY71/f+TXcxx4vSZLULNSWW+odvJJi8JIk\n",
       "Sc1FYw41SpIkaSMYvCRJkhKyweUkJLUcoXPoTiF5621QTElcEOcmWJIktToGL6m1KCSPQSxf7/FR\n",
       "FCRYTeJqDZ4bYiiV1EAMXpJah//f3v3HelXXcRx/vvghpIbk3ASEEpGobBI0TdDhdZIRKjbn+qEm\n",
       "mRWrKFaNUthYs9nK0pyrubyypnPlGrSiRRgzWc0RDcePKV4CTaelIF6QLJB7x7s/vofLt9v33vvB\n",
       "e+8553vP67Hd7XzvOffstfe+537f3885n3P6ajx7M8SbUjPLjxsvs6pZzRR2cBfBqQzjAJfzeWax\n",
       "v+hYZmZV4IvrzapGwEwWs4K5nMRmnuDTRUcyM6sKj3iZVc21PNu1HIxiGO0FpjEzqxQ3XmZVdT+X\n",
       "8iaXMY+rio6SuztYyVEmEIziNB5gCT/n2+ziFFo5xFzEYS7lZubwWtFRzWxoceNlVjINZ98N9Ky6\n",
       "/yBe5ofM4Dqm88aA7bdZXMHXuYDXeY7RPMzv2MRa4G2M4UmWcid3spy/cgNzuLfoqGY2tLjxMiub\n",
       "RrPvBnpW3Z8ZhzjIAqp5i4QNfI7f8xEAjjKenUwGjrCIxwA4he0cZE6BCc1siPLF9WZVdA77Gcft\n",
       "RccoxEpmcZhLWMjVrOAKRvA0nYwCOru2EUeB4YVlNLMhy42XWVn9gG9wN4sGZd8vcBr7uH5Q9l12\n",
       "HbydYRzgXbzJKs6lk5lFRzKz6nDjZVZeMWh7nsselg1SU1d21/A4MILb2cBObmMET2Zr6usdDGb9\n",
       "zayyfI2XmVXLeDpY3vDeZdO6lr7EWmBtbpnMrDI84vUWSWopOkOzcw37x/UbAL9gVtERmpnfg/3n\n",
       "GvZPM9bPI15vXQuwoeAMza4F17AvvZ3uauFE6tfOkV5nR7ZzJHlfQ8UBZgMbi47RxFrwMdxfLbiG\n",
       "/dFCk9XPjZdZWS3l7oHc3YDeB6wZNWo8DzIy6VYdVWxKzWxQuPEys0po1HhKao+22FVEHjOrJkWU\n",
       "e+KOpHIHNBtoI4HRwBFqD7QeCRwGOooMZWZmqSJCPa0rfeNlVjV6j6Y2unO9R2bMzJqfZzWamZmZ\n",
       "5cSNl5mZmVlOfHG9Wdk0mn3nWXVmZkOCR7wSSTpd0npJf5P0B0lje9l2uKQtkn6bZ8ayS6mhpEmS\n",
       "Hpf0tKSnJH21iKxFir3xQrTFrmM/7GQKr/KopF2SvtXobyTdm63fJmlG3pnLTtI8SW091VDSDVnt\n",
       "tkt6QtL5ReQsq77qV7fdBZI6JV2bZ76yS6mfpJbsc+MpSRtyjlh6CcfwGZLWSdqa1fAzBcRM4sYr\n",
       "3a3A+oh4N/BY9ronS4Ad+Flv3aXUsAP4WkScB1wEfFnSe3PMWCqShgM/BuYB7wM+1b0ekuYD50bE\n",
       "VOALwH25By2xlBoCzwFzIuJ84DvA/fmmLK/E+h3b7vvAOmrzcY3kY3gs8BPg6oh4P3Bd7kFLLPE9\n",
       "uBjYEhEfoHZT1bsklfKsnhuvdAuAB7PlB4GPNdpI0kRgPvAA/ufTXZ81jIhXImJrtvwG8AwwIbeE\n",
       "5XMhsDsino+IDuAR4Jpu23TVNSI2AWMlnZlvzFLrs4YRsTEiXs9ebgIm5pyxzFLegwBfAVYBr+YZ\n",
       "rgmk1O96YHVEvAQQEftyzlh2KTV8GRiTLY8BXouIzhwzJnPjle7MiNiTLe8Bevpg+xGwFDiaS6rm\n",
       "klpDACSdDcyg9kFYVWcBL9a9fin7XV/buHE4LqWG9W7BD8iu12f9JJ1F7YPw2GirR/uPS3n/TQVO\n",
       "zy6z2Cyp0UPcqyylhq3AeZL+CWyjduaplEo5DFcUSeuBcQ1WLa9/ERHR6Maukq4C9kbElmZ8cOdA\n",
       "6G8N6/ZzKrVvz0uyka+qSv0A6z666g++45JrIeky4LPAxYMXp+mk1O8e4NbsuBYe7a+XUr+RwEzg\n",
       "cuBkYKOkv0T43n2ZlBouA7ZGRIukKcB6SdMj4l+DnO2EufGqExEf7mmdpD2SxkXEK5LGA3sbbDYb\n",
       "WJBdczMaGCPpoYi4aZAil84A1BBJI4HVwMMR8etBitos/gFMqns9idq3vd62mZj9zmpSakh2QX0r\n",
       "MC8i9ueUrRmk1O+DwCO1noszgI9K6oiINflELLWU+r0I7IuIQ8AhSX8CpgNuvGpSajgbuAMgIp6V\n",
       "9HdgGrA5l4QnwKca060BFmbLC4H/awgiYllETIqIycAngT9WqelK0GcNs2/LK4EdEXFPjtnKajMw\n",
       "VdLZkk4CPkGtjvXWADcBSLoIOFB3StcSaijpncCvgBsjYncBGcusz/pFxDkRMTn737cK+KKbri4p\n",
       "x/BvgEuyGfEnAx+iNkHLalJq2AbMBciucZ1GbdJM6XjEK933gF9KugV4Hvg4gKQJQGtEXNngb3y6\n",
       "53+l1PBi4EZgu6Qt2d/dFhHrCshbuIjolLQYeBQYDqyMiGckLcrW/zQi1kqaL2k38G/g5gIjl05K\n",
       "DYEVwDuA+7JRm46IuLCozGWSWD/rQeIx3CZpHbCd2vXBrRHhxiuT+B78LvAzSduoDSp9MyLaCwvd\n",
       "Cz+r0czMzCwnPtVoZmZmlhM3XmZmZmY5ceNlZmZmlhM3XmZmZmY5ceNlZmZmlhM3XmZmZmY5ceNl\n",
       "ZmZmlpP/AmEL117Cp3ZyAAAAAElFTkSuQmCC\n"
      ],
      "text/plain": [
       "<matplotlib.figure.Figure at 0xb6d7128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the word vectors you trained\n",
    "\n",
    "_, wordVectors0, _ = load_saved_params()\n",
    "wordVectors = (wordVectors0[:nWords,:] + wordVectors0[nWords:,:])\n",
    "visualizeWords = [\"the\", \"a\", \"an\", \",\", \".\", \"?\", \"!\", \"``\", \"''\", \"--\", \"good\", \"great\", \"cool\", \"brilliant\", \"wonderful\", \"well\", \"amazing\", \"worth\", \"sweet\", \"enjoyable\", \"boring\", \"bad\", \"waste\", \"dumb\", \"annoying\"]\n",
    "visualizeIdx = [tokens[word] for word in visualizeWords]\n",
    "visualizeVecs = wordVectors[visualizeIdx, :]\n",
    "temp = (visualizeVecs - np.mean(visualizeVecs, axis=0))\n",
    "covariance = 1.0 / len(visualizeIdx) * temp.T.dot(temp)\n",
    "U,S,V = np.linalg.svd(covariance)\n",
    "coord = temp.dot(U[:,0:2]) \n",
    "\n",
    "for i in xrange(len(visualizeWords)):\n",
    "    plt.text(coord[i,0], coord[i,1], visualizeWords[i], bbox=dict(facecolor='green', alpha=0.1))\n",
    "    \n",
    "plt.xlim((np.min(coord[:,0]), np.max(coord[:,0])))\n",
    "plt.ylim((np.min(coord[:,1]), np.max(coord[:,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Sentiment Analysis\n",
    "\n",
    "Now, with the word vectors you trained, we are going to perform a simple sentiment analysis.\n",
    "\n",
    "For each sentence in the Stanford Sentiment Treebank dataset, we are going to use the average of all the word vectors in that sentence as its feature, and try to predict the sentiment level of the said sentence. The sentiment level of the phrases are represented as real values in the original dataset, here we'll just use five classes:\n",
    "\n",
    "    \"very negative\", \"negative\", \"neutral\", \"positive\", \"very positive\"\n",
    "    \n",
    "which are represented by 0 to 4 in the code, respectively.\n",
    "\n",
    "For this part, you will learn to train a softmax regressor with SGD, and perform train/dev validation to improve generalization of your regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now, implement some helper functions\n",
    "\n",
    "def getSentenceFeature(tokens, wordVectors, sentence):\n",
    "    \"\"\" Obtain the sentence feature for sentiment analysis by averaging its word vectors \"\"\"\n",
    "    ###################################################################\n",
    "    # Implement computation for the sentence features given a         #\n",
    "    # sentence.                                                       #\n",
    "    # Inputs:                                                         #\n",
    "    #   - tokens: a dictionary that maps words to their indices in    #\n",
    "    #             the word vector list                                #\n",
    "    #   - wordVectors: word vectors for all tokens                    #\n",
    "    #   - sentence: a list of words in the sentence of interest       #\n",
    "    # Output:                                                         #\n",
    "    #   - sentVector: feature vector for the sentence                 #\n",
    "    ###################################################################\n",
    "    \n",
    "    sentVector = np.zeros((wordVectors.shape[1],))\n",
    "    \n",
    "    ### YOUR CODE HERE\n",
    "    for t in sentence:\n",
    "        sentVector += wordVectors[tokens[t]]\n",
    "    sentVector /= len(sentence)\n",
    "    ### END YOUR CODE\n",
    "    \n",
    "    return sentVector\n",
    "\n",
    "def softmaxRegression(features, labels, weights, regularization = 0.0, nopredictions = False):\n",
    "    \"\"\" Softmax Regression \"\"\"\n",
    "    ###################################################################\n",
    "    # Implement softmax regression with weight regularization.        #\n",
    "    # Inputs:                                                         #\n",
    "    #   - features: feature vectors, each row is a feature vector     #\n",
    "    #   - labels: labels corresponding to the feature vectors         #\n",
    "    #   - weights: weights of the regressor                           #\n",
    "    #   - regularization: L2 regularization constant                  #\n",
    "    # Output:                                                         #\n",
    "    #   - cost: cost of the regressor                                 #\n",
    "    #   - grad: gradient of the regressor cost with respect to its    #\n",
    "    #           weights                                               #\n",
    "    #   - pred: label predictions of the regressor (you might find    #\n",
    "    #           np.argmax helpful)                                    #\n",
    "    ###################################################################\n",
    "    \n",
    "    prob = softmax(features.dot(weights))\n",
    "    if len(features.shape) > 1:\n",
    "        N = features.shape[0]\n",
    "    else:\n",
    "        N = 1\n",
    "    # A vectorized implementation of    1/N * sum(cross_entropy(x_i, y_i)) + 1/2*|w|^2\n",
    "    cost = np.sum(-np.log(prob[range(N), labels])) / N \n",
    "    cost += 0.5 * regularization * np.sum(weights ** 2)\n",
    "    \n",
    "    ### YOUR CODE HERE: compute the gradients and predictions\n",
    "    #print features.shape, labels.shape, prob.shape, weights.shape\n",
    "    y = np.zeros_like(prob)\n",
    "    y[range(N), labels] = 1\n",
    "    grad = features.T.dot(prob-y) / N + regularization*weights\n",
    "    #print grad.shape\n",
    "    pred = np.argmax(prob, axis=1)\n",
    "    ### END YOUR CODE\n",
    "    \n",
    "    if nopredictions:\n",
    "        return cost, grad\n",
    "    else:\n",
    "        return cost, grad, pred\n",
    "\n",
    "def precision(y, yhat):\n",
    "    \"\"\" Precision for classifier \"\"\"\n",
    "    assert(y.shape == yhat.shape)\n",
    "    return np.sum(y == yhat) * 100.0 / y.size\n",
    "\n",
    "def softmax_wrapper(features, labels, weights, regularization = 0.0):\n",
    "    cost, grad, _ = softmaxRegression(features, labels, weights, regularization)\n",
    "    return cost, grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Gradient check for softmax regression ====\n",
      "Gradient check passed!\n",
      "\n",
      "=== For autograder ===\n",
      "(1.8898664623390471, array([[ 0.10784719,  0.00172068,  0.08397937,  0.14776651,  0.08992627],\n",
      "       [-0.10826474, -0.07471581,  0.0098131 ,  0.08940255,  0.02169381],\n",
      "       [-0.0429461 , -0.08762558,  0.04974576,  0.00127109, -0.03934647],\n",
      "       [ 0.10049874,  0.23456965, -0.0252235 , -0.05538292, -0.0233519 ],\n",
      "       [ 0.13087744,  0.07483317, -0.04913026,  0.00814577, -0.23173774],\n",
      "       [ 0.04334499, -0.02633654,  0.26824201,  0.11725696,  0.07508793],\n",
      "       [-0.13951212, -0.16221602, -0.23853175, -0.14250633,  0.07922634],\n",
      "       [ 0.13853846,  0.07333516, -0.06034437,  0.10827209, -0.13089709],\n",
      "       [-0.21596542,  0.17896988,  0.0545159 ,  0.08952888,  0.0009748 ],\n",
      "       [-0.05271008, -0.00310361,  0.11013229, -0.06217713,  0.10385852]]), array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "# Gradient check always comes first\n",
    "random.seed(314159)\n",
    "np.random.seed(265)\n",
    "dummy_weights = 0.1 * np.random.randn(dimVectors, 5)\n",
    "dummy_features = np.zeros((10, dimVectors))\n",
    "dummy_labels = np.zeros((10,), dtype=np.int32)    \n",
    "for i in xrange(10):\n",
    "    words, dummy_labels[i] = dataset.getRandomTrainSentence()\n",
    "    dummy_features[i, :] = getSentenceFeature(tokens, wordVectors, words)\n",
    "print \"==== Gradient check for softmax regression ====\"\n",
    "gradcheck_naive(lambda weights: softmaxRegression(dummy_features, dummy_labels, weights, 1.0, nopredictions = True), dummy_weights)\n",
    "\n",
    "print \"\\n=== For autograder ===\"\n",
    "print softmaxRegression(dummy_features, dummy_labels, dummy_weights, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 100th iteration, cost function is 1.57152691\n",
      "After 200th iteration, cost function is 1.57107835948\n",
      "After 300th iteration, cost function is 1.57065024201\n",
      "After 400th iteration, cost function is 1.57024118668\n",
      "After 500th iteration, cost function is 1.5698499288\n",
      "After 600th iteration, cost function is 1.56947530126\n",
      "After 700th iteration, cost function is 1.56911622668\n",
      "After 800th iteration, cost function is 1.56877171018\n",
      "After 900th iteration, cost function is 1.56844083265\n",
      "After 1000th iteration, cost function is 1.56812274469\n",
      "After 1100th iteration, cost function is 1.56781666088\n",
      "After 1200th iteration, cost function is 1.56752185471\n",
      "After 1300th iteration, cost function is 1.56723765375\n",
      "After 1400th iteration, cost function is 1.56696343534\n",
      "After 1500th iteration, cost function is 1.56669862257\n",
      "After 1600th iteration, cost function is 1.56644268061\n",
      "After 1700th iteration, cost function is 1.56619511336\n",
      "After 1800th iteration, cost function is 1.56595546033\n",
      "After 1900th iteration, cost function is 1.56572329387\n",
      "After 2000th iteration, cost function is 1.56549821651\n",
      "After 2100th iteration, cost function is 1.5652798586\n",
      "After 2200th iteration, cost function is 1.56506787615\n",
      "After 2300th iteration, cost function is 1.56486194879\n",
      "After 2400th iteration, cost function is 1.56466177795\n",
      "After 2500th iteration, cost function is 1.56446708517\n",
      "After 2600th iteration, cost function is 1.56427761054\n",
      "After 2700th iteration, cost function is 1.5640931113\n",
      "After 2800th iteration, cost function is 1.5639133605\n",
      "After 2900th iteration, cost function is 1.56373814584\n",
      "After 3000th iteration, cost function is 1.56356726855\n",
      "After 3100th iteration, cost function is 1.56340054234\n",
      "After 3200th iteration, cost function is 1.56323779256\n",
      "After 3300th iteration, cost function is 1.56307885523\n",
      "After 3400th iteration, cost function is 1.56292357635\n",
      "After 3500th iteration, cost function is 1.56277181112\n",
      "After 3600th iteration, cost function is 1.5626234233\n",
      "After 3700th iteration, cost function is 1.56247828455\n",
      "After 3800th iteration, cost function is 1.56233627394\n",
      "After 3900th iteration, cost function is 1.56219727736\n",
      "After 4000th iteration, cost function is 1.56206118707\n",
      "After 4100th iteration, cost function is 1.56192790127\n",
      "After 4200th iteration, cost function is 1.56179732365\n",
      "After 4300th iteration, cost function is 1.56166936304\n",
      "After 4400th iteration, cost function is 1.56154393307\n",
      "After 4500th iteration, cost function is 1.56142095183\n",
      "After 4600th iteration, cost function is 1.56130034157\n",
      "After 4700th iteration, cost function is 1.56118202843\n",
      "After 4800th iteration, cost function is 1.56106594221\n",
      "After 4900th iteration, cost function is 1.5609520161\n",
      "After 5000th iteration, cost function is 1.56084018646\n",
      "After 5100th iteration, cost function is 1.56073039265\n",
      "After 5200th iteration, cost function is 1.56062257682\n",
      "After 5300th iteration, cost function is 1.56051668374\n",
      "After 5400th iteration, cost function is 1.56041266065\n",
      "After 5500th iteration, cost function is 1.56031045708\n",
      "After 5600th iteration, cost function is 1.56021002475\n",
      "After 5700th iteration, cost function is 1.56011131743\n",
      "After 5800th iteration, cost function is 1.56001429078\n",
      "After 5900th iteration, cost function is 1.55991890231\n",
      "After 6000th iteration, cost function is 1.5598251112\n",
      "After 6100th iteration, cost function is 1.55973287828\n",
      "After 6200th iteration, cost function is 1.55964216587\n",
      "After 6300th iteration, cost function is 1.55955293775\n",
      "After 6400th iteration, cost function is 1.55946515903\n",
      "After 6500th iteration, cost function is 1.55937879614\n",
      "After 6600th iteration, cost function is 1.5592938167\n",
      "After 6700th iteration, cost function is 1.55921018949\n",
      "After 6800th iteration, cost function is 1.55912788439\n",
      "After 6900th iteration, cost function is 1.55904687232\n",
      "After 7000th iteration, cost function is 1.55896712517\n",
      "After 7100th iteration, cost function is 1.55888861579\n",
      "After 7200th iteration, cost function is 1.55881131789\n",
      "After 7300th iteration, cost function is 1.55873520606\n",
      "After 7400th iteration, cost function is 1.55866025568\n",
      "After 7500th iteration, cost function is 1.5585864429\n",
      "After 7600th iteration, cost function is 1.55851374461\n",
      "After 7700th iteration, cost function is 1.55844213839\n",
      "After 7800th iteration, cost function is 1.55837160251\n",
      "After 7900th iteration, cost function is 1.55830211585\n",
      "After 8000th iteration, cost function is 1.55823365793\n",
      "After 8100th iteration, cost function is 1.55816620884\n",
      "After 8200th iteration, cost function is 1.55809974923\n",
      "After 8300th iteration, cost function is 1.55803426029\n",
      "After 8400th iteration, cost function is 1.55796972373\n",
      "After 8500th iteration, cost function is 1.55790612175\n",
      "After 8600th iteration, cost function is 1.55784343701\n",
      "After 8700th iteration, cost function is 1.55778165266\n",
      "After 8800th iteration, cost function is 1.55772075225\n",
      "After 8900th iteration, cost function is 1.55766071977\n",
      "After 9000th iteration, cost function is 1.55760153962\n",
      "After 9100th iteration, cost function is 1.55754319659\n",
      "After 9200th iteration, cost function is 1.55748567582\n",
      "After 9300th iteration, cost function is 1.55742896284\n",
      "After 9400th iteration, cost function is 1.55737304353\n",
      "After 9500th iteration, cost function is 1.55731790409\n",
      "After 9600th iteration, cost function is 1.55726353106\n",
      "After 9700th iteration, cost function is 1.55720991127\n",
      "After 9800th iteration, cost function is 1.5571570319\n",
      "After 9900th iteration, cost function is 1.55710488037\n",
      "After 10000th iteration, cost function is 1.55705344442\n",
      "Dev precision (%): 29.972752\n",
      "After 100th iteration, cost function is 1.57173933538\n",
      "After 200th iteration, cost function is 1.57128287887\n",
      "After 300th iteration, cost function is 1.57084969091\n",
      "After 400th iteration, cost function is 1.57043814076\n",
      "After 500th iteration, cost function is 1.57004672987\n",
      "After 600th iteration, cost function is 1.56967408058\n",
      "After 700th iteration, cost function is 1.56931892586\n",
      "After 800th iteration, cost function is 1.56898009985\n",
      "After 900th iteration, cost function is 1.56865652927\n",
      "After 1000th iteration, cost function is 1.56834722551\n",
      "After 1100th iteration, cost function is 1.56805127744\n",
      "After 1200th iteration, cost function is 1.56776784485\n",
      "After 1300th iteration, cost function is 1.56749615245\n",
      "After 1400th iteration, cost function is 1.56723548435\n",
      "After 1500th iteration, cost function is 1.5669851791\n",
      "After 1600th iteration, cost function is 1.5667446251\n",
      "After 1700th iteration, cost function is 1.56651325645\n",
      "After 1800th iteration, cost function is 1.56629054913\n",
      "After 1900th iteration, cost function is 1.56607601754\n",
      "After 2000th iteration, cost function is 1.56586921132\n",
      "After 2100th iteration, cost function is 1.56566971246\n",
      "After 2200th iteration, cost function is 1.56547713267\n",
      "After 2300th iteration, cost function is 1.56529111093\n",
      "After 2400th iteration, cost function is 1.56511131133\n",
      "After 2500th iteration, cost function is 1.56493742103\n",
      "After 2600th iteration, cost function is 1.56476914843\n",
      "After 2700th iteration, cost function is 1.56460622146\n",
      "After 2800th iteration, cost function is 1.56444838607\n",
      "After 2900th iteration, cost function is 1.56429540483\n",
      "After 3000th iteration, cost function is 1.56414705559\n",
      "After 3100th iteration, cost function is 1.56400313035\n",
      "After 3200th iteration, cost function is 1.56386343415\n",
      "After 3300th iteration, cost function is 1.56372778411\n",
      "After 3400th iteration, cost function is 1.56359600847\n",
      "After 3500th iteration, cost function is 1.56346794582\n",
      "After 3600th iteration, cost function is 1.56334344429\n",
      "After 3700th iteration, cost function is 1.56322236088\n",
      "After 3800th iteration, cost function is 1.56310456077\n",
      "After 3900th iteration, cost function is 1.5629899168\n",
      "After 4000th iteration, cost function is 1.56287830885\n",
      "After 4100th iteration, cost function is 1.56276962342\n",
      "After 4200th iteration, cost function is 1.56266375308\n",
      "After 4300th iteration, cost function is 1.56256059614\n",
      "After 4400th iteration, cost function is 1.56246005618\n",
      "After 4500th iteration, cost function is 1.56236204174\n",
      "After 4600th iteration, cost function is 1.56226646597\n",
      "After 4700th iteration, cost function is 1.56217324634\n",
      "After 4800th iteration, cost function is 1.56208230435\n",
      "After 4900th iteration, cost function is 1.56199356524\n",
      "After 5000th iteration, cost function is 1.5619069578\n",
      "After 5100th iteration, cost function is 1.56182241411\n",
      "After 5200th iteration, cost function is 1.56173986937\n",
      "After 5300th iteration, cost function is 1.56165926167\n",
      "After 5400th iteration, cost function is 1.56158053182\n",
      "After 5500th iteration, cost function is 1.56150362323\n",
      "After 5600th iteration, cost function is 1.56142848169\n",
      "After 5700th iteration, cost function is 1.56135505528\n",
      "After 5800th iteration, cost function is 1.56128329423\n",
      "After 5900th iteration, cost function is 1.56121315078\n",
      "After 6000th iteration, cost function is 1.56114457909\n",
      "After 6100th iteration, cost function is 1.56107753511\n",
      "After 6200th iteration, cost function is 1.5610119765\n",
      "After 6300th iteration, cost function is 1.56094786253\n",
      "After 6400th iteration, cost function is 1.56088515401\n",
      "After 6500th iteration, cost function is 1.56082381319\n",
      "After 6600th iteration, cost function is 1.5607638037\n",
      "After 6700th iteration, cost function is 1.56070509046\n",
      "After 6800th iteration, cost function is 1.56064763964\n",
      "After 6900th iteration, cost function is 1.56059141859\n",
      "After 7000th iteration, cost function is 1.56053639578\n",
      "After 7100th iteration, cost function is 1.56048254076\n",
      "After 7200th iteration, cost function is 1.56042982406\n",
      "After 7300th iteration, cost function is 1.56037821723\n",
      "After 7400th iteration, cost function is 1.56032769272\n",
      "After 7500th iteration, cost function is 1.56027822386\n",
      "After 7600th iteration, cost function is 1.56022978485\n",
      "After 7700th iteration, cost function is 1.56018235066\n",
      "After 7800th iteration, cost function is 1.56013589708\n",
      "After 7900th iteration, cost function is 1.56009040062\n",
      "After 8000th iteration, cost function is 1.56004583849\n",
      "After 8100th iteration, cost function is 1.56000218859\n",
      "After 8200th iteration, cost function is 1.55995942949\n",
      "After 8300th iteration, cost function is 1.55991754037\n",
      "After 8400th iteration, cost function is 1.55987650101\n",
      "After 8500th iteration, cost function is 1.55983629178\n",
      "After 8600th iteration, cost function is 1.5597968936\n",
      "After 8700th iteration, cost function is 1.55975828794\n",
      "After 8800th iteration, cost function is 1.55972045677\n",
      "After 8900th iteration, cost function is 1.55968338256\n",
      "After 9000th iteration, cost function is 1.55964704827\n",
      "After 9100th iteration, cost function is 1.55961143732\n",
      "After 9200th iteration, cost function is 1.55957653356\n",
      "After 9300th iteration, cost function is 1.55954232128\n",
      "After 9400th iteration, cost function is 1.5595087852\n",
      "After 9500th iteration, cost function is 1.55947591041\n",
      "After 9600th iteration, cost function is 1.55944368242\n",
      "After 9700th iteration, cost function is 1.5594120871\n",
      "After 9800th iteration, cost function is 1.55938111067\n",
      "After 9900th iteration, cost function is 1.55935073972\n",
      "After 10000th iteration, cost function is 1.55932096118\n",
      "Dev precision (%): 29.972752\n",
      "After 100th iteration, cost function is 1.57215662561\n",
      "After 200th iteration, cost function is 1.57167727693\n",
      "After 300th iteration, cost function is 1.57122729898\n",
      "After 400th iteration, cost function is 1.57080443089\n",
      "After 500th iteration, cost function is 1.57040661107\n",
      "After 600th iteration, cost function is 1.57003195853\n",
      "After 700th iteration, cost function is 1.56967875595\n",
      "After 800th iteration, cost function is 1.56934543446\n",
      "After 900th iteration, cost function is 1.56903055971\n",
      "After 1000th iteration, cost function is 1.56873281941\n",
      "After 1100th iteration, cost function is 1.568451012\n",
      "After 1200th iteration, cost function is 1.56818403641\n",
      "After 1300th iteration, cost function is 1.56793088282\n",
      "After 1400th iteration, cost function is 1.56769062433\n",
      "After 1500th iteration, cost function is 1.56746240935\n",
      "After 1600th iteration, cost function is 1.56724545478\n",
      "After 1700th iteration, cost function is 1.56703903987\n",
      "After 1800th iteration, cost function is 1.56684250059\n",
      "After 1900th iteration, cost function is 1.56665522458\n",
      "After 2000th iteration, cost function is 1.56647664659\n",
      "After 2100th iteration, cost function is 1.56630624434\n",
      "After 2200th iteration, cost function is 1.56614353474\n",
      "After 2300th iteration, cost function is 1.56598807053\n",
      "After 2400th iteration, cost function is 1.56583943716\n",
      "After 2500th iteration, cost function is 1.56569725005\n",
      "After 2600th iteration, cost function is 1.565561152\n",
      "After 2700th iteration, cost function is 1.56543081095\n",
      "After 2800th iteration, cost function is 1.56530591782\n",
      "After 2900th iteration, cost function is 1.5651861847\n",
      "After 3000th iteration, cost function is 1.56507134307\n",
      "After 3100th iteration, cost function is 1.56496114224\n",
      "After 3200th iteration, cost function is 1.56485534794\n",
      "After 3300th iteration, cost function is 1.564753741\n",
      "After 3400th iteration, cost function is 1.5646561162\n",
      "After 3500th iteration, cost function is 1.56456228115\n",
      "After 3600th iteration, cost function is 1.56447205534\n",
      "After 3700th iteration, cost function is 1.56438526922\n",
      "After 3800th iteration, cost function is 1.5643017634\n",
      "After 3900th iteration, cost function is 1.56422138786\n",
      "After 4000th iteration, cost function is 1.56414400133\n",
      "After 4100th iteration, cost function is 1.56406947058\n",
      "After 4200th iteration, cost function is 1.56399766991\n",
      "After 4300th iteration, cost function is 1.56392848061\n",
      "After 4400th iteration, cost function is 1.56386179042\n",
      "After 4500th iteration, cost function is 1.56379749317\n",
      "After 4600th iteration, cost function is 1.5637354883\n",
      "After 4700th iteration, cost function is 1.56367568054\n",
      "After 4800th iteration, cost function is 1.56361797952\n",
      "After 4900th iteration, cost function is 1.56356229946\n",
      "After 5000th iteration, cost function is 1.56350855889\n",
      "After 5100th iteration, cost function is 1.56345668038\n",
      "After 5200th iteration, cost function is 1.56340659026\n",
      "After 5300th iteration, cost function is 1.56335821843\n",
      "After 5400th iteration, cost function is 1.5633114981\n",
      "After 5500th iteration, cost function is 1.56326636564\n",
      "After 5600th iteration, cost function is 1.56322276033\n",
      "After 5700th iteration, cost function is 1.56318062427\n",
      "After 5800th iteration, cost function is 1.56313990216\n",
      "After 5900th iteration, cost function is 1.56310054116\n",
      "After 6000th iteration, cost function is 1.56306249079\n",
      "After 6100th iteration, cost function is 1.56302570274\n",
      "After 6200th iteration, cost function is 1.56299013083\n",
      "After 6300th iteration, cost function is 1.56295573082\n",
      "After 6400th iteration, cost function is 1.56292246035\n",
      "After 6500th iteration, cost function is 1.56289027884\n",
      "After 6600th iteration, cost function is 1.56285914738\n",
      "After 6700th iteration, cost function is 1.56282902868\n",
      "After 6800th iteration, cost function is 1.56279988694\n",
      "After 6900th iteration, cost function is 1.56277168782\n",
      "After 7000th iteration, cost function is 1.56274439835\n",
      "After 7100th iteration, cost function is 1.56271798686\n",
      "After 7200th iteration, cost function is 1.56269242293\n",
      "After 7300th iteration, cost function is 1.56266767732\n",
      "After 7400th iteration, cost function is 1.56264372193\n",
      "After 7500th iteration, cost function is 1.56262052974\n",
      "After 7600th iteration, cost function is 1.56259807474\n",
      "After 7700th iteration, cost function is 1.56257633193\n",
      "After 7800th iteration, cost function is 1.56255527722\n",
      "After 7900th iteration, cost function is 1.56253488746\n",
      "After 8000th iteration, cost function is 1.56251514031\n",
      "After 8100th iteration, cost function is 1.5624960143\n",
      "After 8200th iteration, cost function is 1.56247748872\n",
      "After 8300th iteration, cost function is 1.56245954361\n",
      "After 8400th iteration, cost function is 1.56244215975\n",
      "After 8500th iteration, cost function is 1.56242531861\n",
      "After 8600th iteration, cost function is 1.56240900232\n",
      "After 8700th iteration, cost function is 1.56239319364\n",
      "After 8800th iteration, cost function is 1.56237787595\n",
      "After 8900th iteration, cost function is 1.56236303322\n",
      "After 9000th iteration, cost function is 1.56234864998\n",
      "After 9100th iteration, cost function is 1.56233471131\n",
      "After 9200th iteration, cost function is 1.56232120278\n",
      "After 9300th iteration, cost function is 1.56230811051\n",
      "After 9400th iteration, cost function is 1.56229542104\n",
      "After 9500th iteration, cost function is 1.56228312143\n",
      "After 9600th iteration, cost function is 1.56227119916\n",
      "After 9700th iteration, cost function is 1.56225964212\n",
      "After 9800th iteration, cost function is 1.56224843864\n",
      "After 9900th iteration, cost function is 1.56223757744\n",
      "After 10000th iteration, cost function is 1.5622270476\n",
      "Dev precision (%): 30.336058\n",
      "After 100th iteration, cost function is 1.5735400778\n",
      "After 200th iteration, cost function is 1.57291289039\n",
      "After 300th iteration, cost function is 1.57234466836\n",
      "After 400th iteration, cost function is 1.57182930666\n",
      "After 500th iteration, cost function is 1.57136138864\n",
      "After 600th iteration, cost function is 1.57093610333\n",
      "After 700th iteration, cost function is 1.57054917302\n",
      "After 800th iteration, cost function is 1.57019678989\n",
      "After 900th iteration, cost function is 1.56987556052\n",
      "After 1000th iteration, cost function is 1.56958245728\n",
      "After 1100th iteration, cost function is 1.56931477571\n",
      "After 1200th iteration, cost function is 1.56907009717\n",
      "After 1300th iteration, cost function is 1.56884625606\n",
      "After 1400th iteration, cost function is 1.56864131104\n",
      "After 1500th iteration, cost function is 1.56845351974\n",
      "After 1600th iteration, cost function is 1.5682813165\n",
      "After 1700th iteration, cost function is 1.56812329279\n",
      "After 1800th iteration, cost function is 1.56797817997\n",
      "After 1900th iteration, cost function is 1.56784483408\n",
      "After 2000th iteration, cost function is 1.56772222241\n",
      "After 2100th iteration, cost function is 1.5676094116\n",
      "After 2200th iteration, cost function is 1.56750555721\n",
      "After 2300th iteration, cost function is 1.56740989436\n",
      "After 2400th iteration, cost function is 1.56732172954\n",
      "After 2500th iteration, cost function is 1.56724043329\n",
      "After 2600th iteration, cost function is 1.56716543367\n",
      "After 2700th iteration, cost function is 1.56709621054\n",
      "After 2800th iteration, cost function is 1.56703229039\n",
      "After 2900th iteration, cost function is 1.56697324174\n",
      "After 3000th iteration, cost function is 1.56691867109\n",
      "After 3100th iteration, cost function is 1.56686821923\n",
      "After 3200th iteration, cost function is 1.56682155797\n",
      "After 3300th iteration, cost function is 1.56677838725\n",
      "After 3400th iteration, cost function is 1.56673843247\n",
      "After 3500th iteration, cost function is 1.56670144217\n",
      "After 3600th iteration, cost function is 1.56666718586\n",
      "After 3700th iteration, cost function is 1.56663545219\n",
      "After 3800th iteration, cost function is 1.56660604718\n",
      "After 3900th iteration, cost function is 1.56657879268\n",
      "After 4000th iteration, cost function is 1.56655352498\n",
      "After 4100th iteration, cost function is 1.56653009356\n",
      "After 4200th iteration, cost function is 1.56650835992\n",
      "After 4300th iteration, cost function is 1.56648819659\n",
      "After 4400th iteration, cost function is 1.56646948614\n",
      "After 4500th iteration, cost function is 1.56645212037\n",
      "After 4600th iteration, cost function is 1.56643599952\n",
      "After 4700th iteration, cost function is 1.56642103156\n",
      "After 4800th iteration, cost function is 1.56640713159\n",
      "After 4900th iteration, cost function is 1.56639422121\n",
      "After 5000th iteration, cost function is 1.56638222801\n",
      "After 5100th iteration, cost function is 1.56637108509\n",
      "After 5200th iteration, cost function is 1.56636073063\n",
      "After 5300th iteration, cost function is 1.56635110745\n",
      "After 5400th iteration, cost function is 1.56634216266\n",
      "After 5500th iteration, cost function is 1.56633384734\n",
      "After 5600th iteration, cost function is 1.5663261162\n",
      "After 5700th iteration, cost function is 1.56631892732\n",
      "After 5800th iteration, cost function is 1.56631224187\n",
      "After 5900th iteration, cost function is 1.5663060239\n",
      "After 6000th iteration, cost function is 1.56630024006\n",
      "After 6100th iteration, cost function is 1.56629485949\n",
      "After 6200th iteration, cost function is 1.56628985354\n",
      "After 6300th iteration, cost function is 1.56628519568\n",
      "After 6400th iteration, cost function is 1.56628086128\n",
      "After 6500th iteration, cost function is 1.56627682751\n",
      "After 6600th iteration, cost function is 1.56627307316\n",
      "After 6700th iteration, cost function is 1.56626957859\n",
      "After 6800th iteration, cost function is 1.56626632554\n",
      "After 6900th iteration, cost function is 1.56626329707\n",
      "After 7000th iteration, cost function is 1.56626047745\n",
      "After 7100th iteration, cost function is 1.56625785207\n",
      "After 7200th iteration, cost function is 1.56625540735\n",
      "After 7300th iteration, cost function is 1.56625313071\n",
      "After 7400th iteration, cost function is 1.56625101044\n",
      "After 7500th iteration, cost function is 1.56624903564\n",
      "After 7600th iteration, cost function is 1.56624719623\n",
      "After 7700th iteration, cost function is 1.56624548279\n",
      "After 7800th iteration, cost function is 1.56624388659\n",
      "After 7900th iteration, cost function is 1.56624239952\n",
      "After 8000th iteration, cost function is 1.56624101403\n",
      "After 8100th iteration, cost function is 1.5662397231\n",
      "After 8200th iteration, cost function is 1.5662385202\n",
      "After 8300th iteration, cost function is 1.56623739926\n",
      "After 8400th iteration, cost function is 1.56623635464\n",
      "After 8500th iteration, cost function is 1.56623538108\n",
      "After 8600th iteration, cost function is 1.5662344737\n",
      "After 8700th iteration, cost function is 1.56623362796\n",
      "After 8800th iteration, cost function is 1.56623283961\n",
      "After 8900th iteration, cost function is 1.56623210473\n",
      "After 9000th iteration, cost function is 1.56623141965\n",
      "After 9100th iteration, cost function is 1.56623078097\n",
      "After 9200th iteration, cost function is 1.56623018551\n",
      "After 9300th iteration, cost function is 1.56622963032\n",
      "After 9400th iteration, cost function is 1.56622911264\n",
      "After 9500th iteration, cost function is 1.56622862992\n",
      "After 9600th iteration, cost function is 1.56622817978\n",
      "After 9700th iteration, cost function is 1.56622775999\n",
      "After 9800th iteration, cost function is 1.5662273685\n",
      "After 9900th iteration, cost function is 1.56622700337\n",
      "After 10000th iteration, cost function is 1.56622666281\n",
      "Dev precision (%): 29.972752\n",
      "After 100th iteration, cost function is 1.57688668572\n",
      "After 200th iteration, cost function is 1.57539999246\n",
      "After 300th iteration, cost function is 1.57418844088\n",
      "After 400th iteration, cost function is 1.57320033851\n",
      "After 500th iteration, cost function is 1.57239386787\n",
      "After 600th iteration, cost function is 1.57173516621\n",
      "After 700th iteration, cost function is 1.57119678544\n",
      "After 800th iteration, cost function is 1.57075645563\n",
      "After 900th iteration, cost function is 1.57039609133\n",
      "After 1000th iteration, cost function is 1.57010099201\n",
      "After 1100th iteration, cost function is 1.56985919806\n",
      "After 1200th iteration, cost function is 1.56966097153\n",
      "After 1300th iteration, cost function is 1.56949837697\n",
      "After 1400th iteration, cost function is 1.56936494276\n",
      "After 1500th iteration, cost function is 1.56925538706\n",
      "After 1600th iteration, cost function is 1.56916539601\n",
      "After 1700th iteration, cost function is 1.5690914439\n",
      "After 1800th iteration, cost function is 1.56903064725\n",
      "After 1900th iteration, cost function is 1.56898064636\n",
      "After 2000th iteration, cost function is 1.56893950901\n",
      "After 2100th iteration, cost function is 1.56890565205\n",
      "After 2200th iteration, cost function is 1.56887777773\n",
      "After 2300th iteration, cost function is 1.56885482158\n",
      "After 2400th iteration, cost function is 1.56883591014\n",
      "After 2500th iteration, cost function is 1.56882032628\n",
      "After 2600th iteration, cost function is 1.56880748099\n",
      "After 2700th iteration, cost function is 1.56879689027\n",
      "After 2800th iteration, cost function is 1.56878815624\n",
      "After 2900th iteration, cost function is 1.56878095171\n",
      "After 3000th iteration, cost function is 1.5687750075\n",
      "After 3100th iteration, cost function is 1.5687701021\n",
      "After 3200th iteration, cost function is 1.56876605314\n",
      "After 3300th iteration, cost function is 1.56876271044\n",
      "After 3400th iteration, cost function is 1.56875995031\n",
      "After 3500th iteration, cost function is 1.56875767081\n",
      "After 3600th iteration, cost function is 1.56875578793\n",
      "After 3700th iteration, cost function is 1.56875423241\n",
      "After 3800th iteration, cost function is 1.56875294714\n",
      "After 3900th iteration, cost function is 1.56875188501\n",
      "After 4000th iteration, cost function is 1.56875100715\n",
      "After 4100th iteration, cost function is 1.56875028151\n",
      "After 4200th iteration, cost function is 1.5687496816\n",
      "After 4300th iteration, cost function is 1.56874918558\n",
      "After 4400th iteration, cost function is 1.56874877541\n",
      "After 4500th iteration, cost function is 1.5687484362\n",
      "After 4600th iteration, cost function is 1.56874815563\n",
      "After 4700th iteration, cost function is 1.56874792354\n",
      "After 4800th iteration, cost function is 1.56874773154\n",
      "After 4900th iteration, cost function is 1.56874757269\n",
      "After 5000th iteration, cost function is 1.56874744124\n",
      "After 5100th iteration, cost function is 1.56874733247\n",
      "After 5200th iteration, cost function is 1.56874724246\n",
      "After 5300th iteration, cost function is 1.56874716795\n",
      "After 5400th iteration, cost function is 1.56874710628\n",
      "After 5500th iteration, cost function is 1.56874705523\n",
      "After 5600th iteration, cost function is 1.56874701297\n",
      "After 5700th iteration, cost function is 1.56874697798\n",
      "After 5800th iteration, cost function is 1.56874694901\n",
      "After 5900th iteration, cost function is 1.56874692502\n",
      "After 6000th iteration, cost function is 1.56874690515\n",
      "After 6100th iteration, cost function is 1.5687468887\n",
      "After 6200th iteration, cost function is 1.56874687507\n",
      "After 6300th iteration, cost function is 1.56874686379\n",
      "After 6400th iteration, cost function is 1.56874685444\n",
      "After 6500th iteration, cost function is 1.5687468467\n",
      "After 6600th iteration, cost function is 1.56874684028\n",
      "After 6700th iteration, cost function is 1.56874683497\n",
      "After 6800th iteration, cost function is 1.56874683056\n",
      "After 6900th iteration, cost function is 1.56874682691\n",
      "After 7000th iteration, cost function is 1.56874682389\n",
      "After 7100th iteration, cost function is 1.56874682138\n",
      "After 7200th iteration, cost function is 1.56874681931\n",
      "After 7300th iteration, cost function is 1.56874681759\n",
      "After 7400th iteration, cost function is 1.56874681616\n",
      "After 7500th iteration, cost function is 1.56874681498\n",
      "After 7600th iteration, cost function is 1.568746814\n",
      "After 7700th iteration, cost function is 1.56874681319\n",
      "After 7800th iteration, cost function is 1.56874681251\n",
      "After 7900th iteration, cost function is 1.56874681196\n",
      "After 8000th iteration, cost function is 1.56874681149\n",
      "After 8100th iteration, cost function is 1.56874681111\n",
      "After 8200th iteration, cost function is 1.56874681079\n",
      "After 8300th iteration, cost function is 1.56874681053\n",
      "After 8400th iteration, cost function is 1.56874681031\n",
      "After 8500th iteration, cost function is 1.56874681013\n",
      "After 8600th iteration, cost function is 1.56874680998\n",
      "After 8700th iteration, cost function is 1.56874680985\n",
      "After 8800th iteration, cost function is 1.56874680975\n",
      "After 8900th iteration, cost function is 1.56874680966\n",
      "After 9000th iteration, cost function is 1.56874680959\n",
      "After 9100th iteration, cost function is 1.56874680953\n",
      "After 9200th iteration, cost function is 1.56874680948\n",
      "After 9300th iteration, cost function is 1.56874680944\n",
      "After 9400th iteration, cost function is 1.56874680941\n",
      "After 9500th iteration, cost function is 1.56874680938\n",
      "After 9600th iteration, cost function is 1.56874680936\n",
      "After 9700th iteration, cost function is 1.56874680934\n",
      "After 9800th iteration, cost function is 1.56874680932\n",
      "After 9900th iteration, cost function is 1.56874680931\n",
      "After 10000th iteration, cost function is 1.5687468093\n",
      "Dev precision (%): 27.883742\n",
      "After 100th iteration, cost function is 1.58328612076\n",
      "After 200th iteration, cost function is 1.57724910478\n",
      "After 300th iteration, cost function is 1.5739900942\n",
      "After 400th iteration, cost function is 1.57223009149\n",
      "After 500th iteration, cost function is 1.57127926958\n",
      "After 600th iteration, cost function is 1.57076541889\n",
      "After 700th iteration, cost function is 1.57048762663\n",
      "After 800th iteration, cost function is 1.57033740163\n",
      "After 900th iteration, cost function is 1.57025613785\n",
      "After 1000th iteration, cost function is 1.57021216565\n",
      "After 1100th iteration, cost function is 1.57018836548\n",
      "After 1200th iteration, cost function is 1.57017548011\n",
      "After 1300th iteration, cost function is 1.57016850223\n",
      "After 1400th iteration, cost function is 1.57016472255\n",
      "After 1500th iteration, cost function is 1.57016267476\n",
      "After 1600th iteration, cost function is 1.57016156505\n",
      "After 1700th iteration, cost function is 1.57016096355\n",
      "After 1800th iteration, cost function is 1.57016063747\n",
      "After 1900th iteration, cost function is 1.57016046065\n",
      "After 2000th iteration, cost function is 1.57016036476\n",
      "After 2100th iteration, cost function is 1.57016031275\n",
      "After 2200th iteration, cost function is 1.57016028453\n",
      "After 2300th iteration, cost function is 1.57016026921\n",
      "After 2400th iteration, cost function is 1.57016026091\n",
      "After 2500th iteration, cost function is 1.5701602564\n",
      "After 2600th iteration, cost function is 1.57016025395\n",
      "After 2700th iteration, cost function is 1.57016025262\n",
      "After 2800th iteration, cost function is 1.5701602519\n",
      "After 2900th iteration, cost function is 1.5701602515\n",
      "After 3000th iteration, cost function is 1.57016025129\n",
      "After 3100th iteration, cost function is 1.57016025118\n",
      "After 3200th iteration, cost function is 1.57016025111\n",
      "After 3300th iteration, cost function is 1.57016025108\n",
      "After 3400th iteration, cost function is 1.57016025106\n",
      "After 3500th iteration, cost function is 1.57016025105\n",
      "After 3600th iteration, cost function is 1.57016025104\n",
      "After 3700th iteration, cost function is 1.57016025104\n",
      "After 3800th iteration, cost function is 1.57016025104\n",
      "After 3900th iteration, cost function is 1.57016025104\n",
      "After 4000th iteration, cost function is 1.57016025104\n",
      "After 4100th iteration, cost function is 1.57016025104\n",
      "After 4200th iteration, cost function is 1.57016025104\n",
      "After 4300th iteration, cost function is 1.57016025104\n",
      "After 4400th iteration, cost function is 1.57016025104\n",
      "After 4500th iteration, cost function is 1.57016025104\n",
      "After 4600th iteration, cost function is 1.57016025104\n",
      "After 4700th iteration, cost function is 1.57016025104\n",
      "After 4800th iteration, cost function is 1.57016025104\n",
      "After 4900th iteration, cost function is 1.57016025104\n",
      "After 5000th iteration, cost function is 1.57016025104\n",
      "After 5100th iteration, cost function is 1.57016025104\n",
      "After 5200th iteration, cost function is 1.57016025104\n",
      "After 5300th iteration, cost function is 1.57016025104\n",
      "After 5400th iteration, cost function is 1.57016025104\n",
      "After 5500th iteration, cost function is 1.57016025104\n",
      "After 5600th iteration, cost function is 1.57016025104\n",
      "After 5700th iteration, cost function is 1.57016025104\n",
      "After 5800th iteration, cost function is 1.57016025104\n",
      "After 5900th iteration, cost function is 1.57016025104\n",
      "After 6000th iteration, cost function is 1.57016025104\n",
      "After 6100th iteration, cost function is 1.57016025104\n",
      "After 6200th iteration, cost function is 1.57016025104\n",
      "After 6300th iteration, cost function is 1.57016025104\n",
      "After 6400th iteration, cost function is 1.57016025104\n",
      "After 6500th iteration, cost function is 1.57016025104\n",
      "After 6600th iteration, cost function is 1.57016025104\n",
      "After 6700th iteration, cost function is 1.57016025104\n",
      "After 6800th iteration, cost function is 1.57016025104\n",
      "After 6900th iteration, cost function is 1.57016025104\n",
      "After 7000th iteration, cost function is 1.57016025104\n",
      "After 7100th iteration, cost function is 1.57016025104\n",
      "After 7200th iteration, cost function is 1.57016025104\n",
      "After 7300th iteration, cost function is 1.57016025104\n",
      "After 7400th iteration, cost function is 1.57016025104\n",
      "After 7500th iteration, cost function is 1.57016025104\n",
      "After 7600th iteration, cost function is 1.57016025104\n",
      "After 7700th iteration, cost function is 1.57016025104\n",
      "After 7800th iteration, cost function is 1.57016025104\n",
      "After 7900th iteration, cost function is 1.57016025104\n",
      "After 8000th iteration, cost function is 1.57016025104\n",
      "After 8100th iteration, cost function is 1.57016025104\n",
      "After 8200th iteration, cost function is 1.57016025104\n",
      "After 8300th iteration, cost function is 1.57016025104\n",
      "After 8400th iteration, cost function is 1.57016025104\n",
      "After 8500th iteration, cost function is 1.57016025104\n",
      "After 8600th iteration, cost function is 1.57016025104\n",
      "After 8700th iteration, cost function is 1.57016025104\n",
      "After 8800th iteration, cost function is 1.57016025104\n",
      "After 8900th iteration, cost function is 1.57016025104\n",
      "After 9000th iteration, cost function is 1.57016025104\n",
      "After 9100th iteration, cost function is 1.57016025104\n",
      "After 9200th iteration, cost function is 1.57016025104\n",
      "After 9300th iteration, cost function is 1.57016025104\n",
      "After 9400th iteration, cost function is 1.57016025104\n",
      "After 9500th iteration, cost function is 1.57016025104\n",
      "After 9600th iteration, cost function is 1.57016025104\n",
      "After 9700th iteration, cost function is 1.57016025104\n",
      "After 9800th iteration, cost function is 1.57016025104\n",
      "After 9900th iteration, cost function is 1.57016025104\n",
      "After 10000th iteration, cost function is 1.57016025104\n",
      "Dev precision (%): 25.431426\n",
      "After 100th iteration, cost function is 1.58222176025\n",
      "After 200th iteration, cost function is 1.57284244519\n",
      "After 300th iteration, cost function is 1.57132544727\n",
      "After 400th iteration, cost function is 1.57108002382\n",
      "After 500th iteration, cost function is 1.57104030824\n",
      "After 600th iteration, cost function is 1.57103387965\n",
      "After 700th iteration, cost function is 1.57103283884\n",
      "After 800th iteration, cost function is 1.57103267028\n",
      "After 900th iteration, cost function is 1.57103264298\n",
      "After 1000th iteration, cost function is 1.57103263856\n",
      "After 1100th iteration, cost function is 1.57103263784\n",
      "After 1200th iteration, cost function is 1.57103263773\n",
      "After 1300th iteration, cost function is 1.57103263771\n",
      "After 1400th iteration, cost function is 1.5710326377\n",
      "After 1500th iteration, cost function is 1.5710326377\n",
      "After 1600th iteration, cost function is 1.5710326377\n",
      "After 1700th iteration, cost function is 1.5710326377\n",
      "After 1800th iteration, cost function is 1.5710326377\n",
      "After 1900th iteration, cost function is 1.5710326377\n",
      "After 2000th iteration, cost function is 1.5710326377\n",
      "After 2100th iteration, cost function is 1.5710326377\n",
      "After 2200th iteration, cost function is 1.5710326377\n",
      "After 2300th iteration, cost function is 1.5710326377\n",
      "After 2400th iteration, cost function is 1.5710326377\n",
      "After 2500th iteration, cost function is 1.5710326377\n",
      "After 2600th iteration, cost function is 1.5710326377\n",
      "After 2700th iteration, cost function is 1.5710326377\n",
      "After 2800th iteration, cost function is 1.5710326377\n",
      "After 2900th iteration, cost function is 1.5710326377\n",
      "After 3000th iteration, cost function is 1.5710326377\n",
      "After 3100th iteration, cost function is 1.5710326377\n",
      "After 3200th iteration, cost function is 1.5710326377\n",
      "After 3300th iteration, cost function is 1.5710326377\n",
      "After 3400th iteration, cost function is 1.5710326377\n",
      "After 3500th iteration, cost function is 1.5710326377\n",
      "After 3600th iteration, cost function is 1.5710326377\n",
      "After 3700th iteration, cost function is 1.5710326377\n",
      "After 3800th iteration, cost function is 1.5710326377\n",
      "After 3900th iteration, cost function is 1.5710326377\n",
      "After 4000th iteration, cost function is 1.5710326377\n",
      "After 4100th iteration, cost function is 1.5710326377\n",
      "After 4200th iteration, cost function is 1.5710326377\n",
      "After 4300th iteration, cost function is 1.5710326377\n",
      "After 4400th iteration, cost function is 1.5710326377\n",
      "After 4500th iteration, cost function is 1.5710326377\n",
      "After 4600th iteration, cost function is 1.5710326377\n",
      "After 4700th iteration, cost function is 1.5710326377\n",
      "After 4800th iteration, cost function is 1.5710326377\n",
      "After 4900th iteration, cost function is 1.5710326377\n",
      "After 5000th iteration, cost function is 1.5710326377\n",
      "After 5100th iteration, cost function is 1.5710326377\n",
      "After 5200th iteration, cost function is 1.5710326377\n",
      "After 5300th iteration, cost function is 1.5710326377\n",
      "After 5400th iteration, cost function is 1.5710326377\n",
      "After 5500th iteration, cost function is 1.5710326377\n",
      "After 5600th iteration, cost function is 1.5710326377\n",
      "After 5700th iteration, cost function is 1.5710326377\n",
      "After 5800th iteration, cost function is 1.5710326377\n",
      "After 5900th iteration, cost function is 1.5710326377\n",
      "After 6000th iteration, cost function is 1.5710326377\n",
      "After 6100th iteration, cost function is 1.5710326377\n",
      "After 6200th iteration, cost function is 1.5710326377\n",
      "After 6300th iteration, cost function is 1.5710326377\n",
      "After 6400th iteration, cost function is 1.5710326377\n",
      "After 6500th iteration, cost function is 1.5710326377\n",
      "After 6600th iteration, cost function is 1.5710326377\n",
      "After 6700th iteration, cost function is 1.5710326377\n",
      "After 6800th iteration, cost function is 1.5710326377\n",
      "After 6900th iteration, cost function is 1.5710326377\n",
      "After 7000th iteration, cost function is 1.5710326377\n",
      "After 7100th iteration, cost function is 1.5710326377\n",
      "After 7200th iteration, cost function is 1.5710326377\n",
      "After 7300th iteration, cost function is 1.5710326377\n",
      "After 7400th iteration, cost function is 1.5710326377\n",
      "After 7500th iteration, cost function is 1.5710326377\n",
      "After 7600th iteration, cost function is 1.5710326377\n",
      "After 7700th iteration, cost function is 1.5710326377\n",
      "After 7800th iteration, cost function is 1.5710326377\n",
      "After 7900th iteration, cost function is 1.5710326377\n",
      "After 8000th iteration, cost function is 1.5710326377\n",
      "After 8100th iteration, cost function is 1.5710326377\n",
      "After 8200th iteration, cost function is 1.5710326377\n",
      "After 8300th iteration, cost function is 1.5710326377\n",
      "After 8400th iteration, cost function is 1.5710326377\n",
      "After 8500th iteration, cost function is 1.5710326377\n",
      "After 8600th iteration, cost function is 1.5710326377\n",
      "After 8700th iteration, cost function is 1.5710326377\n",
      "After 8800th iteration, cost function is 1.5710326377\n",
      "After 8900th iteration, cost function is 1.5710326377\n",
      "After 9000th iteration, cost function is 1.5710326377\n",
      "After 9100th iteration, cost function is 1.5710326377\n",
      "After 9200th iteration, cost function is 1.5710326377\n",
      "After 9300th iteration, cost function is 1.5710326377\n",
      "After 9400th iteration, cost function is 1.5710326377\n",
      "After 9500th iteration, cost function is 1.5710326377\n",
      "After 9600th iteration, cost function is 1.5710326377\n",
      "After 9700th iteration, cost function is 1.5710326377\n",
      "After 9800th iteration, cost function is 1.5710326377\n",
      "After 9900th iteration, cost function is 1.5710326377\n",
      "After 10000th iteration, cost function is 1.5710326377\n",
      "Dev precision (%): 25.522252\n",
      "After 100th iteration, cost function is 1.57319749107\n",
      "After 200th iteration, cost function is 1.57267108127\n",
      "After 300th iteration, cost function is 1.57266990678\n",
      "After 400th iteration, cost function is 1.57266990416\n",
      "After 500th iteration, cost function is 1.57266990415\n",
      "After 600th iteration, cost function is 1.57266990415\n",
      "After 700th iteration, cost function is 1.57266990415\n",
      "After 800th iteration, cost function is 1.57266990415\n",
      "After 900th iteration, cost function is 1.57266990415\n",
      "After 1000th iteration, cost function is 1.57266990415\n",
      "After 1100th iteration, cost function is 1.57266990415\n",
      "After 1200th iteration, cost function is 1.57266990415\n",
      "After 1300th iteration, cost function is 1.57266990415\n",
      "After 1400th iteration, cost function is 1.57266990415\n",
      "After 1500th iteration, cost function is 1.57266990415\n",
      "After 1600th iteration, cost function is 1.57266990415\n",
      "After 1700th iteration, cost function is 1.57266990415\n",
      "After 1800th iteration, cost function is 1.57266990415\n",
      "After 1900th iteration, cost function is 1.57266990415\n",
      "After 2000th iteration, cost function is 1.57266990415\n",
      "After 2100th iteration, cost function is 1.57266990415\n",
      "After 2200th iteration, cost function is 1.57266990415\n",
      "After 2300th iteration, cost function is 1.57266990415\n",
      "After 2400th iteration, cost function is 1.57266990415\n",
      "After 2500th iteration, cost function is 1.57266990415\n",
      "After 2600th iteration, cost function is 1.57266990415\n",
      "After 2700th iteration, cost function is 1.57266990415\n",
      "After 2800th iteration, cost function is 1.57266990415\n",
      "After 2900th iteration, cost function is 1.57266990415\n",
      "After 3000th iteration, cost function is 1.57266990415\n",
      "After 3100th iteration, cost function is 1.57266990415\n",
      "After 3200th iteration, cost function is 1.57266990415\n",
      "After 3300th iteration, cost function is 1.57266990415\n",
      "After 3400th iteration, cost function is 1.57266990415\n",
      "After 3500th iteration, cost function is 1.57266990415\n",
      "After 3600th iteration, cost function is 1.57266990415\n",
      "After 3700th iteration, cost function is 1.57266990415\n",
      "After 3800th iteration, cost function is 1.57266990415\n",
      "After 3900th iteration, cost function is 1.57266990415\n",
      "After 4000th iteration, cost function is 1.57266990415\n",
      "After 4100th iteration, cost function is 1.57266990415\n",
      "After 4200th iteration, cost function is 1.57266990415\n",
      "After 4300th iteration, cost function is 1.57266990415\n",
      "After 4400th iteration, cost function is 1.57266990415\n",
      "After 4500th iteration, cost function is 1.57266990415\n",
      "After 4600th iteration, cost function is 1.57266990415\n",
      "After 4700th iteration, cost function is 1.57266990415\n",
      "After 4800th iteration, cost function is 1.57266990415\n",
      "After 4900th iteration, cost function is 1.57266990415\n",
      "After 5000th iteration, cost function is 1.57266990415\n",
      "After 5100th iteration, cost function is 1.57266990415\n",
      "After 5200th iteration, cost function is 1.57266990415\n",
      "After 5300th iteration, cost function is 1.57266990415\n",
      "After 5400th iteration, cost function is 1.57266990415\n",
      "After 5500th iteration, cost function is 1.57266990415\n",
      "After 5600th iteration, cost function is 1.57266990415\n",
      "After 5700th iteration, cost function is 1.57266990415\n",
      "After 5800th iteration, cost function is 1.57266990415\n",
      "After 5900th iteration, cost function is 1.57266990415\n",
      "After 6000th iteration, cost function is 1.57266990415\n",
      "After 6100th iteration, cost function is 1.57266990415\n",
      "After 6200th iteration, cost function is 1.57266990415\n",
      "After 6300th iteration, cost function is 1.57266990415\n",
      "After 6400th iteration, cost function is 1.57266990415\n",
      "After 6500th iteration, cost function is 1.57266990415\n",
      "After 6600th iteration, cost function is 1.57266990415\n",
      "After 6700th iteration, cost function is 1.57266990415\n",
      "After 6800th iteration, cost function is 1.57266990415\n",
      "After 6900th iteration, cost function is 1.57266990415\n",
      "After 7000th iteration, cost function is 1.57266990415\n",
      "After 7100th iteration, cost function is 1.57266990415\n",
      "After 7200th iteration, cost function is 1.57266990415\n",
      "After 7300th iteration, cost function is 1.57266990415\n",
      "After 7400th iteration, cost function is 1.57266990415\n",
      "After 7500th iteration, cost function is 1.57266990415\n",
      "After 7600th iteration, cost function is 1.57266990415\n",
      "After 7700th iteration, cost function is 1.57266990415\n",
      "After 7800th iteration, cost function is 1.57266990415\n",
      "After 7900th iteration, cost function is 1.57266990415\n",
      "After 8000th iteration, cost function is 1.57266990415\n",
      "After 8100th iteration, cost function is 1.57266990415\n",
      "After 8200th iteration, cost function is 1.57266990415\n",
      "After 8300th iteration, cost function is 1.57266990415\n",
      "After 8400th iteration, cost function is 1.57266990415\n",
      "After 8500th iteration, cost function is 1.57266990415\n",
      "After 8600th iteration, cost function is 1.57266990415\n",
      "After 8700th iteration, cost function is 1.57266990415\n",
      "After 8800th iteration, cost function is 1.57266990415\n",
      "After 8900th iteration, cost function is 1.57266990415\n",
      "After 9000th iteration, cost function is 1.57266990415\n",
      "After 9100th iteration, cost function is 1.57266990415\n",
      "After 9200th iteration, cost function is 1.57266990415\n",
      "After 9300th iteration, cost function is 1.57266990415\n",
      "After 9400th iteration, cost function is 1.57266990415\n",
      "After 9500th iteration, cost function is 1.57266990415\n",
      "After 9600th iteration, cost function is 1.57266990415\n",
      "After 9700th iteration, cost function is 1.57266990415\n",
      "After 9800th iteration, cost function is 1.57266990415\n",
      "After 9900th iteration, cost function is 1.57266990415\n",
      "After 10000th iteration, cost function is 1.57266990415\n",
      "Dev precision (%): 25.522252\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0xf9981d0>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": [
       "iVBORw0KGgoAAAANSUhEUgAAAlkAAAHuCAYAAACs3xkXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\n",
       "AAALEgAACxIB0t1+/AAAIABJREFUeJzt3XvQbXdZH/DvQ05iAoFcIIaL2HgBpY5CGA3U6wG1QjsD\n",
       "MlYdpyr1MtpWhaFWUKtjnF7w0lrGabWdEUaqo9ahiggiouVYmJGES8IlCZcoIhcTEAiSG8Tk6R97\n",
       "HfPmcM573Wuvtff+fGb2vPtd12dn5Zx88/s9a+3q7gAAsFz3m7oAAIBNJGQBAIxAyAIAGIGQBQAw\n",
       "AiELAGAEQhYAwAh2DVlVdW5VXVVV11bV9VX1/GH5N1fVdVV1d1U9fjWlAgCsj2O7rezuO6vqSd19\n",
       "e1UdS/K6qvrKJG9L8owk/3MVRQIArJtdQ1aSdPftw9tzkpyV5KPd/Y4kqaoRSwMAWF979mRV1f2q\n",
       "6tokNyd5TXdfP35ZAADrbT8jWfckeVxVXZDkVVV1vLtP7OfgVeU7ewCAtdHdS5um2zNk7Tjpx6vq\n",
       "FUm+NMmJA+xnTnENVdWV3X3l1HVwOK7f+nLt1pvrt96WPTi0192FD6mqC4f35yX5+iTXnLrZMgsC\n",
       "ANgEe/VkPSzJ/x16sq5K8vvd/SdV9Yyqel+SJyZ5RVW9cuxCAQDWyV6PcHhbkk97DlZ3/26S3x2r\n",
       "KGbhxNQFcCQnpi6AQzsxdQEcyYmpC2A+qnu83vSqaj1ZAMA6WHZu8bU6AAAjELIAAEYgZAEAjEDI\n",
       "AgAYgZAFADACIQsAYARCFgDACIQsAIARCFkAACMQsgAARiBkAQCMQMgCABiBkAUAMAIhCwBgBEIW\n",
       "AMAIhCwAgBEIWQAAIxCyAABGIGQBAIxAyAIAGIGQBQAwAiELAGAEQhYAwAiELACAEQhZAAAjELIA\n",
       "AEYgZAEAjEDIAgAYgZAFADACIQsAYARCFgDACIQsAIARCFkAACMQsgAARiBkAQCMQMgCABiBkAUA\n",
       "MAIhCwBgBEIWAMAIhCwAgBEIWQAAIxCyAABGIGQBAIxg9JBVlWePfQ4AgLmp7h7v4FWd9I3dedRo\n",
       "JwEAWIKq6u6upR1vBSHr7iTndeeu0U4EAHBEyw5Zq+jJOivJZSs4DwDAbKyq8d10IQCwVYQsAIAR\n",
       "rCJkfSJCFgCwZVYRst4SIQsA2DKrCFnXRsgCALbMKkLWdUkeXpVzVnAuAIBZWEXI+niS9yX53BWc\n",
       "CwBgFlYRsm5P8u6YMgQAtsgqQtZtSW6MkAUAbBEjWQAAI1jVSJaQBQBsFSELAGAEq5oufG+SS6ty\n",
       "7grOBwAwuZWMZHXn77IIWp+3gvMBAExuVSNZiSlDAGCLjB6yunPX8FbIAgC2xipGsk4SsgCArSFk\n",
       "AQCMYNeQVVXnVtVVVXVtVV1fVc8fll9cVa+uqndV1R9V1YX7OJeQBQBsjeru3Teoun93315Vx5K8\n",
       "Lsm/TfK0JH/T3T9XVc9LclF3/+hp9u3ursX7nJXk1iQP7v77ZngAgFnYmVuWYc/pwu4+GYjOSXJW\n",
       "ko9lEbJePCx/cZJv3Ps4uTvJe5J8/qEqBQBYI3uGrKq6X1Vdm+TmJK/p7uuSXNrdNw+b3Jzk0n2e\n",
       "z5QhALAVju21QXffk+RxVXVBkldV1ZNOWd9VdcY5x6q68t7fXnRn8l1CFgAwuao6nuT4aMffqyfr\n",
       "lGJ+MskdSb43yfHuvqmqHpbFCNcXnmb7+8xtVuX7k1zRne85eukAAMuz0p6sqnrIyTsHq+q8JF+f\n",
       "5JokL0vyzGGzZyZ56T7P98Hsf2oRAGBt7TVd+LAkL66q+2URyH6tu/+kqq5J8ttV9T1J/jLJt+zz\n",
       "fB9NcvFhiwUAWBcHmi488ME/fbrwMUle2p0vGO2kAACHsPJHOCzZR2IkCwDYAqsOWR9LclHVys8L\n",
       "ALBSKw073bkryW1JHrTK8wIArNoUI0qa3wGAjTdVyHrwBOcFAFiZKUKW5ncAYOMZyQIAGIGeLACA\n",
       "EZguBAAYgelCAIARGMkCABiBniwAgBGYLgQAGIHpQgCAERjJAgAYwRQh62NJLqia5NwAACux8qDT\n",
       "nb9LcmuSC1Z9bgCAVZlqNMmUIQCw0aYKWZrfAYCNNuVIlpAFAGws04UAACMwXQgAMAIjWQAAIzCS\n",
       "BQAwAo3vAAAjMF0IADAC04UAACMwkgUAMAIjWQAAI5gqZN2S5EFVOWui8wMAjGqSkNWdu5N8IsmF\n",
       "U5wfAGBsU41kJaYMAYANNmXI8qwsAGBjTR2y3GEIAGwk04UAACMwkgUAMAIjWQAAI5h6JEvIAgA2\n",
       "0tQhy3QhALCRTBcCAIzASBYAwAiMZAEAjGDqkSwhCwDYSFOGrI8neWBVjk1YAwDAKCYLWd25O4ug\n",
       "deFUNQAAjGXKkazElCEAsKHmELLcYQgAbJypQ5Y7DAGAjTR1yDKSBQBspKlDlpEsAGAjTR2yNL4D\n",
       "ABtpDiHLdCEAsHGmDlmmCwGAjTR1yDKSBQBspKlDlpEsAGAjTR2yNL4DABtpDiHLdCEAsHGmDlkf\n",
       "T/KAqpw9cR0AAEs1acjqzj1Jbkly4ZR1AAAs29QjWYkpQwBgA80hZLnDEADYOHMIWUayAICNM4eQ\n",
       "ZSQLANg4cwhZnpUFAGycuYQs04UAwEbZNWRV1SOr6jVVdV1Vvb2qnjUsf2xV/VlVvbWqXlZVDzxC\n",
       "DaYLAYCNs9dI1l1JntPdX5TkiUl+oKoek+RXkjy3u78kye8m+ZEj1GAkCwDYOLuGrO6+qbuvHd7f\n",
       "muSGJI9I8qjufu2w2R8n+aYj1GAkCwDYOPvuyaqqy5JcnuSqJNdV1dOHVd+c5JFHqEHjOwCwcY7t\n",
       "Z6OqOj/JS5I8u7s/UVXfneQXq+onk7wsyad22ffKHb+e6O4Tp2xiuhAAWLmqOp7k+GjH7+69Cjg7\n",
       "ycuTvLK7X3Ca9Y9O8mvd/YTTrOvurt2PnwuSvK87DzpQ5QAAS7Sf3HIQe91dWElemOT6nQGrqi4Z\n",
       "ft4vyU8k+eUj1PC3Se5flbOPcAwAgFnZqyfrK5J8e5InVdU1w+upSb6tqt6ZRSP8+7v7Vw9bQHc6\n",
       "yceiLwsA2CB7Thce6eD7HHaryjuSPKM7N4xWDADALlY6XbhCmt8BgI0yl5DlWVkAwEaZS8jyrCwA\n",
       "YKPMKWSZLgQANsZcQpbpQgBgo8wlZBnJAgA2ylxClpEsAGCjzCVkaXwHADbKnEKW6UIAYGPMJWSZ\n",
       "LgQANspcQpbpQgBgo8wlZH0iyblVOWfqQgAAlmEWIas7HaNZAMAGmUXIGmh+BwA2xpxCluZ3AGBj\n",
       "zClkmS4EADbG3EKW6UIAYCPMKWSZLgQANsacQpaRLABgY8wpZBnJAgA2xpxClsZ3AGBjzC1kmS4E\n",
       "ADbCnEKW6UIAYGPMKWSZLgQANsbcQpbpQgBgI8wpZN2a5OyqnDt1IQAARzWbkNWdjilDAGBDzCZk\n",
       "DTS/AwAbYW4hy0gWALAR5hiyNL8DAGtvbiHLdCEAsBHmFrKMZAEAG2FuIctIFgCwEeYWsjS+AwAb\n",
       "YY4hy3QhALD25hayTBcCABthbiHLdCEAsBHmGLJMFwIAa29uIct0IQCwEeYWsm5PclZVzpu6EACA\n",
       "o5hVyOpOx2gWALABZhWyBprfAYC1N9eQpfkdAFhrcwxZpgsBgLU3x5BlJAsAWHtzDFlGsgCAtTfH\n",
       "kKXxHQBYe3MNWaYLAYC1NseQZboQAFh7cwxZpgsBgLU315BluhAAWGtzDFmmCwGAtTfHkPXRJA+u\n",
       "Sk1dCADAYc0uZHXn9iSd5LypawEAOKzZhayB5ncAYK3NOWRpfgcA1tZcQ5bmdwBgrc01ZBnJAgDW\n",
       "2lxDlpEsAGCtzTVkaXwHANbanEOW6UIAYG3NNWSZLgQA1tpcQ5bpQgBgrc05ZJkuBADW1lxDlulC\n",
       "AGCt7RqyquqRVfWaqrquqt5eVc8all9RVVdX1TVV9Yaq+rIl12UkCwBYa9XdZ15Z9dAkD+3ua6vq\n",
       "/CRvSvKNSX45yfO7+1VV9dQkz+3uJ51m/+7uOnBRlfOS3JLk3O6cuUAAgCU5bG45k2O7rezum5Lc\n",
       "NLy/tapuSPKIJH+d5IJhswuTfGBZBS3OlTuqcneS+ye5bZnHBgBYhV1Hsu6zYdVlSf40yRdlMZX3\n",
       "uiSdxZTjP+ru951mn0Mnwqq8P8mXd+evDrM/AMBBLHska1+N78NU4UuSPLu7b03ywiTP6u7PTvKc\n",
       "JC9aVkE7aH4HANbWrtOFSVJVZyf5P0l+vbtfOiy+oru/bnj/kiS/ssv+V+749UR3n9hnbZrfAYDR\n",
       "VNXxJMfHOv6uIauqKotRq+u7+wU7Vt1YVV/T3X+a5MlJ3nWmY3T3lYeszUgWADCaYeDnxMnfq+qn\n",
       "lnn8vUayviLJtyd5a1VdMyz78STfl+S/V9VnJLlj+H3ZPPUdAFhbe91d+LqcuW/rCcsv5z5MFwIA\n",
       "a2uuT3xPTBcCAGtsziHLdCEAsLbmHrJMFwIAa2nOIct0IQCwtuYcsj6Y5B9MXQQAwGHMOWT9eZLz\n",
       "q/LQqQsBADio2Yas7nSSqzP+oyIAAJZutiFrIGQBAGtp7iHrqghZAMAaqu4e7+BV3d11+P1zSZIb\n",
       "k1zUnXuWVxkAwH0dNbecatYjWd35cJK/SfKFU9cCAHAQsw5ZA1OGAMDaWYeQpfkdAFg76xCyjGQB\n",
       "AGtn1o3vi2Pk3Cy+x/Ah3bl9OZUBANzXVjW+J0l37kxyXZLHT10LAMB+zT5kDUwZAgBrRcgCABjB\n",
       "uoQsdxgCAGtlXULWu5M8qCoPnboQAID9WIuQNXylztVJrpi6FgCA/ViLkDXQlwUArA0hCwBgBLN/\n",
       "GOm9x8olSW5MctEwfQgAsDRb9zDSk7rz4SQfSfKFU9cCALCXtQlZg6ui+R0AWAPrGLL0ZQEAsydk\n",
       "AQCMYG0a3xfHy3lZ9GU9pDu3L+u4AABb2/ieJN25I8n1SR4/dS0AALtZq5A10PwOAMzeuoYsfVkA\n",
       "wKwJWQAAI1jHkPXuJBdU5dKpCwEAOJO1C1nDV+q8IUazAIAZW7uQNdD8DgDM2jqHLCNZAMBsrdXD\n",
       "SO89bi7Jojfr4mH6EADgSLb6YaQndefDST6a5AumrgUA4HTWMmQNro4pQwBgptY5ZGl+BwBma91D\n",
       "lpEsAGCW1rLxfXHsnJfkI0kePHxxNADAoWl8HwzB6vokj5+6FgCAU61tyBpofgcAZmndQ5bmdwBg\n",
       "ljYhZBnJAgBmZ91D1ruSXFiVz5y6EACAndY6ZA1fqfOGGM0CAGZmrUPWQPM7ADA7mxCyNL8DALOz\n",
       "tg8jvfcc+cwk78zioaT3jHkuAGBzeRjpKbrzoSS3JHn01LUAAJy09iFr4FEOAMCsCFkAACPYlJB1\n",
       "dTS/AwAzsvaN74vz5LwkH8mi+f2Osc8HAGweje+nMQSrG5JcPnUtAADJhoSsgb4sAGA2hCwAgBFs\n",
       "UsjS/A4AzMYmhax3Jrm4KpdMXQgAwMaErOErdd4QU4YAwAxsTMga6MsCAGZByAIAGMFGPIz03vPl\n",
       "0iTvyOKhpPes6rwAwPpb6cNIq+qRVfWaqrquqt5eVc8alv/vqrpmeL2nqq5ZVkFH0Z2bk3w8yaOm\n",
       "rgUA2G7H9lh/V5LndPe1VXV+kjdV1au7+1tPblBV/znJLWMWeUAnpwzfOXUhAMD22nUkq7tv6u5r\n",
       "h/e3ZvHVNQ8/ub6qKsm3JPnNMYs8IH1ZAMDk9t34XlWXZfHdgFftWPxVSW7u7j9fbllHImQBAJPb\n",
       "a7owSTJMFb4kybOHEa2Tvi3Jb+yx75U7fj3R3ScOWONBXZPkH1bl3O7cOfK5AIA1VVXHkxwf7fh7\n",
       "3V1YVWcneXmSV3b3C3YsP5bk/Uke390fPMO+K7278N7z5s1JfqA7f7bqcwMA62nVdxdWkhcmuX5n\n",
       "wBp8XZIbzhSwJmbKEACY1F49WV+R5NuTPGnHIxueMqz71syr4X0nIQsAmNRGPYz03vPmMUle0Z3P\n",
       "XfW5AYD1tNLpwjX2ziQXV+WSqQsBALbTRoas4St13pjkiqlrAQC200aGrIG+LABgMkIWAMAINrLx\n",
       "fXHuXJrkHUkePEwfAgCckcb3ferOzUk+nuRRU9cCAGyfjQ1Zg6uj+R0AmMCmhyx9WQDAJIQsAIAR\n",
       "bGzj++L8uX+Sv0lycXfunKoOAGD+NL4fQHduz+IOw8unrgUA2C4bHbIGmt8BgJXbhpClLwsAWDkh\n",
       "CwBgBNsQst6R5CFVuWTqQgCA7bHxIWv4Sp03RF8WALBCGx+yBprfAYCV2paQpS8LAFipjX4Y6b11\n",
       "5KFJrk/y4O6M94EBgLXlYaSH0J2bknwiyaOmrgUA2A5bEbIGpgwBgJXZtpCl+R0AWIltCllXx0gW\n",
       "ALAiW9H4niRVuX+SD2fR/H7n1PUAAPOi8f2QunN7kncledzUtQAAm29rQtZA8zsAsBLbGLI0vwMA\n",
       "o9u2kKX5HQBYiW0LWe9IcklVHjJ1IQDAZtuqkNWdu5O8MaYMAYCRbVXIGmh+BwBGt60hy0gWADCq\n",
       "bQxZVye5oiqzeEgqALCZti5kdeevk9yW5POnrgUA2FxbF7IG+rIAgFEJWQAAI9jmkKX5HQAYTXX3\n",
       "eAdf8rdZL0tVHpDkQ0ku7s4np64HAJjesnPLVo5kdee2JO9O8ripawEANtNWhqyBviwAYDRCFgDA\n",
       "CLY9ZGl+BwBGsc0h6x1JLq3Kg6cuBADYPFsbsrpzd5I3xmgWADCCrQ1ZA31ZAMAohCwhCwAYgZCV\n",
       "XFGV2T0wFQBYb1sdsrrz10luS/J5U9cCAGyWrQ5Zg6tjyhAAWDIhS18WADACIUvIAgBGUN093sGX\n",
       "/G3WY6jKA5J8KMnF3fnk1PUAANNYdm7Z+pGs7tyW5N1JHjt1LQDA5tj6kDXQ/A4ALJWQtaAvCwBY\n",
       "KiFrQcgCAJZKyFq4IcmlVbl46kIAgM0gZCXpzt1J3pjkiqlrAQA2g5B1L83vAMDSCFn30pcFACyN\n",
       "kHWvq5JcUZVZPzwVAFgPQtagOx9MckeSz5u6FgBg/QlZ93VVNL8DAEsgZN2XviwAYCmErPtyhyEA\n",
       "sBS7hqyqemRVvaaqrquqt1fVs3as+6GqumFY/rPjl7oSb0ryxVX5jKkLAQDW27E91t+V5DndfW1V\n",
       "nZ/kTVX16iQPTfK0JF/S3XdV1SVjF7oK3bm1KjcmeWwWo1oAAIey60hWd9/U3dcO72/N4utnHpHk\n",
       "XyZ5fnffNaz78NiFrpDmdwDgyPbdk1VVlyW5PIsQ8ugkX11Vr6+qE1X1peOUNwnN7wDAke01XZgk\n",
       "GaYKX5Lk2d39iao6luSi7n5iVX1Zkt9O8rln2PfKHb+e6O4TRyt5dFcned7URQAA46qq40mOj3b8\n",
       "7t6rgLOTvDzJK7v7BcOyVyb5me7+0+H3G5M8obs/csq+3d1r9QT1qpyV5GNJLuvOR6euBwBYjWXn\n",
       "lr3uLqwkL0xy/cmANXhpkicP2zw6yTmnBqx11Z27s7jLUF8WAHBoe/VkfUWSb0/ypKq6Zng9JcmL\n",
       "knxuVb0tyW8m+c6R61w1ze8AwJHsOV14pIOv4XRhklTlGUm+tzv/dOpaAIDVWOl04Ra7OskTqrJ2\n",
       "AREAmAch6zS684Ekd+YMd0wCAOxFyDozz8sCAA5NyDozze8AwKEJWWdmJAsAODR3F55BVc5PcnOS\n",
       "i7rzqanrAQDG5e7CFenOrUn+PMljp64FAFg/QtbuTBkCAIciZO1O8zsAcChC1u6MZAEAhyJk7e76\n",
       "JA+rykVTFwIArBchaxfduTvJm2PKEAA4ICFrb6YMAYADE7L2pvkdADgwIWtvVyV5QlXW8qGqAMA0\n",
       "hKw9dOcDST6Z5HOmrgUAWB9C1v5cHX1ZAMABCFn7o/kdADgQIWt/NL8DAAdS3T3ewZf8bdZTqcr5\n",
       "SW5KcnF3PjV1PQDA8i07txjJ2ofu3JrkL5J8ydS1AADrQcjaP83vAMC+CVn7p/kdANg3IWv/NL8D\n",
       "APsmZO3fdUkeXpWLpi4EAJg/IWufunN3kjcn+bKpawEA5k/IOhjN7wDAvghZB6P5HQDYFyHrYK5K\n",
       "ckVV1v4BqwDAuISsA+jO+5PcleSyiUsBAGbu2NQFrKGTU4bvmboQPt0wyviAJBckuXCXn+dMVSMA\n",
       "20HIOriTIeu3pi5kE1Xl7CyC0F4h6Uw/H5TkU0k+nuSWM/z8eJI7V/WZANhOviD6gKrypCT/sTtf\n",
       "PnUtc7NjFOkw4ejkz8/IvUHoTCFp15/duWv0DwvAxll2bhGyDqgqD0xyU5ILN+0/5jtGkQ4bki5I\n",
       "8skcMhwNP2/rznj/UgLAGSw7t5guPKDufKIqf5HkS5K8aep6ThpGkc7P0ULSyVGk3ULQe5O85Qzr\n",
       "jSIBwEDIOpyTfVlLC1lVOSdH70W6M7sHpI9l0bB/pvW3G0UCgOUQsg7nqiRfmeSXkr8fRXpg9p5K\n",
       "2y0knZ29R5Hes8v6vzWKBADzoSfrEKryxVkErZuzCEgPTHJHjtCsHaNIADApje8zUZXH5N4m77/t\n",
       "zt9NXBIAcARCFgDACJadW3ytDgDACIQsAIARCFkAACMQsgAARiBkAQCMQMgCABiBkAUAMAIhCwBg\n",
       "BEIWAMAIhCwAgBEIWQAAIxCyAABGIGQBAIxAyAIAGIGQBQAwAiELAGAEQhYAwAiELACAEQhZAAAj\n",
       "ELIAAEYgZAEAjEDIAgAYgZAFADACIQsAYARCFgDACIQsAIAR7BqyquqRVfWaqrquqt5eVc8all9Z\n",
       "Ve+vqmuG11NWUy6rUlXHp66Bw3P91pdrt95cP3baayTrriTP6e4vSvLEJD9QVY9J0kl+obsvH15/\n",
       "OHahrNzxqQvgSI5PXQCHdnzqAjiS41MXwHwc221ld9+U5Kbh/a1VdUOSRwyra+TaAADW1r57sqrq\n",
       "siSXJ3n9sOiHquotVfXCqrpwhNoAANZWdffeG1Wdn+REkv/Q3S+tqs9M8uFh9b9P8rDu/p7T7Lf3\n",
       "wQEAZqK7lzZTt2fIqqqzk7w8ySu7+wWnWX9Zkt/v7i9eVlEAAOtur7sLK8kLk1y/M2BV1cN2bPaM\n",
       "JG8bpzwAgPW060hWVX1lkv+X5K1Z3FGYJD+e5NuSPG5Y9p4k39/dN49bKgDA+thXTxYAAAdzkLsL\n",
       "n1JV76iqd1fV886wzS8O699SVZfvtW9VXVxVr66qd1XVH7lLcTwjXb+fr6obhu1/p6ouWMVn2TZj\n",
       "XLsd63+4qu6pqovH/AzbbKzrV1U/NPz5e3tV/ezYn2MbjfT35hVVdfXwIO83VNWXreKzbKMjXr8X\n",
       "VdXNVfW2U7Y/WG7p7j1fSc5KcmOSy5KcneTaJI85ZZt/kuQPhvdPSPL6vfZN8nNJnju8f16Sn9lP\n",
       "PV4He414/b4+yf2G9z/j+q3PtRvWPzLJH2Yx5X/x1J91E18j/tl7UpJXJzl7+P2SqT/rpr1GvHYn\n",
       "knzD8P6pSV4z9WfdxNdRrt/w+1dl8diqt52yz4Fyy35Hsq5IcmN3/2V335Xkt5I8/ZRtnpbkxUnS\n",
       "3VclubCqHrrHvn+/z/DzG/dZDwczyvXr7ld39z3D/lcl+azxP8rWGevPXpL8QpLnjv0BttxY1+9f\n",
       "JXn+sDzd/eGwbGNdu79OcnLU/8IkHxj3Y2yto1y/dPdrk3zsNMc9UG7Zb8h6RJL37fj9/bn3ye97\n",
       "bfPwXfa9tO9tmL85yaX7rIeDGev67fTdSf7gyJVyqlGuXVU9Pcn7u/utyy6Y+xjrz96jknx1Vb2+\n",
       "qk5U1ZcutWqS8a7djyb5L1X1V0l+PsmPLbFm7nWU67ebA+WW/Yas/XbH7+cBXnW64/Vi7E0X/jiW\n",
       "ef0+faeqf5fkU939G4fZn10t/dpV1XlZ3CX8U4fZnwMZ68/esSQXdfcTk/xIkt8+4P7sbaxr98Ik\n",
       "z+ruz07ynCQvOuD+7M9hr9++c8h+cst+Q9YHsujfOOmRWSS+3bb5rGGb0y0/OTx688mhueHZWx/a\n",
       "Zz0czDKv3332rap/kcW89j9fXrnsMMa1+7ws+hTeUlXvGbZ/0/BNDizXWH/23p/kd5Kku9+Q5J6q\n",
       "evDyyibjXbsruvt3h/cvyWJai+U77PXba/r2QLllvyHrjUkeVVWXVdU5Sb41yctO2eZlSb5zOPET\n",
       "k9wyDKnttu/LkjxzeP/MJC/dZz0czCjXr6qeksX/RT+9u+9czUfZOku/dt399u6+tLs/p7s/J4u/\n",
       "eB7f3f4nZ/nG+rvzpUmePOzz6CTndPdHRv8022Wsa3djVX3N8P7JSd418ufYVke5frs5WG45QKf+\n",
       "U5O8M4tu/R8bln1/Fg8iPbnNfxvWvyWLv7TPuO+w/OIkf5zFv2R/lOTCqe9I2NTXSNfv3Unem+Sa\n",
       "4fVLU3/OTXyNce1OOf5fxN2Fa3X9srhb6tey+LaNNyU5PvXn3MTXSNfuS7O4UejaJH+W5PKpP+em\n",
       "vo54/X4zyQeTfDKLvq3vGpYfKLd4GCkAwAj2/TBSAAD2T8gCABiBkAUAMAIhCwBgBEIWAMAIhCwA\n",
       "gBEIWcBoquruqrqmqt5WVb89fKXPUY/501X1tbus//6q+o6jngfgqDwnCxhNVX2iux84vP/1JG/q\n",
       "7v+6Y/2x7v67yQoEGJGRLGBVXpvk86vqa6rqtVX1e0neXlX3q6qfr6qrq+otVfV9J3eoqudV1Vur\n",
       "6tqq+k/Dsl+tqm8a3v9MVV037Pdzw7Irq+qHh/ePq6rXD+t/p6ouHJafGPa9qqreWVVfuep/GMDm\n",
       "OzZ1AcDmq6pjWXyR+B8Miy5P8kXd/d4hVN3S3VdU1WckeV1V/VGSxyR5WhZfqHvnyYCUxbfe9/CF\n",
       "yN/Y3V84nONBO9cP7/9Xkh/o7tdW1U8n+akkzxnWn9XdT6iqpw7Lv368fwLANjKSBYzpvKq6Jskb\n",
       "kvxlkhclqSRXd/d7h23+cZLvHLZ7fRbfDfaoJF+b5EU9fPl4d99yyrFvSXJnVb2wqp6R5I6dK4fQ\n",
       "dUF3v3ZY9OIkX71jk98Zfr45yWVH/JwAn8ZIFjCmO7r78p0LqipJbjtlux/s7lefst03ZBHITqe6\n",
       "++6quiKLMPbPkvzg8P5MTj3WJ4efd8ffhcAIjGQBU3tVkn89TCmmqh5dVfdP8uok33XyjsSqumjn\n",
       "TlX1gCTmXbQiAAAAl0lEQVQXdvcrk/ybJI89uSqLEPa3ST62o9/qO5KcGPvDAJzk/96AMZ3u9uU+\n",
       "ZfmvZDFd9+ZaDHN9KIteq1dV1eOSvLGqPpXkFUl+YscxHpjk96rq3CyC1XNOc/xnJvkfQ2j78yTf\n",
       "dYA6AY7EIxwAAEZguhAAYARCFgDACIQsAIARCFkAACMQsgAARiBkAQCMQMgCABjB/wdX8wgGXqPK\n",
       "qwAAAABJRU5ErkJggg==\n"
      ],
      "text/plain": [
       "<matplotlib.figure.Figure at 0x9f0c6d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Try different regularizations and pick the best!\n",
    "\n",
    "### YOUR CODE HERE\n",
    "\n",
    "regularization = 0.0 # try 0.0, 0.00001, 0.00003, 0.0001, 0.0003, 0.001, 0.003, 0.01 and pick the best\n",
    "precisions = []\n",
    "regularizations = [0.0, 0.00001, 0.00003, 0.0001, 0.0003, 0.001, 0.003, 0.01]\n",
    "for regularization in [0.0, 0.00001, 0.00003, 0.0001, 0.0003, 0.001, 0.003, 0.01]:\n",
    "    \n",
    "    ### END YOUR CODE\n",
    "\n",
    "    random.seed(3141)\n",
    "    np.random.seed(59265)\n",
    "    weights = np.random.randn(dimVectors, 5)\n",
    "\n",
    "    trainset = dataset.getTrainSentences()\n",
    "    nTrain = len(trainset)\n",
    "    trainFeatures = np.zeros((nTrain, dimVectors))\n",
    "    trainLabels = np.zeros((nTrain,), dtype=np.int32)\n",
    "\n",
    "    for i in xrange(nTrain):\n",
    "        words, trainLabels[i] = trainset[i]\n",
    "        trainFeatures[i, :] = getSentenceFeature(tokens, wordVectors, words)\n",
    "\n",
    "    # We will do batch optimization\n",
    "    weights = sgd(lambda weights: softmax_wrapper(trainFeatures, trainLabels, weights, regularization), weights, 3.0, 10000, PRINT_EVERY=100)\n",
    "\n",
    "    # Prepare dev set features\n",
    "    devset = dataset.getDevSentences()\n",
    "    nDev = len(devset)\n",
    "    devFeatures = np.zeros((nDev, dimVectors))\n",
    "    devLabels = np.zeros((nDev,), dtype=np.int32)\n",
    "\n",
    "    for i in xrange(nDev):\n",
    "        words, devLabels[i] = devset[i]\n",
    "        devFeatures[i, :] = getSentenceFeature(tokens, wordVectors, words)\n",
    "\n",
    "    _, _, pred = softmaxRegression(devFeatures, devLabels, weights)\n",
    "    print \"Dev precision (%%): %f\" % precision(devLabels, pred)\n",
    "    precisions.append(precision(devLabels, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29.972752043596731, 29.972752043596731, 30.336058128973661, 29.972752043596731, 27.883742052679381, 25.431425976385103, 25.522252497729337, 25.522252497729337]\n",
      "[0.0, 1e-05, 3e-05, 0.0001, 0.0003, 0.001, 0.003, 0.01]\n",
      "After 100th iteration, cost function is 1.57005964065\n",
      "After 200th iteration, cost function is 1.5696834975\n",
      "After 300th iteration, cost function is 1.56932946268\n",
      "After 400th iteration, cost function is 1.56899589953\n",
      "After 500th iteration, cost function is 1.56868131302\n",
      "After 600th iteration, cost function is 1.56838433653\n",
      "After 700th iteration, cost function is 1.56810371972\n",
      "After 800th iteration, cost function is 1.56783831774\n",
      "After 900th iteration, cost function is 1.56758708142\n",
      "After 1000th iteration, cost function is 1.56734904838\n",
      "After 1100th iteration, cost function is 1.56712333509\n",
      "After 1200th iteration, cost function is 1.5669091296\n",
      "After 1300th iteration, cost function is 1.56670568506\n",
      "After 1400th iteration, cost function is 1.56651231378\n",
      "After 1500th iteration, cost function is 1.56632838196\n",
      "After 1600th iteration, cost function is 1.56615330486\n",
      "After 1700th iteration, cost function is 1.56598654243\n",
      "After 1800th iteration, cost function is 1.5658275954\n",
      "After 1900th iteration, cost function is 1.56567600171\n",
      "After 2000th iteration, cost function is 1.56553133329\n",
      "After 2100th iteration, cost function is 1.56539319315\n",
      "After 2200th iteration, cost function is 1.56526121272\n",
      "After 2300th iteration, cost function is 1.56513504946\n",
      "After 2400th iteration, cost function is 1.5650143847\n",
      "After 2500th iteration, cost function is 1.56489892165\n",
      "After 2600th iteration, cost function is 1.5647883836\n",
      "After 2700th iteration, cost function is 1.56468251234\n",
      "After 2800th iteration, cost function is 1.56458106661\n",
      "After 2900th iteration, cost function is 1.5644838208\n",
      "After 3000th iteration, cost function is 1.56439056374\n",
      "After 3100th iteration, cost function is 1.56430109752\n",
      "After 3200th iteration, cost function is 1.56421523653\n",
      "After 3300th iteration, cost function is 1.56413280651\n",
      "After 3400th iteration, cost function is 1.56405364368\n",
      "After 3500th iteration, cost function is 1.56397759402\n",
      "After 3600th iteration, cost function is 1.5639045125\n",
      "After 3700th iteration, cost function is 1.56383426246\n",
      "After 3800th iteration, cost function is 1.56376671502\n",
      "After 3900th iteration, cost function is 1.56370174853\n",
      "After 4000th iteration, cost function is 1.56363924807\n",
      "After 4100th iteration, cost function is 1.56357910496\n",
      "After 4200th iteration, cost function is 1.5635212164\n",
      "After 4300th iteration, cost function is 1.56346548503\n",
      "After 4400th iteration, cost function is 1.5634118186\n",
      "After 4500th iteration, cost function is 1.5633601296\n",
      "After 4600th iteration, cost function is 1.56331033503\n",
      "After 4700th iteration, cost function is 1.56326235603\n",
      "After 4800th iteration, cost function is 1.56321611769\n",
      "After 4900th iteration, cost function is 1.56317154877\n",
      "After 5000th iteration, cost function is 1.5631285815\n",
      "After 5100th iteration, cost function is 1.56308715136\n",
      "After 5200th iteration, cost function is 1.5630471969\n",
      "After 5300th iteration, cost function is 1.56300865954\n",
      "After 5400th iteration, cost function is 1.56297148342\n",
      "After 5500th iteration, cost function is 1.56293561528\n",
      "After 5600th iteration, cost function is 1.56290100424\n",
      "After 5700th iteration, cost function is 1.56286760173\n",
      "After 5800th iteration, cost function is 1.56283536134\n",
      "After 5900th iteration, cost function is 1.56280423873\n",
      "After 6000th iteration, cost function is 1.56277419146\n",
      "After 6100th iteration, cost function is 1.56274517896\n",
      "After 6200th iteration, cost function is 1.56271716239\n",
      "After 6300th iteration, cost function is 1.56269010457\n",
      "After 6400th iteration, cost function is 1.5626639699\n",
      "After 6500th iteration, cost function is 1.56263872425\n",
      "After 6600th iteration, cost function is 1.56261433493\n",
      "After 6700th iteration, cost function is 1.56259077057\n",
      "After 6800th iteration, cost function is 1.56256800113\n",
      "After 6900th iteration, cost function is 1.56254599775\n",
      "After 7000th iteration, cost function is 1.56252473275\n",
      "After 7100th iteration, cost function is 1.56250417956\n",
      "After 7200th iteration, cost function is 1.56248431268\n",
      "After 7300th iteration, cost function is 1.5624651076\n",
      "After 7400th iteration, cost function is 1.56244654079\n",
      "After 7500th iteration, cost function is 1.56242858962\n",
      "After 7600th iteration, cost function is 1.56241123237\n",
      "After 7700th iteration, cost function is 1.56239444813\n",
      "After 7800th iteration, cost function is 1.56237821681\n",
      "After 7900th iteration, cost function is 1.56236251909\n",
      "After 8000th iteration, cost function is 1.56234733638\n",
      "After 8100th iteration, cost function is 1.56233265078\n",
      "After 8200th iteration, cost function is 1.56231844509\n",
      "After 8300th iteration, cost function is 1.56230470275\n",
      "After 8400th iteration, cost function is 1.56229140779\n",
      "After 8500th iteration, cost function is 1.56227854486\n",
      "After 8600th iteration, cost function is 1.56226609918\n",
      "After 8700th iteration, cost function is 1.56225405649\n",
      "After 8800th iteration, cost function is 1.56224240308\n",
      "After 8900th iteration, cost function is 1.56223112573\n",
      "After 9000th iteration, cost function is 1.56222021169\n",
      "After 9100th iteration, cost function is 1.56220964869\n",
      "After 9200th iteration, cost function is 1.56219942489\n",
      "After 9300th iteration, cost function is 1.56218952888\n",
      "After 9400th iteration, cost function is 1.56217994967\n",
      "After 9500th iteration, cost function is 1.56217067663\n",
      "After 9600th iteration, cost function is 1.56216169955\n",
      "After 9700th iteration, cost function is 1.56215300856\n",
      "After 9800th iteration, cost function is 1.56214459413\n",
      "After 9900th iteration, cost function is 1.56213644709\n",
      "After 10000th iteration, cost function is 1.56212855858\n",
      "=== For autograder ===\n",
      "3e-05\t30.3361\n"
     ]
    },
    {
     "data": {
      "image/png": [
       "iVBORw0KGgoAAAANSUhEUgAAAmEAAAHzCAYAAABos8qeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\n",
       "AAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xm4XXV97/H3B4IGBbQIKGBoKqhQcUAcK5TgUIRaqVq1\n",
       "k/pYxaFW1Gvt7dVq8ale52qhrW0tVlu9ah2rlVFJUFtBVBDCoKKmohWuEwKXINP3/rFXyCE5JznT\n",
       "2r89vF/PkyfnrL32Wh8Wh+TDWr/9+6WqkCRJ0nDt0DqAJEnSNLKESZIkNWAJkyRJasASJkmS1IAl\n",
       "TJIkqQFLmCRJUgO9lbAkK5Ocm+SCJJckeUO3/alJLk5yS5IH93V+SZKkUbairwNX1Q1Jjqyq65Os\n",
       "AL6Q5DDgIuBJwN/3dW5JkqRR11sJA6iq67sv7wDsCPykqi4DSNLnqSVJkkZar2PCkuyQ5ALgKmBt\n",
       "VV3S5/kkSZLGRa8lrKpuraoHAfcEfjXJmj7PJ0mSNC56fRy5SVX9LMmngYcA6+bzniQuailJksZG\n",
       "VS1orFVvJSzJHsDNVXV1kp2BxwGv3XK3bR1jof8w6keSdVW1pnUO+e9iGLzG/fMa989r3L8tr/Fi\n",
       "bh71+Thyb+CsbkzYucCnquqzSZ6U5ArgEcCnk5zaYwYtjw2tA+g2G1oHmAIbWgeYAhtaB5gCG1oH\n",
       "mAIblnqAPqeouAjYah6wqvo48PG+zqtebGgdQLfZ0DrAFNjQOsAU2NA6wBTY0DrAFNiw1AM4Y77m\n",
       "Y13rALrNutYBpsC61gGmwLrWAabAutYBpsC6pR4gVaM5/j1JOSZMkiSNg8X0Fu+ESZIkNWAJkyRJ\n",
       "asASJkmS1IAlTJIkqQFLmCRJUgOWMEmSpAYsYZIkSQ1YwiRJkhqwhEmSJDVgCZMkSWrAEiZJktSA\n",
       "JUySJKkBS5gkSVIDljBJkqQGLGGSJEkNWMIkSZIasIRJkiQ1YAmTJElqwBImSZLUgCVMkiSpAUuY\n",
       "JElSA5YwSZKkBixhkiRJDVjCJEmSGrCESZIkNWAJkyRJasASJkmS1IAlTJIkqQFLmCRJUgOWMEmS\n",
       "pAYsYZIkSQ1YwiRJkhqwhEmSJDVgCZMkSWrAEiZJktSAJUySJKkBS5gkSVIDljBJkqQGLGGSJEkN\n",
       "WMIkSZIaWNE6gCRp/pKDj4FVx8OuK+HaG+CKE6vWn9I6l6SFs4RJ0pgYFLBH/hW864DNW4/bPzkY\n",
       "i5g0fnwcKUljY9Xxty9gMPh+vxe3ySNpKSxhkjQ2dl05+/Zddh5uDknLwRImSSMuIQk7DsaAzWaf\n",
       "AxN+abipJC2VJUySRljCfsCngD+EK06E4y6//R7HfRvufxpwXsLrE3ZpEFPSIqSqWmeYVZKqqrTO\n",
       "IUktDO588SLgNcA7gDdXceNgcP5+Lx48grxuI3z3pKr1pyTsC7wRuGsVv9EyuzSNFtNbLGGSNGIS\n",
       "HgC8C7gBeF4VX1/Ae3euYmNv4STNyhImSRMg4b3AF4CTq7i1dR5J22cJkyRtJWF34FnA31RxY+s8\n",
       "0iRaTG9xYL4kTb47AY8G1ic8IcH/wZVGgHfCJKmBrgg9HTi3iu8M6ZyPZzDI/zvAy6q4bBjnlaaB\n",
       "d8IkaQwk/CLw78CrgF2Hdd4qTgPuD5wBnN19olJSI5YwSRqShB0TXgp8BfgP4NAqLhxmhipuquLt\n",
       "wP5VfH+Y55Z0ey7gLUlDkLADsBa4BfiVKr7RMk8V17U8vyTHhEnS0CQ8ELiwitH8gxdIeA5wRhVX\n",
       "tM4ijRPHhEnSCKviayNewALcE7gg4TUJLgwu9cgSJknLLBneYPvlVEVV8VrgUOBg4NKEpzqlhdQP\n",
       "S5gkLZOEJPw28I1u6aGxVMWGKp7GYILXVwEvbxxJmkiOCZOkZdBNO/FOYBVwXBXnNI60LLqFxHd2\n",
       "IL+0bY4Jk6Qh22LaiS8AD56UAgZQxS0WMKkfTlEhSUuzE/BARmDaiWFKOBS4WxVntM4ijSsfR0qS\n",
       "FixhDXAysB54eRWXt00kteXjSEnSUFSxDvhl4IvAOQlvHNdPhUqt9FbCkqxMcm6SC5JckuQN3fbd\n",
       "k5yZ5BtJzkhy174ySNJySbhbwtsS7tw6y6io4udVvBF4ALA38AWns5Dmr7cSVlU3AEdW1YMY/Ad6\n",
       "ZJLDgD8Fzqyq+wCf7b6XpJHUTTvxuwweu+3YOs8oquK/q3gWcOQoT0YrjZpeB+ZX1fXdl3dg8IfX\n",
       "T4EnAkd0298LrMMiJmkEJaxmMO3EvsCxVXypbaLRVsVPWmeQxkmvJSzJDsBXgf2Bd1bVxUnuXlVX\n",
       "dbtcBdy9zwxavOTgY2DV8bDrSrj2BrjixKr1p7TOJfVh65/33T8I738r8DbgrVXc1DrjOOrmGXsO\n",
       "8M9w8KP9M0XarO87YbcCD0pyF+D0JEdu8XolmfPWdZITZny7rqrW9RJUWxn8hfTIv4J3HbB563H7\n",
       "JwfjH5qaNHP9vMNTXlL10fe3SzYRdgN+Hc48AY4MnHSPzS/5Z4rGV5I1wJolHWNYU1QkeTWwEXgu\n",
       "sKaqrkyyN7C2qg6cZX+nqGgoOfo0OPWorV954bfhnR8C/qOKT2/9Pg4DjpnlkO7v/iO8/+8fBe97\n",
       "8Nbbjzmt6pSjZzm+Fij5vS/D+w/d+hWvsSbDYnpLb3fCkuwB3FxVVyfZGXgc8FrgkwzWI3tT9/sn\n",
       "+sqgpdh15ezbVwS4Drhxjjfe2L0+23b3d/8R3f+Oc/xZuMvOcxxHC3bTHLPue401vXq7E5bk/gwG\n",
       "3u/Q/fqXqnpLkt2BfwX2AzYAT6uqq2d5v3fCGpr7Tpj/16rJ4897/7zGmnQjNVlrVV1UVQ+uqgdV\n",
       "1QOq6i3d9p9U1WOr6j5V9WuzFTCNgitOhOO2mAH7ud+C757UJo/UJ3/e++c1lrbkskWa02Cw8n4v\n",
       "HjwuuG4jfPckB9BqUvnz3j+vsSbZYnqLJUySJGmJRupxpCRJkuZmCZMkSWrAEiZJGrqE53TztklT\n",
       "yxImSWphL+C3WoeQWrKESZJaOAP4tdYhpJYsYZKkFs4H9kxY1TqI1IolTJI0dFXcCnyGwZJ20lSy\n",
       "hEmSWvGRpKaak7VKkppIuCuwRxWXb3dnacQ5Y74kSVIDzpgvSZI0JixhkiRJDVjCJEmSGrCESZKa\n",
       "SkjCnVvnkIbNEiZJau2lwBtah5CGzRImSWrtbJwvTFPIEiZJau0C4G4Jv9g6iDRMljBJUlPdEkZn\n",
       "4hJGmjKWMEnSKHAJI00dS5gkaRScCezcOoQ0TC5bJEmStEQuWyRJkjQmLGGSJEkNWMIkSZIasIRJ\n",
       "kiQ1YAmTJI2MhP0Tfqt1DmkYLGGSpFGyC64jqSlhCZMkjZKLgF0T7tU6iNQ3S5gkaWS4hJGmiSVM\n",
       "kjRqXMJIU8EZ8yVJIyVhb+ASYM8qbm6dR5oPZ8yXJI29Kn4APA/YsXUWqU/eCZMkSVoi74RJkiSN\n",
       "CUuYJElSA5YwSZKkBixhkiRJDVjCJEkjKWFVwpda55D6YgmTJI2q7wGrEvZvHUTqgyVMkjSSqigG\n",
       "s+e7hJEmkiVMkjTKXMJIE8vJWiVJIyvh7sBluISRRpyTtUqSJkoVVwFfBw5snUVabt4JkySNtIQd\n",
       "qri1dQ5pW7wTJkmaOBYwTSpLmCRJUgOWMEmSpAYsYZIkSQ1YwiRJIy9hx4QnJPiBLU0MS5gkaRzc\n",
       "Cvw9uISRJoclTJI08mYsYXRU6yzScrGESZLGhUsYaaI4WaskaSwk7AlcDuxRxU2t80gzOVmrJGli\n",
       "VfFDBiXsEa2zSMvBEiZJGidvAK5tHUJaDj6OlCRJWiIfR0qSJI0JS5gkSVIDljBJkqQGLGGSJEkN\n",
       "WMIkSWMn4R8S7tM6h7QUljBJ0jjaEZcw0pizhEmSxpFLGGns9VbCkqxKsjbJxUnWJzm+2/7AJF9M\n",
       "cmGSTybZta8MkqSJ9VngiIQ7tA4iLVafd8JuAl5WVfdjsMTEi5IcBPwj8CdV9QDg48AreswgSZpA\n",
       "VfwI+DrwyNZZpMXqrYRV1ZVVdUH39XXApcC+wL2r6vPdbp8BntJXBknSRDsDeFzrENJirRjGSZKs\n",
       "Bg4BzgUuTnJsVf0b8FRg1TAySJImzpuBja1DSIvVewlLsgvwEeAlVXVtkj8ATkzyauCTwI3beO8J\n",
       "M75dV1Xr+swqSRofVfysdQZNryRrgDVLOkafC3gn2Qn4d+DUqnrHLK/fB/iXqnr4LK+5gLckSRoL\n",
       "I7WAd5IAJwOXzCxgSfbsft8B+DPgnX1lkCRJGlW93QlLchjwOeBCYNNJXgncG3hR9/1Hq+qVc7zf\n",
       "O2GSJGksLKa39Po4ciksYZKk+UjYC7ipip+2zqLpNVKPIyVJGpLXA89sHUJaKEuYJGncuYSRxpKP\n",
       "IyVJYy1hd2ADsGcVP28cR1PKx5GSpKlTxU8YrMryK62zSAthCZMkTQIfSWrsWMIkSZPgk8DVrUNI\n",
       "C+GYMEmSpCVyTJgkSdKYsIRJkiQ1YAmTJElqwBImSZLUgCVMkjQxEo5KeHLrHNJ8WMIkSZNkF+C4\n",
       "1iGk+XCKCknSxEj4BeC7DJYwuqF1Hk0Pp6iQJE21Kn4KrAce1TqLtD2WMEnSpDkdlzDSGLCESZIm\n",
       "jetIaiw4JkySNFESVgCHVnFu6yyaHovpLZYwSZKkJXJgviRJ0piwhEmSJDVgCZMkSWrAEiZJmlgJ\n",
       "K1tnkOZiCZMkTaSEo4B/a51DmoufjpQkTaSEuwDfA/aqYmPrPJpsfjpSkqROFT8DvgYc1jqLNBtL\n",
       "mCRpkjl7vkaWJUySNMksYRpZljBJ0iT7MnB9wp1aB5G25MB8SZKkJXJgviRJ0piwhEmSJDVgCZMk\n",
       "SWrAEiZJktSAJUySNPESdk94Zusc0kx+OlKSNPESdgO+D9y9iutb59Hk8dORkiTNooprgAuAw1tn\n",
       "kTaxhEmSpoWz52ukWMIkSdPCEqaRYgmTJE2LLwP7JuzTOogEljBJ0pSo4hbg2cCNrbNI4KcjJUmS\n",
       "lsxPR0qSJI0JS5gkSVIDljBJkqQGLGGSJEkNWMIkSVMlYUXCRQl3bp1F080SJkmaKlXcDPwYOKJ1\n",
       "Fk03S5gkaRo5e76as4RJkqaRJUzNbbeEJTksyZlJvpnkO92vbw8jnCRJPTkf2CthVesgml4r5rHP\n",
       "ycBLga8Ct/QbR5Kk/lVxS8KZwEOBK1rn0XTa7rJFSc6tqocPKc/M87pskSSpNwk7dutJSku2mN4y\n",
       "nxL2RmBH4GPAzzdtr6qvLibkvINZwiRJ0pjoq4StA7baqaqOXFC6BbKESZKkcdFLCWvFEiZJksbF\n",
       "YnrLfD4dedckb0/yle7X25LcZfExJUmSNJ95wt4NXAM8FXgacC3wT32GkiRpWBIOdwkjtTCfMWFf\n",
       "q6oHbm/bsgfzcaQkaQgSzgLeVsWnW2fR+OrlcSSwMcnhM05yGHD9QsNJkjSinD1fTcxnstYXAP88\n",
       "YxzYT4Fn9RdJkqShOgN4f+sQmj7z/nRkkt0AquqaXhNtPp+PIyVJvUvYAbgKOLSK77bOo/G0mN4y\n",
       "552wJM+oqn9J8nJmzBOWJEBV1V8uPqokSaOhilu7JYwex2CpPmkotvU48k7d77ty+8lawyyTt0qS\n",
       "NMZOBnZqHULTxclaJUmSlqivyVrfnGS3JDsl+WySHyV5xjzetyrJ2iQXJ1mf5Phu+8OSfCnJ+UnO\n",
       "S/LQhQSWJEmaBPOZouKobjD+E4ANwP7AK+bxvpuAl1XV/YBHAC9KchDwZuDVVXUI8Jrue0mSpKky\n",
       "nykqNu3zBOAjVfWzJNt9hllVVwJXdl9fl+RSYF/gB8Cm6S7uCnx/waklSZLG3HxK2KeSXAbcALww\n",
       "yV7d1/OWZDVwCHAO8E3gC0neyuBO3CMXcixJkqRJMK+B+UnuBlxdVbckuTOwa3enaz7v3QVYB7yu\n",
       "qj6R5DPA31TVx5M8FXheVT1ulvc5MF+SNFQJrwDOr+IzrbNovCz3PGGPqarPJnkK3ZQU3RxhdN9/\n",
       "bB6BdgI+Cryvqj7RbX5YVT22+/ojwD9u4/0nzPh2XVWt2945JUlaggDHgiVM25ZkDbBmSceY605Y\n",
       "ktdW1Z8neQ+zzAtWVc/eTrgA7wV+XFUvm7H9qwwG7J+d5DHAG6tqq09IeidMkjRsCQ8CPlTFfVtn\n",
       "0XhZTG/pbZ6wbqHvzwEXsrnEvRL4IfA3wB2BjcAfVtX5s7zfEiZJGqpuCaMfAA+vYkPjOBojvZSw\n",
       "JP8beHNVXd19/wvAy6vqzxaddD7BLGGSpAYS3gecXcW7WmfR+OhlslbgmE0FDKCqfgr8+kLDSZI0\n",
       "Js4Afq11CE2++UxRsUOSlVV1A0CSnYE79BtLkqRW1lwHu+2erFwH194AV5xYtf6U1qk0eeZTwt4P\n",
       "fDbJuxl8auTZwD/3mkqSpAaSg4+BR74J3nXA5q3H7Z8cjEVMy22+84QdDTym+/bMqjq911Q4JkyS\n",
       "NHzJ0afBqUdt/coxp1WdcvTwE2lcLOs8YVu4FLi5qs5Mcqcku1bVtQuPKEnSKNt15ezbd9l5uDk0\n",
       "DbY7MD/J84APA3/Xbbon8Im53yFJ0ri6do5l+a7bONwcmgbz+XTki4DDgGsAquobwF59hpIkqY0r\n",
       "ToTjLr/9tud+C757Ups8mmTzeRz586r6+aYVi5KsYJYZ9CVJGndV609JDgaOeTEccBDcdAucc7yD\n",
       "8tWH+UzW+hbgauCZwB8BfwhcUlWv6jWYA/MlSQ0lHAm8oYpHtM6i0dfXjPk7AM9l88R1pwP/WH2t\n",
       "d7T5vJYwSVIzCSsZLLW3b9VgSI40l2UvYd2jx/VVdeBSwy2UJUyS1FrCWcDbqvh06ywabcu+bFFV\n",
       "3Qx8PckvLimZJEnjaS1wZOsQmkzzGZi/O3Bxki8B/6/bVlX1xP5iSZI0Ek4DntQ6hCbTfMaEHbHp\n",
       "yxmbq6rO7i0VPo6UJEnjY1lnzO8W6n4BcABwIfDuqrppaRElSZIE2x4T9l7gUAYF7BjgrUNJJEmS\n",
       "NAXmfByZ5KKqun/39QrgvKo6ZGjBfBwpSZLGxHJ/OvLmTV90n5KUJEnSMtnWnbBbgOtnbNoZ2LSA\n",
       "aVXVbr0G806YJGlEJBwFXFPFF1tn0Wha1oH5VbXj0iNJkjQR7gfcGyxhWj7bnKxVkiQBTtqqHljC\n",
       "JEnavq8Beybs0zqIJoclTJKk7ajiVuBsvBumZWQJkyRpfs7CEqZlNJ+1IyVJEnycwQTm0rLY7tqR\n",
       "rThFhSRJGhfLPVmrJEmSemIJkyRJasASJkmS1IAlTJIkqQFLmCRJC5BwQsIftM6h8WcJkyRpYf4L\n",
       "eFzrEBp/ljBJkhZmLXBkgtMoaUksYZIkLUAVG4CNwEGNo2jMWcIkSVo4lzDSklnCJElauLXAQ1qH\n",
       "0Hhz2SJJkhYoYQVwSxWj+Zeohm4xvcUFvCVJWqAqbm6dQePPx5GSJEkNWMIkSZIasIRJkiQ1YAmT\n",
       "JGmREg5I2Lt1Do0nS5gkSYt3PPCM1iE0nixhkiQt3lrg0a1DaDw5T5gkSYuUsDuwAbhbFTc1jqOG\n",
       "FtNbvBMmSdIiVfET4HLgoa2zaPxYwiRJWhofSWpRLGGSJC3Nx4Dvtw6h8eOYMEmSpCVyTJgkSdKY\n",
       "sIRJkiQ1YAmTJElqwBImSZLUgCVMkqRlkPCChEe0zqHxYQmTJGl57AMc2zqExoclTJKk5bEWOLJ1\n",
       "CI0P5wmTJGkZJKwEfgjsW8U1rfNouJwnTJKkRqq4ATgPOLx1Fo0HS5gkScvHR5KaNx9HSpK0TBL2\n",
       "Bu5YxYbWWTRci+ktljBJkqQlckyYJEnSmLCESZIkNWAJkyRJasASJknSMkvYIWFF6xwabZYwSZKW\n",
       "3/uBJ7cOodHWWwlLsirJ2iQXJ1mf5Phu+4eSnN/9+k6S8/vKIElSI+fhfGHajj5vld4EvKyqLkiy\n",
       "C/CVJGdW1dM37ZDkrcDVPWaQJKmFs4Dntw6h0dbbnbCqurKqLui+vg64lMEK8wAkCfA04AN9ZZAk\n",
       "qZELgT2SzX/vSVsaypiwJKuBQ4BzZ2w+HLiqqr41jAySJA1LFbcCZ+MjSW1D75/c6B5FfgR4SXdH\n",
       "bJPfAf7Pdt57woxv11XVumUPKElSP04H9msdQv1IsgZYs6Rj9LlsUZKdgH8HTq2qd8zYvgL4HvDg\n",
       "qvrvOd7rskWSJGksjNSyRd2Yr5OBS2YWsM5jgUvnKmCSJEmTrs8xYY8Cfh84csaUFI/vXns6DsiX\n",
       "JElTrNfHkUvh40hJkjQuRupxpCRJkuZmCZMkqUcJj03Yu3UOjR5LmCRJ/XoW8ButQ2j0WMIkSerX\n",
       "WcCjW4fQ6LGESZLUr7XAmgQ/bKbbsYRJktSjKjYAG4GDGkfRiLGESZLUPx9Jaiu9rx0pSZJ4N3DH\n",
       "1iE0WpysVZIkaYmcrFWSJGlMWMIkSZIasIRJkiQ1YAmTJElqwBImSdKQJPxlwiGtc2g0WMIkSRqe\n",
       "FcDjWofQaLCESZI0PGtx0lZ1nCdMkqQhSdgd2ADsUcWNjeNoGTlPmCRJI6yKnwCXAw9tnUXtWcIk\n",
       "SRqutcCRrUOoPR9HSpI0RN0jyeuruKF1Fi2fxfQWS5gkSdISOSZMkiRpTFjCJEmSGrCESZIkNWAJ\n",
       "kySpgYS7JdyxdQ61YwmTJKmNjwNHtA6hdixhkiS1sQ7nC5tqljBJktpw0tYp5zxhkiQ1kLAS+BGw\n",
       "TxXXtM6jpXGeMEmSxkQ3Y/6XgMNbZ1EbljBJktr5MLBL6xBqw8eRkiRJS+TjSEmSpDFhCZMkSWrA\n",
       "EiZJktSAJUySJKkBS5gkSY0lPD9hj9Y5NFyWMEmS2nsC8OjWITRcljBJktpzCaMpZAmTJKm9s/BO\n",
       "2NSxhEmS1N6FwB4J+7QOouGxhEmS1FgVtwLr8JHkVHHZIkmSRkDCQ4Frq7isdRYt3GJ6iyVMkiRp\n",
       "iVw7UpIkaUxYwiRJkhqwhEmSJDVgCZMkSWrAEiZJ0ghJOCPh3q1zqH+WMEmSRsuVOF/YVLCESZI0\n",
       "WtbiEkZTwRImSdJoWQusSXCuzAlnCZMkaYRUsQG4HjiocRT1zBImSdLoWQs8vHUI9ctliyRJGjEJ\n",
       "d6jixtY5NH8uWyRJ0gSwgE0HS5gkSVIDljBJkqQGLGGSJEkNWMIkSRpRCQ9JWNE6h/phCZMkaXS9\n",
       "BzikdQj1wxImSdLoOguXMJpYljBJkkbXWlzMe2I5WaskSSMqYXdgA7CHc4eNNidrlSRpglTxE+Bb\n",
       "wENbZ9Hy662EJVmVZG2Si5OsT3L8jNdenOTSbvub+sogSdIEeGfrAOpHb48jk9wDuEdVXZBkF+Ar\n",
       "wG8C9wBeCRxTVTcl2bOqfjjL+30cKUmSxsJiektvc49U1ZXAld3X1yW5FNgXOA54Q1Xd1L22VQGT\n",
       "JEmadEMZE5ZkNYN5Ts4F7gP8apJzkqxL8pBhZJAkSRolvc/C2z2K/Ajwkqq6NskK4Beq6hFJHgr8\n",
       "K3CvvnNIkiSNkl5LWJKdgI8C76uqT3Sbvwd8DKCqzktya5K7VdWPZ3n/CTO+XVdV6/rMK0mSNB9J\n",
       "1gBrlnSMHgfmB3gv8OOqetmM7c8H9qmqP09yH+AzVbXfLO93YL4kSUBCgHcA/6uK61vn0dZGbZ6w\n",
       "RwG/DxyZ5Pzu1+OBdwP3SnIR8AHgmT1mkCRp7FVRwKEM/m7VhHDGfEmSxkDCXwA7VvHK1lm0tVG7\n",
       "EyZJkpbPWbiO5ETxTpgkSWMgYSXwI2DvKq5tnUe3550wSZImVBU3AOcBh7fOouXhnTBJksZEwv2A\n",
       "K6vYalontbWY3mIJkyRJWiIfR0qSJI0JS5gkSVIDljBJkqQGLGGSJI2ZpN+1nzUcljBJksZIt47k\n",
       "hoQ9W2fR0ljCJEkaI906khcAaxpH0RJZwiRJGj8uYTQBLGGSJI2ftcCjW4fQ0ljCJEkaP18D9krY\n",
       "p3UQLZ4lTJKkMVPFrcCngANbZ9HiuWyRJEnSErlskSRJ0piwhEmSJDVgCZMkSWrAEiZJktSAJUyS\n",
       "pDGVsGPCU7uljDRmLGGSJI2vW4F3APu3DqKFs4RJkjSmunUkz8LZ88eSJUySpPG2FteRHEuWMEmS\n",
       "xtta4EjHhY0fS5gkSWOsiu8AG4GDWmfRwljCJEkaf68BbmwdQgvj2pGSJElLtJjesqKvMJIkSbNJ\n",
       "Dj4GVh0Pu66Ea2+AK06sWn9K61zzsZzZLWGSJGloBiXmkX8F7zpg89bj9k8OZtSL2LayL+p4Po6U\n",
       "JEnDkhx9Gpx61NavPOcSOPkk4IIqztn6fRwCPHyWQw5t/7mzH3ManPp4H0dKkqTmEu4I3BuoKi7e\n",
       "/MquK2d/x11+AXgQ8H/nOORe3etbGuL+c2XfZec5jrlNljBJkiZAwh2ADwNPruKWBue/L/Ac4EAG\n",
       "02WsAjYA74aZJezaG2Y/wmVfq+IFcx2/itOB0+ebp5/958p+3cb5nmcmp6iQJGkCVHEjgzUkD1nu\n",
       "Yyck4Z4Jj0349Tl22wG4GngP8ERgtyoOrOLNt9/tihPhuMtvv+2534LvnrTcuZff8mZ3TJgkSRMi\n",
       "4STgiq2Lz6KOtS/wBgZ3tg4ErgcuAz5bxV8s7dgHHwP7vXjwGO+6jfDdk0Z9UP4mc2VfTG+xhEmS\n",
       "NCGSN74Orno+fP/ibU2fkHBnNpere1Txtln2uQvwFAbF69Iqftp3/nHmPGGSJE2pwR2aR/0u/P0e\n",
       "wBGDrZunfugGyn+SQfHaE/gmcClw0WzHq+JnDMZzqSfeCZMkaQJsa/qEqlOOHuzD44FvAP/VYvD+\n",
       "JPNOmCRJU2v70ydUcdqw0mj7/HSkJEkTYXmnT1D/LGGSJE2EcZ76YTo5JkySpAkxzlM/jDunqJAk\n",
       "SWpgMb3Fx5GSJEkNWMIkSZIasIRJkiQ1YAmTJElqwBImSZLUgCVMkiSpAUuYJElSA5YwSZKkBixh\n",
       "kiRJDVjCJEmSGrCESZIkNWAJkyRJasASJkmS1IAlTJIkqQFLmCRJUgOWMEmSpAYsYZIkSQ1YwiRJ\n",
       "khqwhEmSJDVgCZMkSWrAEiZJktSAJUySJKkBS5gkSVIDvZWwJKuSrE1ycZL1SY7vtp+Q5HtJzu9+\n",
       "Pb6vDFoeSda0zqAB/130z2vcP69x/7zG/VuOa9znnbCbgJdV1f2ARwAvSnIQUMBfVtUh3a/Tesyg\n",
       "5bGmdQC4azFtAAAHWUlEQVTdZk3rAFNgTesAU2BN6wBTYE3rAFNgzVIPsGIZQsyqqq4Eruy+vi7J\n",
       "pcC+3cvp67zqxerWAXSb1a0DTIHVrQNMgdWtA0yB1a0DTIHVSz3AUMaEJVkNHAKc0216cZKvJTk5\n",
       "yV2HkUFLsrp1AN1mdesAU2B16wBTYHXrAFNgdesAU2D1Ug+QqlqGHNs4QbILsA54XVV9IslewA+7\n",
       "l/8C2LuqnjPL+/oNJkmStIyqakFP+notYUl2Av4dOLWq3jHL66uBT1XV/XsLIUmSNIL6/HRkgJOB\n",
       "S2YWsCR7z9jtScBFfWWQJEkaVb3dCUtyGPA54EIGn4gEeCXwO8CDum3fAZ5fVVf1EkKSJGlE9T4m\n",
       "TJIkSVtzxnxJkqQGLGHSmMvA65OcmOSZrfNMoiRrknw+yTuTHNE6z6RKcuck5yX59dZZJlGSA7uf\n",
       "4X9NstWsBFq6JMcm+YckH0zyuO3tbwnTnJI8PsllSb6Z5H+2zqM5/SaDiZBvBL7XOMukuhW4Frgj\n",
       "XuM+/QnwodYhJlVVXVZVLwR+GziqdZ5JVFX/VlXPA14APH17+1vCNKskOwJ/DTwe+GXgd7plp9ST\n",
       "JO9OclWSi7bYvr0yfB/gP6rqj4EXDiXsmFrCNf58VR0D/Cnw2qGEHVOLvcbdXYNL2DyPpOawhJ9j\n",
       "kvwG8Gngg8PIOq6Wco07f8bg79BtsoRpLg8DLq+qDVV1E4P/YI9tnGnS/ROD0nubucpwkmckeXuS\n",
       "fRjcmbm6e8utwww8hhZ1jWvzJ5iuZnA3THNb7M/xEQzWGf5d4LhumiPNbrHXmKr6VFUdDTxr2KHH\n",
       "zKKucTc85E0M5ke9YHsn6W3tSI29fYErZnz/PeDhjbJMhar6fDeB8Uy3lWGAJB8Ejq2qNwL/0m37\n",
       "GHBSksMZrE6hOSzhGj+JweObuwInDSvvOFrsNWZw54AkzwJ+WH50f05L+Dk+AngysBJYO6y842gJ\n",
       "1/h44DHAbkkOqKq/39Z5LGGai38AjobtluGq2gg8d5ihJsx8rvHHgY8PM9SEmff/1FXVe4eSaPLM\n",
       "5+f4bODsYYaaMPO5xicCJ873gD6O1Fy+D6ya8f0qHJDcgmW4f17j/nmN++c17t+yX2NLmObyZeDe\n",
       "SVYnuQODT3l8snGmaWQZ7p/XuH9e4/55jfu37NfYEqZZVdXNwB8BpzP4xNKHqurStqmmkmW4f17j\n",
       "/nmN++c17t+yX2NLmOZUVadW1X2r6oCqekPrPJMuyQeA/wTuk+SKJM+2DC8vr3H/vMb98xr3b1jX\n",
       "2LUjJUmSGvBOmCRJUgOWMEmSpAYsYZIkSQ1YwiRJkhqwhEmSJDVgCZMkSWrAEiZJktSAJUxS75Lc\n",
       "kuT8JBcm+ViSXXo4x7okhy7wPa9N8phFnOvYJAct9TiSppslTNIwXF9Vh1TVA4BrgOf3cI5iAQvs\n",
       "Jtmhqv68qj67iHM9Cfjl2068+ONImmKWMEnD9kVgf4Ak+yc5NcmXk3wuyX1nbD+nu3P2uiTXdtvX\n",
       "JPnUpgMl+eskz9ryBEn+Nsl5SdYnOWHG9g1J3pjkK8BTk7wnyVOSHNrdqTs/yUVJbu32Py7Jl5Jc\n",
       "kOQjSXZO8ivAbwBvSfLVJPfadJzuPY/ptl+Y5ORujblN5z4hyVe61+7b0/WVNCYsYZKGJsmOwK8B\n",
       "67tN/wC8uKoeArwC+Ntu+18Bb+/unF2xjUPOdffrVVX1UOCBwBFJDp6x/4+q6tCq+tCm91fVV7o7\n",
       "dYcApwJv6fb/aFU9rKoeBFwKPKeq/pPBor1/XFUPrqpvbzpOkpXAPwFP67KvAF4449w/rKpDgXcC\n",
       "fzyPSyZpglnCJA3DzknOB34ArAL+rhsX9kjgw91rfwfco9v/EcCHu68/sIjzPb272/VV4H7MeHQI\n",
       "fGiLfXPbF8nTgQcDf9ptun+Szye5EPi9LY4Tbi/AfYHvVNXl3bb3Ar86Y5+Pdb9/FVi9kH8gSZNn\n",
       "ResAkqbCxqo6JMnOwOnAscBngKu7u0/zdTO3/5/HnbfcIckvAS8HHlJVP0vyT8DKGbv8v9kO3N0t\n",
       "+3Pg8KradHftPcATq+qi7rHnmhlvme0O3JbbssW2n3e/34J//kpTzzthkoamqjYCxwOvB64DvpPk\n",
       "twAy8IBu13OA3+q+/u0Zh/gv4JeT3CHJXYFHz3Ka3RgUrWuS3B04enuxumN9AHhGVf14xmu7AFcm\n",
       "2Qn4fTYXqmu789zuOMDXgdVJ9u+2PQM4ezvnlzSlLGGShuG2u0FVdQFwOfA0Bo/4npPkAgbjxJ7Y\n",
       "7fZS4H902/cHfta99wrgX7t9P8Tgsd7tT1T1NeB84DLg/cAX5pHvicB+wD92g/M3HffVwLndMS6d\n",
       "sf8HgVd0g+zvNePcPweezeAR64UM7tz93ZbXgAV+klPSZMrmu+6SNBqS7NzdNSPJbwNPr6onNY4l\n",
       "ScvKMQmSRtGhSf6awZiqnwJ/0DiPJC0774RJkiQ14JgwSZKkBixhkiRJDVjCJEmSGrCESZIkNWAJ\n",
       "kyRJasASJkmS1MD/B8kXpIDFSkUPAAAAAElFTkSuQmCC\n"
      ],
      "text/plain": [
       "<matplotlib.figure.Figure at 0x14e80518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Write down the best regularization and accuracy you found\n",
    "# sanity check: your accuracy should be around or above 30%\n",
    "\n",
    "### YOUR CODE HERE\n",
    "plt.plot(regularizations, precisions, \"bo--\")\n",
    "plt.xlabel(\"Regularization\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.xlim(np.array([-1e-6, max(regularizations)*1.1]))\n",
    "plt.xscale(\"symlog\",linthreshx=1e-6)\n",
    "\n",
    "BEST_REGULARIZATION = 1\n",
    "BEST_ACCURACY = 0.0\n",
    "i = np.argmax(precisions)\n",
    "BEST_REGULARIZATION = regularizations[i]\n",
    "BEST_ACCURACY = precisions[i]\n",
    "regularization = BEST_REGULARIZATION\n",
    "print precisions\n",
    "print regularizations\n",
    "weights = sgd(lambda weights: softmax_wrapper(trainFeatures, trainLabels, weights, regularization), weights, 3.0, 10000, PRINT_EVERY=100)\n",
    "### END YOUR CODE\n",
    "\n",
    "print \"=== For autograder ===\\n%g\\t%g\" % (BEST_REGULARIZATION, BEST_ACCURACY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== For autograder ===\n",
      "Test precision (%): 28.280543\n"
     ]
    }
   ],
   "source": [
    "# Test your findings on the test set\n",
    "\n",
    "testset = dataset.getTestSentences()\n",
    "nTest = len(testset)\n",
    "testFeatures = np.zeros((nTest, dimVectors))\n",
    "testLabels = np.zeros((nTest,), dtype=np.int32)\n",
    "\n",
    "for i in xrange(nTest):\n",
    "    words, testLabels[i] = testset[i]\n",
    "    testFeatures[i, :] = getSentenceFeature(tokens, wordVectors, words)\n",
    "    \n",
    "_, _, pred = softmaxRegression(testFeatures, testLabels, weights)\n",
    "print \"=== For autograder ===\\nTest precision (%%): %f\" % precision(testLabels, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extra Credit\n",
    "\n",
    "Train your own classifier for sentiment analysis! We will not provide any starter code for this part, but you can feel free to reuse the code you've written before, or write some new code for this task. Also feel free to refer to the code we provided you with to see how we scaffolded training for you.\n",
    "\n",
    "Try to contain all of your code in one code block. You could start by using multiple blocks, then paste code together and remove unnecessary blocks. Report, as the last two lines of the output of your block, the dev set accuracy and test set accuracy you achieved, in the format we used above.\n",
    "\n",
    "*Note: no credits will be given for this part if you use the dev or test sets for training, or if you fine-tune your regularization or other hyperparameters on the test set.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE\n",
    "\n",
    "### END YOU CODE\n",
    "\n",
    "\n",
    "_, _, pred = softmaxRegression(devFeatures, devLabels, weights)\n",
    "print \"=== For autograder ===\\nDev precision (%%): %f\" % precision(devLabels, pred)\n",
    "_, _, pred = softmaxRegression(testFeatures, testLabels, weights)\n",
    "print \"Test precision (%%): %f\" % precision(testLabels, pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
